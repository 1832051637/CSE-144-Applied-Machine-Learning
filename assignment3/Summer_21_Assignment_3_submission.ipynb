{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Summer_21_Assignment_3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IlwhV0z2nMr"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU7xWQml74JY"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Chprzdhe2nMw"
      },
      "source": [
        "# Assignment 3\n",
        "\n",
        "**DUE: Sunday July 11 at 11:59pm**\n",
        "\n",
        "Turn in the assignment via Canvas.\n",
        "\n",
        "To write legible answers you will need to be familiar with both [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) and [Latex](https://www.latex-tutorial.com/tutorials/amsmath/)\n",
        "\n",
        "Before you turn this problem in, make sure everything runs as expected. First, restart the kernel (in the menubar, select Runtime→→Restart runtime) and then run all cells (in the menubar, select Runtime→→Run All).\n",
        "\n",
        "Make sure you fill in any place that says \"YOUR CODE HERE\" or \"YOUR ANSWER HERE\", as well as your name below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jeWubXE2nMx"
      },
      "source": [
        "NAME = \"Erjie Zhang\"\n",
        "STUDENT_ID = \"ezhang25\""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_22iEs6s1oL"
      },
      "source": [
        "## Problem 1 - Logistic Regression Calculation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrpQWvSs0x3v"
      },
      "source": [
        "Recall from lecture sigmoid function:\n",
        "$$\\begin{align}\n",
        "f(x)= \\sigma(\\theta^T \\cdot \\mathbf{x})) = \\frac{1}{1+e^{\\theta^T \\cdot \\mathbf{x}}}\n",
        "\\end{align}$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeJAjBYEs6iJ"
      },
      "source": [
        "### a) Probabilities (10 points)\n",
        "Write a script to, or by hand, calculate the probability $ \\sigma(\\theta^T \\cdot \\mathbf{x}))$ for each of the following $x^i$'s assuming Assuming $\\theta=[-0.1, 0.1, 0.5, 0.3]$, \n",
        "\n",
        "| | $x^i_{0}$ | $x^i_{1}$ | $x^i_{2}$ | y|\n",
        "| --- | --- | --- | --- | --- |\n",
        "|$x^{1}$ | 1 | -7 | -3 | 0 |\n",
        "|$x^{2}$ | 1 | 5 | 1 | 1 |\n",
        "|$x^{3}$ | 1 | 1 | 1 | 1 |\n",
        "|$x^{4}$ | -1 | -1 | 1 | 1 |\n",
        "|$x^{4}$ | 2 | -1 | 3 | 0 |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3AQpCM_BE-M"
      },
      "source": [
        "θ^T⋅x^1 = (-0.1 * 1 + 0.1* (-7) + 0.5 * (-3) + 0.3 * 0) = -2.3, p(θ^T⋅x^1) = 0.091\n",
        "\n",
        "θ^T⋅x^2 = (-0.1 * 1 + 0.1* 5 + 0.5 * 1 + 0.3 * 1) = 1.2, p(θ^T⋅x^2) = 0.769\n",
        "\n",
        "θ^T⋅x^3 = (-0.1 * 1 + 0.1* 1 + 0.5 * 1 + 0.3 * 1) = 0.8, p(θ^T⋅x^3) = 0.690\n",
        "\n",
        "θ^T⋅x^4 = (-0.1 * -1 + 0.1* (-1) + 0.5 * 1 + 0.3 * 1) = 0.8, p(θ^T⋅x^4) = 0.690\n",
        "\n",
        "θ^T⋅x^5 = (-0.1 * 2 + 0.1* (-1) + 0.5 * 3 + 0.3 * 0) = 1.2, p(θ^T⋅x^5) = 0.769"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd413HoUtBRH"
      },
      "source": [
        "### b) Classification (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmoTCICMBMGs"
      },
      "source": [
        "Using the probabilities you calculated in part a) and the decision boundary $\\theta^T\\mathbf{x}=0$ classify the points as class 1 or class 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nKSXta9BIW7"
      },
      "source": [
        "Class 0(prob > 1/2): X^1\n",
        "\n",
        "Class 1(prob < 1/2): X^2, X^3, X^4, X^5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IeQoSWbtEPn"
      },
      "source": [
        "## Problem 2 - Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh57Se9YtZBD"
      },
      "source": [
        "For this problem, we will predict whether or not breast tumors are cancerous or not using the Breast Cancer Wisconsin (Diagnostic) Data Set. Begin by importing and processing data. A description of the dataset is given below.\n",
        "\n",
        "\n",
        "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. \n",
        "\n",
        "Separating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree Construction Via Linear Programming.\" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree. Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.\n",
        "\n",
        "The actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n",
        "\n",
        "This database is also available through the UW CS ftp server:\n",
        "ftp ftp.cs.wisc.edu\n",
        "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
        "\n",
        "Also can be found on UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
        "\n",
        "Attribute Information:\n",
        "\n",
        "1) ID number\n",
        "\n",
        "2) Diagnosis (M = malignant, B = benign)\n",
        "\n",
        "3 to 32)\n",
        "\n",
        "Ten real-valued features are computed for each cell nucleus:\n",
        "\n",
        "* a) radius (mean of distances from center to points on the perimeter)\n",
        "* b) texture (standard deviation of gray-scale values)\n",
        "* c) perimeter\n",
        "* d) area\n",
        "* e) smoothness (local variation in radius lengths)\n",
        "* f) compactness (perimeter^2 / area - 1.0)\n",
        "* g) concavity (severity of concave portions of the contour)\n",
        "* h) concave points (number of concave portions of the contour)\n",
        "* i) symmetry\n",
        "* j) fractal dimension (\"coastline approximation\" - 1)\n",
        "\n",
        "The mean, standard error and \"worst\" or largest (mean of the three\n",
        "largest values) of these features were computed for each image,\n",
        "resulting in 30 features. For instance, field 3 is Mean Radius, field\n",
        "13 is Radius SE, field 23 is Worst Radius.\n",
        "\n",
        "All feature values are recoded with four significant digits.\n",
        "\n",
        "Missing attribute values: none\n",
        "\n",
        "Class distribution: 357 benign, 212 malignant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qm6WAqNPRRu"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyKWchKWIvPi"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwexIqp8I_lF"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLF5xucumaai"
      },
      "source": [
        "downloaded = drive.CreateFile({'id':\"1igyRhO_Vugc0WD_bop9WUqX61Q4BJYBg\"})\n",
        "downloaded.GetContentFile('data.csv')  "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpxch0eIm2D3"
      },
      "source": [
        "# Create pandas dataframe\n",
        "data = pd.read_csv('data.csv')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEGGgoy6nD4w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "598464cd-b4a0-4c9f-9668-01c4d3fef78c"
      },
      "source": [
        "# Let's look at the data\n",
        "data"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>926424</td>\n",
              "      <td>M</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>926682</td>\n",
              "      <td>M</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>926954</td>\n",
              "      <td>M</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>927241</td>\n",
              "      <td>M</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>92751</td>\n",
              "      <td>B</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0      842302         M  ...                  0.11890          NaN\n",
              "1      842517         M  ...                  0.08902          NaN\n",
              "2    84300903         M  ...                  0.08758          NaN\n",
              "3    84348301         M  ...                  0.17300          NaN\n",
              "4    84358402         M  ...                  0.07678          NaN\n",
              "..        ...       ...  ...                      ...          ...\n",
              "564    926424         M  ...                  0.07115          NaN\n",
              "565    926682         M  ...                  0.06637          NaN\n",
              "566    926954         M  ...                  0.07820          NaN\n",
              "567    927241         M  ...                  0.12400          NaN\n",
              "568     92751         B  ...                  0.07039          NaN\n",
              "\n",
              "[569 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8birwmMhNxqx"
      },
      "source": [
        "# drop Unnamed: 32 column\n",
        "data = data.iloc[:,0:-1]\n",
        "\n",
        "#drop the id column\n",
        "data = data.iloc[:,1:]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Roig66zZ4z3B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "f7f715ec-d9ce-4e55-aa53-a89ebde915f0"
      },
      "source": [
        "# Let's check the data again\n",
        "data"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>M</td>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>M</td>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>M</td>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>M</td>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>B</td>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    diagnosis  radius_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "0           M        17.99  ...          0.4601                  0.11890\n",
              "1           M        20.57  ...          0.2750                  0.08902\n",
              "2           M        19.69  ...          0.3613                  0.08758\n",
              "3           M        11.42  ...          0.6638                  0.17300\n",
              "4           M        20.29  ...          0.2364                  0.07678\n",
              "..        ...          ...  ...             ...                      ...\n",
              "564         M        21.56  ...          0.2060                  0.07115\n",
              "565         M        20.13  ...          0.2572                  0.06637\n",
              "566         M        16.60  ...          0.2218                  0.07820\n",
              "567         M        20.60  ...          0.4087                  0.12400\n",
              "568         B         7.76  ...          0.2871                  0.07039\n",
              "\n",
              "[569 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PRmp0GI2nOi"
      },
      "source": [
        "### a) Converting Categorical Data to Numeric Values (5 points)\n",
        "\n",
        "The diagnosis column has categorical values 'B' if a tumor is benign, and 'M' if it is malignant. Convert these values to 0 for 'B' and 1 for 'M'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0vh80Yc2nOj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f9e7de3-f55e-4168-c7a8-f73e9eac552b"
      },
      "source": [
        "### YOUR CODE HERE ###\n",
        "data[\"diagnosis\"] = data[\"diagnosis\"].replace(to_replace=\"M\", value=1)\n",
        "data[\"diagnosis\"] = data[\"diagnosis\"].replace(to_replace=\"B\", value=0)\n",
        "data[\"diagnosis\"]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1\n",
              "1      1\n",
              "2      1\n",
              "3      1\n",
              "4      1\n",
              "      ..\n",
              "564    1\n",
              "565    1\n",
              "566    1\n",
              "567    1\n",
              "568    0\n",
              "Name: diagnosis, Length: 569, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zsToX3tPahn"
      },
      "source": [
        "### b) Run Logistic Regression (10 points)\n",
        "Divide your data into feature set X which contains the following variables:\n",
        "* radius_mean\t\n",
        "* texture_mean\t\n",
        "* perimeter_mean\tarea_mean\t\n",
        "* smoothness_mean\t\n",
        "* compactness_mean\n",
        "* concavity_mean\t\n",
        "* concave points_mean\t\n",
        "* symmetry_mean\t\n",
        "* fractal_dimension_mean\tradius_se\t\n",
        "* texture_se\tperimeter_se\t\n",
        "* area_se\t\n",
        "* smoothness_se\t\n",
        "* compactness_se\t\n",
        "* concavity_se\t\n",
        "* concave points_se\t\n",
        "* symmetry_se\t\n",
        "* fractal_dimension_se\t\n",
        "* radius_worst\t\n",
        "* texture_worst\t\n",
        "* perimeter_worst\t\n",
        "* area_worst\tsmoothness_worst\t\n",
        "* compactness_worst\t\n",
        "* concavity_worst\t\n",
        "* concave points_worst\t\n",
        "* symmetry_worst\t\n",
        "* fractal_dimension_worst\n",
        "\n",
        "and labels y which contains the diagnosis column. Then divide your data into 75% training set data and 25% test set data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8e_w2-rRtED"
      },
      "source": [
        "# Split data into X and y\n",
        "col_lst = [\"radius_mean\",\n",
        "\"texture_mean\",\n",
        "\"perimeter_mean\", \n",
        "\"area_mean\",\n",
        "\"smoothness_mean\",\n",
        "\"compactness_mean\",\n",
        "\"concavity_mean\",\n",
        "\"concave points_mean\",\n",
        "\"symmetry_mean\",\n",
        "\"fractal_dimension_mean\", \n",
        "\"radius_se\",\n",
        "\"texture_se\",\n",
        "\"perimeter_se\",\n",
        "\"area_se\",\n",
        "\"smoothness_se\",\n",
        "\"compactness_se\",\n",
        "\"concavity_se\",\n",
        "\"concave points_se\",\n",
        "\"symmetry_se\",\n",
        "\"fractal_dimension_se\",\n",
        "\"radius_worst\",\n",
        "\"texture_worst\",\n",
        "\"perimeter_worst\",\n",
        "\"area_worst\",\n",
        "\"smoothness_worst\",\n",
        "\"compactness_worst\",\n",
        "\"concavity_worst\",\n",
        "\"concave points_worst\",\n",
        "\"symmetry_worst\",\n",
        "\"fractal_dimension_worst\"] \n",
        "X = data[col_lst]\n",
        "y = data[\"diagnosis\"]\n",
        "\n",
        "# Split X and y into X_train, y_train, X_test, y_test using train_test_split()\n",
        "### YOUR CODE HERE ###\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=144)\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHlyB20UPqQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fddd5bd3-bcfc-4370-c397-c55d363d63c4"
      },
      "source": [
        "# instantiate LinearRegression\n",
        "clf = LogisticRegression(random_state=144)\n",
        "\n",
        "\n",
        "# Fit the regressor using X_train and y_train\n",
        "### YOUR CODE HERE ###\n",
        "clf.fit(X_train, y_train)\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=144, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlmjRX-FV6Fa"
      },
      "source": [
        "### c) Classification accuracy for the training and test sets (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfwZS4CJWNrT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7edcee60-3de1-4d69-ebf3-d2a16d254ecf"
      },
      "source": [
        "# Generate predictions using X_train\n",
        "### YOUR CODE HERE ###\n",
        "y_train_pred = clf.predict(X_train)\n",
        "# Calculate the classification accuracy for the training set\n",
        "### YOUR CODE HERE ###\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Classification accuracy for training set: \", accuracy_score(y_train, y_train_pred))\n",
        "\n",
        "\n",
        "# Generate predictions using X_test\n",
        "### YOUR CODE HERE ###\n",
        "y_test_pred = clf.predict(X_test)\n",
        "# Calculate the classification accuracy for the test set\n",
        "### YOUR CODE HERE ###\n",
        "print(\"Classification accuracy for test set: \", accuracy_score(y_test, y_test_pred))\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification accuracy for training set:  0.931924882629108\n",
            "Classification accuracy for test set:  0.9790209790209791\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56vnLVWyU83B"
      },
      "source": [
        "### d) False Positives, False Negatives, True Positives, True Negatives (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luz4lriJdESy"
      },
      "source": [
        "In binary classification, A **false positive** (FP) is an outcome where the model incorrectly predicts the positive class. And a **false negative** (FN) is an outcome where the model incorrectly predicts the negative class. Likewise, a **true positive** (TP) is an outcome where the model correctly predicts a positive class. A **true negative** (TN) is an outcome where the model correctly predicts the negative class.\n",
        "\n",
        "Calculate the number of FPs, FNs, TPs,and TNs using the test set predictions and test set labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLFPG2AbhGj0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "341b1176-22d4-4c67-9c6f-419432b65df7"
      },
      "source": [
        "# Calculate the number of false positives using the test set predictions and test set labels.\n",
        "### YOUR CODE HERE ###\n",
        "fp = 0\n",
        "fn = 0\n",
        "tn = 0\n",
        "tp = 0\n",
        "for i in range(len(y_test_pred)):\n",
        "  if y_test_pred[i]==1 and y_test.values[i]!= y_test_pred[i]:\n",
        "    fp += 1\n",
        "# Calculate the number of false negatives using the test set predictions and test set labels.\n",
        "### YOUR CODE HERE ###\n",
        "  if y_test_pred[i]==0 and y_test.values[i]!= y_test_pred[i]:\n",
        "    fn += 1\n",
        "#Calculate the number of true positives using the test set predictions and test set labels.\n",
        "### YOUR CODE HERE ###\n",
        "  if y_test.values[i]== y_test_pred[i]==1:\n",
        "    tp += 1\n",
        "#Calculate the number of true negatives using the test set predictions and test set labels.\n",
        "### YOUR CODE HERE ###\n",
        "  if y_test.values[i]== y_test_pred[i]==0:\n",
        "    tn += 1\n",
        "print(\"Number of false positives(FP): \", fp)\n",
        "print(\"Number of false negatives(FN): \", fn)\n",
        "print(\"Number of true positives(TP): \", tp)\n",
        "print(\"Number of true negatives(TN): \", tn)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of false positives(FP):  2\n",
            "Number of false negatives(FN):  1\n",
            "Number of true positives(TP):  49\n",
            "Number of true negatives(TN):  91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-p_GEkAbjYHv"
      },
      "source": [
        "### e) Precision and Recall (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0xed4wIjcmn"
      },
      "source": [
        "Two important statistics used to analyze the performance of classification models are precision and recall. **precision** (also called positive predictive value) is proportion of positive identifications that were actually correct, while **recall** (also known as sensitivity) is the proportion of actual positives that were identified correctly.\n",
        "\n",
        "Precision can be calculated as:\n",
        "$$Precision = \\frac{TP}{TP+FP}$$\n",
        "\n",
        "Recall can be calculated as:\n",
        "$$Recall = \\frac{TP}{TP+FN}$$\n",
        "\n",
        "For more info: https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THYqeYZ5o_lE"
      },
      "source": [
        "Use your answer from part d) to calculate Precision:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMym2_FYpM3u"
      },
      "source": [
        "precision = 49/(49+2) = 0.960"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTdTM4vmpMxc"
      },
      "source": [
        "User your answer from part d) to calculate Recall:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5gUHq9MpbVG"
      },
      "source": [
        "recall = 49/(49+1) = 0.98"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZITT5VUttzO"
      },
      "source": [
        "## Problem 3 - Neural Network For Classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMCxB72z-kC9"
      },
      "source": [
        "### a) Training a simply neural network for classification (5 points)\n",
        "Complete the following code segments to create a NN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt7K04ckhK1v"
      },
      "source": [
        "# import Keras from TensorFlow\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1Ekoez3ciwE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "f1c71979-3fc3-414b-d15d-3c9f4ab6d2c1"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets.samples_generator import make_moons\n",
        "from pylab import rcParams\n",
        "\n",
        "# Create the training data\n",
        "np.random.seed(42) \n",
        "data, labels = make_moons(n_samples=500, noise=0.1)\n",
        "colors = ['r' if y else 'b' for y in labels]\n",
        "print('data.shape =', data.shape)\n",
        "print('labels.shape =', labels.shape)\n",
        "plt.scatter(data[:,0], data[:,1], c=colors)\n",
        "plt.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data.shape = (500, 2)\n",
            "labels.shape = (500,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tW6XzU_IciwH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "957b2f73-ea92-45ae-dd2b-de880244145c"
      },
      "source": [
        "# Create and plot the test data\n",
        "np.random.seed(17)   \n",
        "test_data, test_labels = make_moons(n_samples=500, noise=0.1)\n",
        "colors = ['r' if y else 'b' for y in test_labels]\n",
        "print('test_data.shape =', test_data.shape)\n",
        "print('test_labels.shape =', test_labels.shape)\n",
        "plt.scatter(test_data[:,0], test_data[:,1], c=colors)\n",
        "plt.show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_data.shape = (500, 2)\n",
            "test_labels.shape = (500,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ1Coz15ciwJ"
      },
      "source": [
        "The above image is created by sampling from the same distribution as before. But these are entirely different points than your model was trained on.  So how our model performs on this test data will be a good indication of our model's ability to generalize.\n",
        "\n",
        " In the cell below, construct a simple neural network with 5 layers as follows:\n",
        "* **input layer** of shape 5\n",
        "* **dense layer** with 10 neurons, and relu activation\n",
        "* **dense layer** with 4 neurons, and relu activation\n",
        "* **dense layer** with 3 neurons, and relu activation\n",
        "* **dense layer** with 1 neuron, and sigmoid activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRRrqpb1ciwK"
      },
      "source": [
        "def build_model1():\n",
        "    ### YOUR CODE HERE ###\n",
        "    input_layer = Input(shape=2)\n",
        "    x = Dense(10, activation=\"relu\")(input_layer)\n",
        "    x = Dense(4, activation=\"relu\")(x)\n",
        "    x = Dense(3, activation=\"relu\")(x)\n",
        "    x = Dense(1, activation=\"sigmoid\")(x)\n",
        "    return Model(input_layer, x)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k6KzH-yXOAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7684651-62af-489a-ace3-e12124800547"
      },
      "source": [
        "# Get model summary\n",
        "model = build_model1()\n",
        "model.summary()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                30        \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 4)                 44        \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 3)                 15        \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 4         \n",
            "=================================================================\n",
            "Total params: 93\n",
            "Trainable params: 93\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PROyV-LvciwL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4a66205-fc1b-460e-8444-3439fbd4f08d"
      },
      "source": [
        "# Compile the NN model, defining the optimizer to use (sgd), the loss function (binary_crossentropy), and the metrics (acc) to use.\n",
        "# These settings are appropriate for a binary classification task.\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "# Train the model (obviously on the training data), iterating on the data in batches of 32 samples for 300 epochs. Have a validation_split of 0.2.\n",
        "history = model.fit(data,\n",
        "                    labels,\n",
        "                    epochs=300,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "train_loss, train_acc = model.evaluate(data, labels)\n",
        "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
        "\n",
        "print('Training set accuracy:', train_acc)\n",
        "print('Test set accuracy:', test_acc)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "13/13 [==============================] - 1s 14ms/step - loss: 0.6846 - accuracy: 0.5525 - val_loss: 0.6794 - val_accuracy: 0.5600\n",
            "Epoch 2/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.6800 - accuracy: 0.5600 - val_loss: 0.6752 - val_accuracy: 0.5600\n",
            "Epoch 3/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6757 - accuracy: 0.5725 - val_loss: 0.6721 - val_accuracy: 0.6700\n",
            "Epoch 4/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6730 - accuracy: 0.6875 - val_loss: 0.6700 - val_accuracy: 0.7400\n",
            "Epoch 5/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.6709 - accuracy: 0.7400 - val_loss: 0.6682 - val_accuracy: 0.7300\n",
            "Epoch 6/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6689 - accuracy: 0.7375 - val_loss: 0.6663 - val_accuracy: 0.7200\n",
            "Epoch 7/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6671 - accuracy: 0.7375 - val_loss: 0.6643 - val_accuracy: 0.7200\n",
            "Epoch 8/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6651 - accuracy: 0.7375 - val_loss: 0.6622 - val_accuracy: 0.7200\n",
            "Epoch 9/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.6630 - accuracy: 0.7400 - val_loss: 0.6600 - val_accuracy: 0.7200\n",
            "Epoch 10/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6609 - accuracy: 0.7375 - val_loss: 0.6579 - val_accuracy: 0.7200\n",
            "Epoch 11/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.6586 - accuracy: 0.7375 - val_loss: 0.6554 - val_accuracy: 0.7200\n",
            "Epoch 12/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.6561 - accuracy: 0.7375 - val_loss: 0.6528 - val_accuracy: 0.7200\n",
            "Epoch 13/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.6536 - accuracy: 0.7400 - val_loss: 0.6500 - val_accuracy: 0.7200\n",
            "Epoch 14/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6508 - accuracy: 0.7425 - val_loss: 0.6471 - val_accuracy: 0.7200\n",
            "Epoch 15/300\n",
            "13/13 [==============================] - 0s 13ms/step - loss: 0.6480 - accuracy: 0.7425 - val_loss: 0.6442 - val_accuracy: 0.7200\n",
            "Epoch 16/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.6450 - accuracy: 0.7450 - val_loss: 0.6410 - val_accuracy: 0.7200\n",
            "Epoch 17/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.6418 - accuracy: 0.7500 - val_loss: 0.6375 - val_accuracy: 0.7200\n",
            "Epoch 18/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.6384 - accuracy: 0.7475 - val_loss: 0.6340 - val_accuracy: 0.7200\n",
            "Epoch 19/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6349 - accuracy: 0.7475 - val_loss: 0.6300 - val_accuracy: 0.7200\n",
            "Epoch 20/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.6311 - accuracy: 0.7500 - val_loss: 0.6257 - val_accuracy: 0.7200\n",
            "Epoch 21/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6269 - accuracy: 0.7500 - val_loss: 0.6213 - val_accuracy: 0.7200\n",
            "Epoch 22/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6227 - accuracy: 0.7525 - val_loss: 0.6167 - val_accuracy: 0.7200\n",
            "Epoch 23/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6183 - accuracy: 0.7500 - val_loss: 0.6121 - val_accuracy: 0.7200\n",
            "Epoch 24/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.6140 - accuracy: 0.7550 - val_loss: 0.6073 - val_accuracy: 0.7200\n",
            "Epoch 25/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.6094 - accuracy: 0.7525 - val_loss: 0.6023 - val_accuracy: 0.7200\n",
            "Epoch 26/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.6046 - accuracy: 0.7525 - val_loss: 0.5971 - val_accuracy: 0.7200\n",
            "Epoch 27/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.5997 - accuracy: 0.7550 - val_loss: 0.5919 - val_accuracy: 0.7200\n",
            "Epoch 28/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.7575 - val_loss: 0.5865 - val_accuracy: 0.7300\n",
            "Epoch 29/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5897 - accuracy: 0.7575 - val_loss: 0.5812 - val_accuracy: 0.7300\n",
            "Epoch 30/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5846 - accuracy: 0.7600 - val_loss: 0.5757 - val_accuracy: 0.7300\n",
            "Epoch 31/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5796 - accuracy: 0.7600 - val_loss: 0.5703 - val_accuracy: 0.7300\n",
            "Epoch 32/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.5745 - accuracy: 0.7625 - val_loss: 0.5649 - val_accuracy: 0.7300\n",
            "Epoch 33/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5694 - accuracy: 0.7625 - val_loss: 0.5596 - val_accuracy: 0.7300\n",
            "Epoch 34/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.7625 - val_loss: 0.5542 - val_accuracy: 0.7300\n",
            "Epoch 35/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.7625 - val_loss: 0.5489 - val_accuracy: 0.7300\n",
            "Epoch 36/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5547 - accuracy: 0.7625 - val_loss: 0.5440 - val_accuracy: 0.7300\n",
            "Epoch 37/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.7650 - val_loss: 0.5392 - val_accuracy: 0.7300\n",
            "Epoch 38/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7650 - val_loss: 0.5344 - val_accuracy: 0.7400\n",
            "Epoch 39/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7625 - val_loss: 0.5295 - val_accuracy: 0.7400\n",
            "Epoch 40/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.7650 - val_loss: 0.5250 - val_accuracy: 0.7400\n",
            "Epoch 41/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7650 - val_loss: 0.5205 - val_accuracy: 0.7400\n",
            "Epoch 42/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5281 - accuracy: 0.7650 - val_loss: 0.5163 - val_accuracy: 0.7400\n",
            "Epoch 43/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.7700 - val_loss: 0.5118 - val_accuracy: 0.7400\n",
            "Epoch 44/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5200 - accuracy: 0.7700 - val_loss: 0.5076 - val_accuracy: 0.7500\n",
            "Epoch 45/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7725 - val_loss: 0.5034 - val_accuracy: 0.7500\n",
            "Epoch 46/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7725 - val_loss: 0.4995 - val_accuracy: 0.7500\n",
            "Epoch 47/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7775 - val_loss: 0.4960 - val_accuracy: 0.7500\n",
            "Epoch 48/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.7800 - val_loss: 0.4924 - val_accuracy: 0.7500\n",
            "Epoch 49/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.5012 - accuracy: 0.7875 - val_loss: 0.4885 - val_accuracy: 0.7500\n",
            "Epoch 50/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4977 - accuracy: 0.7875 - val_loss: 0.4850 - val_accuracy: 0.7500\n",
            "Epoch 51/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7900 - val_loss: 0.4815 - val_accuracy: 0.7500\n",
            "Epoch 52/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.7925 - val_loss: 0.4782 - val_accuracy: 0.7600\n",
            "Epoch 53/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4873 - accuracy: 0.7950 - val_loss: 0.4748 - val_accuracy: 0.7600\n",
            "Epoch 54/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.8025 - val_loss: 0.4718 - val_accuracy: 0.7700\n",
            "Epoch 55/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.8025 - val_loss: 0.4685 - val_accuracy: 0.7700\n",
            "Epoch 56/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.8025 - val_loss: 0.4659 - val_accuracy: 0.7700\n",
            "Epoch 57/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.8025 - val_loss: 0.4626 - val_accuracy: 0.7700\n",
            "Epoch 58/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.8025 - val_loss: 0.4593 - val_accuracy: 0.7700\n",
            "Epoch 59/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.8050 - val_loss: 0.4563 - val_accuracy: 0.7700\n",
            "Epoch 60/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.8075 - val_loss: 0.4536 - val_accuracy: 0.7900\n",
            "Epoch 61/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.8100 - val_loss: 0.4508 - val_accuracy: 0.8000\n",
            "Epoch 62/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.8125 - val_loss: 0.4478 - val_accuracy: 0.8000\n",
            "Epoch 63/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.8150 - val_loss: 0.4449 - val_accuracy: 0.8000\n",
            "Epoch 64/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.8150 - val_loss: 0.4422 - val_accuracy: 0.8000\n",
            "Epoch 65/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.4498 - accuracy: 0.8150 - val_loss: 0.4394 - val_accuracy: 0.8000\n",
            "Epoch 66/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.4470 - accuracy: 0.8150 - val_loss: 0.4365 - val_accuracy: 0.8100\n",
            "Epoch 67/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.4441 - accuracy: 0.8175 - val_loss: 0.4339 - val_accuracy: 0.8100\n",
            "Epoch 68/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.4415 - accuracy: 0.8175 - val_loss: 0.4314 - val_accuracy: 0.8100\n",
            "Epoch 69/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.8200 - val_loss: 0.4291 - val_accuracy: 0.8100\n",
            "Epoch 70/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.8200 - val_loss: 0.4266 - val_accuracy: 0.8100\n",
            "Epoch 71/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.8225 - val_loss: 0.4247 - val_accuracy: 0.8300\n",
            "Epoch 72/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.8225 - val_loss: 0.4223 - val_accuracy: 0.8300\n",
            "Epoch 73/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.8225 - val_loss: 0.4202 - val_accuracy: 0.8400\n",
            "Epoch 74/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.8225 - val_loss: 0.4176 - val_accuracy: 0.8400\n",
            "Epoch 75/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.8225 - val_loss: 0.4151 - val_accuracy: 0.8400\n",
            "Epoch 76/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.8225 - val_loss: 0.4128 - val_accuracy: 0.8500\n",
            "Epoch 77/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8225 - val_loss: 0.4110 - val_accuracy: 0.8500\n",
            "Epoch 78/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.8225 - val_loss: 0.4085 - val_accuracy: 0.8500\n",
            "Epoch 79/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4136 - accuracy: 0.8225 - val_loss: 0.4062 - val_accuracy: 0.8500\n",
            "Epoch 80/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4112 - accuracy: 0.8225 - val_loss: 0.4043 - val_accuracy: 0.8500\n",
            "Epoch 81/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.8250 - val_loss: 0.4019 - val_accuracy: 0.8500\n",
            "Epoch 82/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8250 - val_loss: 0.3998 - val_accuracy: 0.8500\n",
            "Epoch 83/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.4043 - accuracy: 0.8250 - val_loss: 0.3979 - val_accuracy: 0.8500\n",
            "Epoch 84/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.4020 - accuracy: 0.8275 - val_loss: 0.3958 - val_accuracy: 0.8500\n",
            "Epoch 85/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.8300 - val_loss: 0.3939 - val_accuracy: 0.8500\n",
            "Epoch 86/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3974 - accuracy: 0.8300 - val_loss: 0.3921 - val_accuracy: 0.8500\n",
            "Epoch 87/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.3953 - accuracy: 0.8300 - val_loss: 0.3897 - val_accuracy: 0.8500\n",
            "Epoch 88/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.3930 - accuracy: 0.8300 - val_loss: 0.3874 - val_accuracy: 0.8500\n",
            "Epoch 89/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.3910 - accuracy: 0.8300 - val_loss: 0.3853 - val_accuracy: 0.8500\n",
            "Epoch 90/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8300 - val_loss: 0.3835 - val_accuracy: 0.8500\n",
            "Epoch 91/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8300 - val_loss: 0.3814 - val_accuracy: 0.8500\n",
            "Epoch 92/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3848 - accuracy: 0.8300 - val_loss: 0.3795 - val_accuracy: 0.8500\n",
            "Epoch 93/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8300 - val_loss: 0.3771 - val_accuracy: 0.8500\n",
            "Epoch 94/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3808 - accuracy: 0.8300 - val_loss: 0.3755 - val_accuracy: 0.8500\n",
            "Epoch 95/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3787 - accuracy: 0.8300 - val_loss: 0.3738 - val_accuracy: 0.8500\n",
            "Epoch 96/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3767 - accuracy: 0.8300 - val_loss: 0.3722 - val_accuracy: 0.8500\n",
            "Epoch 97/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3748 - accuracy: 0.8300 - val_loss: 0.3706 - val_accuracy: 0.8500\n",
            "Epoch 98/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3729 - accuracy: 0.8300 - val_loss: 0.3691 - val_accuracy: 0.8500\n",
            "Epoch 99/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3709 - accuracy: 0.8325 - val_loss: 0.3670 - val_accuracy: 0.8500\n",
            "Epoch 100/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3688 - accuracy: 0.8350 - val_loss: 0.3655 - val_accuracy: 0.8500\n",
            "Epoch 101/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3670 - accuracy: 0.8375 - val_loss: 0.3639 - val_accuracy: 0.8500\n",
            "Epoch 102/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3651 - accuracy: 0.8375 - val_loss: 0.3621 - val_accuracy: 0.8500\n",
            "Epoch 103/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.3629 - accuracy: 0.8375 - val_loss: 0.3604 - val_accuracy: 0.8500\n",
            "Epoch 104/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.8375 - val_loss: 0.3587 - val_accuracy: 0.8500\n",
            "Epoch 105/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.8375 - val_loss: 0.3567 - val_accuracy: 0.8500\n",
            "Epoch 106/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8375 - val_loss: 0.3550 - val_accuracy: 0.8500\n",
            "Epoch 107/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3555 - accuracy: 0.8375 - val_loss: 0.3540 - val_accuracy: 0.8500\n",
            "Epoch 108/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3536 - accuracy: 0.8400 - val_loss: 0.3525 - val_accuracy: 0.8500\n",
            "Epoch 109/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.3518 - accuracy: 0.8425 - val_loss: 0.3514 - val_accuracy: 0.8500\n",
            "Epoch 110/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.3501 - accuracy: 0.8450 - val_loss: 0.3499 - val_accuracy: 0.8500\n",
            "Epoch 111/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.3483 - accuracy: 0.8450 - val_loss: 0.3480 - val_accuracy: 0.8500\n",
            "Epoch 112/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3465 - accuracy: 0.8450 - val_loss: 0.3462 - val_accuracy: 0.8500\n",
            "Epoch 113/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3447 - accuracy: 0.8475 - val_loss: 0.3450 - val_accuracy: 0.8500\n",
            "Epoch 114/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3428 - accuracy: 0.8500 - val_loss: 0.3431 - val_accuracy: 0.8500\n",
            "Epoch 115/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3412 - accuracy: 0.8475 - val_loss: 0.3419 - val_accuracy: 0.8500\n",
            "Epoch 116/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3395 - accuracy: 0.8500 - val_loss: 0.3406 - val_accuracy: 0.8500\n",
            "Epoch 117/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3379 - accuracy: 0.8500 - val_loss: 0.3389 - val_accuracy: 0.8500\n",
            "Epoch 118/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.8500 - val_loss: 0.3371 - val_accuracy: 0.8500\n",
            "Epoch 119/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.3346 - accuracy: 0.8525 - val_loss: 0.3362 - val_accuracy: 0.8500\n",
            "Epoch 120/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3330 - accuracy: 0.8525 - val_loss: 0.3350 - val_accuracy: 0.8500\n",
            "Epoch 121/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.3313 - accuracy: 0.8525 - val_loss: 0.3332 - val_accuracy: 0.8500\n",
            "Epoch 122/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3296 - accuracy: 0.8550 - val_loss: 0.3320 - val_accuracy: 0.8500\n",
            "Epoch 123/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3281 - accuracy: 0.8550 - val_loss: 0.3304 - val_accuracy: 0.8500\n",
            "Epoch 124/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8550 - val_loss: 0.3286 - val_accuracy: 0.8500\n",
            "Epoch 125/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3249 - accuracy: 0.8575 - val_loss: 0.3276 - val_accuracy: 0.8500\n",
            "Epoch 126/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3234 - accuracy: 0.8575 - val_loss: 0.3267 - val_accuracy: 0.8500\n",
            "Epoch 127/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3217 - accuracy: 0.8575 - val_loss: 0.3255 - val_accuracy: 0.8500\n",
            "Epoch 128/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8575 - val_loss: 0.3254 - val_accuracy: 0.8500\n",
            "Epoch 129/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3186 - accuracy: 0.8550 - val_loss: 0.3231 - val_accuracy: 0.8500\n",
            "Epoch 130/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3171 - accuracy: 0.8550 - val_loss: 0.3215 - val_accuracy: 0.8500\n",
            "Epoch 131/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3156 - accuracy: 0.8575 - val_loss: 0.3207 - val_accuracy: 0.8500\n",
            "Epoch 132/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.8575 - val_loss: 0.3195 - val_accuracy: 0.8500\n",
            "Epoch 133/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3126 - accuracy: 0.8575 - val_loss: 0.3185 - val_accuracy: 0.8500\n",
            "Epoch 134/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.3113 - accuracy: 0.8575 - val_loss: 0.3176 - val_accuracy: 0.8500\n",
            "Epoch 135/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3099 - accuracy: 0.8575 - val_loss: 0.3163 - val_accuracy: 0.8500\n",
            "Epoch 136/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3084 - accuracy: 0.8600 - val_loss: 0.3145 - val_accuracy: 0.8500\n",
            "Epoch 137/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.3070 - accuracy: 0.8625 - val_loss: 0.3133 - val_accuracy: 0.8500\n",
            "Epoch 138/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3058 - accuracy: 0.8575 - val_loss: 0.3123 - val_accuracy: 0.8500\n",
            "Epoch 139/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3045 - accuracy: 0.8600 - val_loss: 0.3118 - val_accuracy: 0.8500\n",
            "Epoch 140/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3033 - accuracy: 0.8625 - val_loss: 0.3116 - val_accuracy: 0.8500\n",
            "Epoch 141/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3019 - accuracy: 0.8625 - val_loss: 0.3100 - val_accuracy: 0.8500\n",
            "Epoch 142/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.3006 - accuracy: 0.8625 - val_loss: 0.3087 - val_accuracy: 0.8500\n",
            "Epoch 143/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2994 - accuracy: 0.8625 - val_loss: 0.3077 - val_accuracy: 0.8500\n",
            "Epoch 144/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2982 - accuracy: 0.8625 - val_loss: 0.3070 - val_accuracy: 0.8500\n",
            "Epoch 145/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.2969 - accuracy: 0.8625 - val_loss: 0.3054 - val_accuracy: 0.8500\n",
            "Epoch 146/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2957 - accuracy: 0.8650 - val_loss: 0.3052 - val_accuracy: 0.8600\n",
            "Epoch 147/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.2946 - accuracy: 0.8625 - val_loss: 0.3039 - val_accuracy: 0.8600\n",
            "Epoch 148/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2935 - accuracy: 0.8650 - val_loss: 0.3028 - val_accuracy: 0.8700\n",
            "Epoch 149/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2923 - accuracy: 0.8675 - val_loss: 0.3018 - val_accuracy: 0.8700\n",
            "Epoch 150/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2913 - accuracy: 0.8725 - val_loss: 0.3012 - val_accuracy: 0.8700\n",
            "Epoch 151/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2900 - accuracy: 0.8725 - val_loss: 0.2997 - val_accuracy: 0.8700\n",
            "Epoch 152/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2889 - accuracy: 0.8750 - val_loss: 0.2985 - val_accuracy: 0.8700\n",
            "Epoch 153/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2878 - accuracy: 0.8725 - val_loss: 0.2976 - val_accuracy: 0.8700\n",
            "Epoch 154/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2867 - accuracy: 0.8725 - val_loss: 0.2966 - val_accuracy: 0.8700\n",
            "Epoch 155/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2859 - accuracy: 0.8775 - val_loss: 0.2962 - val_accuracy: 0.8700\n",
            "Epoch 156/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2847 - accuracy: 0.8750 - val_loss: 0.2951 - val_accuracy: 0.8600\n",
            "Epoch 157/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2835 - accuracy: 0.8750 - val_loss: 0.2941 - val_accuracy: 0.8600\n",
            "Epoch 158/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2825 - accuracy: 0.8750 - val_loss: 0.2939 - val_accuracy: 0.8600\n",
            "Epoch 159/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2815 - accuracy: 0.8775 - val_loss: 0.2934 - val_accuracy: 0.8600\n",
            "Epoch 160/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2804 - accuracy: 0.8800 - val_loss: 0.2923 - val_accuracy: 0.8600\n",
            "Epoch 161/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2794 - accuracy: 0.8800 - val_loss: 0.2918 - val_accuracy: 0.8600\n",
            "Epoch 162/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2784 - accuracy: 0.8800 - val_loss: 0.2904 - val_accuracy: 0.8600\n",
            "Epoch 163/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2776 - accuracy: 0.8825 - val_loss: 0.2898 - val_accuracy: 0.8600\n",
            "Epoch 164/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2764 - accuracy: 0.8800 - val_loss: 0.2890 - val_accuracy: 0.8600\n",
            "Epoch 165/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2755 - accuracy: 0.8825 - val_loss: 0.2872 - val_accuracy: 0.8600\n",
            "Epoch 166/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2745 - accuracy: 0.8825 - val_loss: 0.2859 - val_accuracy: 0.8600\n",
            "Epoch 167/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2735 - accuracy: 0.8800 - val_loss: 0.2862 - val_accuracy: 0.8600\n",
            "Epoch 168/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2726 - accuracy: 0.8825 - val_loss: 0.2857 - val_accuracy: 0.8600\n",
            "Epoch 169/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2715 - accuracy: 0.8850 - val_loss: 0.2854 - val_accuracy: 0.8600\n",
            "Epoch 170/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2709 - accuracy: 0.8875 - val_loss: 0.2862 - val_accuracy: 0.8600\n",
            "Epoch 171/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2694 - accuracy: 0.8900 - val_loss: 0.2852 - val_accuracy: 0.8600\n",
            "Epoch 172/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2686 - accuracy: 0.8875 - val_loss: 0.2848 - val_accuracy: 0.8600\n",
            "Epoch 173/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2676 - accuracy: 0.8875 - val_loss: 0.2842 - val_accuracy: 0.8600\n",
            "Epoch 174/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2665 - accuracy: 0.8875 - val_loss: 0.2824 - val_accuracy: 0.8600\n",
            "Epoch 175/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2657 - accuracy: 0.8900 - val_loss: 0.2818 - val_accuracy: 0.8700\n",
            "Epoch 176/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2648 - accuracy: 0.8875 - val_loss: 0.2814 - val_accuracy: 0.8700\n",
            "Epoch 177/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2639 - accuracy: 0.8875 - val_loss: 0.2804 - val_accuracy: 0.8700\n",
            "Epoch 178/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2629 - accuracy: 0.8900 - val_loss: 0.2793 - val_accuracy: 0.8700\n",
            "Epoch 179/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2620 - accuracy: 0.8925 - val_loss: 0.2783 - val_accuracy: 0.8700\n",
            "Epoch 180/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2611 - accuracy: 0.8925 - val_loss: 0.2786 - val_accuracy: 0.8700\n",
            "Epoch 181/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2598 - accuracy: 0.8975 - val_loss: 0.2779 - val_accuracy: 0.8700\n",
            "Epoch 182/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2588 - accuracy: 0.8975 - val_loss: 0.2764 - val_accuracy: 0.8700\n",
            "Epoch 183/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2579 - accuracy: 0.8975 - val_loss: 0.2759 - val_accuracy: 0.8700\n",
            "Epoch 184/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2570 - accuracy: 0.8975 - val_loss: 0.2743 - val_accuracy: 0.8800\n",
            "Epoch 185/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2560 - accuracy: 0.8975 - val_loss: 0.2737 - val_accuracy: 0.8800\n",
            "Epoch 186/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2552 - accuracy: 0.8975 - val_loss: 0.2723 - val_accuracy: 0.8800\n",
            "Epoch 187/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2543 - accuracy: 0.9025 - val_loss: 0.2717 - val_accuracy: 0.8800\n",
            "Epoch 188/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2535 - accuracy: 0.9000 - val_loss: 0.2707 - val_accuracy: 0.8800\n",
            "Epoch 189/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2525 - accuracy: 0.9025 - val_loss: 0.2698 - val_accuracy: 0.8800\n",
            "Epoch 190/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2515 - accuracy: 0.9025 - val_loss: 0.2695 - val_accuracy: 0.8800\n",
            "Epoch 191/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.9025 - val_loss: 0.2690 - val_accuracy: 0.8800\n",
            "Epoch 192/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2496 - accuracy: 0.9025 - val_loss: 0.2685 - val_accuracy: 0.8800\n",
            "Epoch 193/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2486 - accuracy: 0.9025 - val_loss: 0.2676 - val_accuracy: 0.8800\n",
            "Epoch 194/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2476 - accuracy: 0.9050 - val_loss: 0.2672 - val_accuracy: 0.8800\n",
            "Epoch 195/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.9075 - val_loss: 0.2656 - val_accuracy: 0.8800\n",
            "Epoch 196/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2452 - accuracy: 0.9100 - val_loss: 0.2635 - val_accuracy: 0.8800\n",
            "Epoch 197/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2441 - accuracy: 0.9075 - val_loss: 0.2632 - val_accuracy: 0.8800\n",
            "Epoch 198/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2428 - accuracy: 0.9100 - val_loss: 0.2628 - val_accuracy: 0.8800\n",
            "Epoch 199/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2420 - accuracy: 0.9150 - val_loss: 0.2618 - val_accuracy: 0.8800\n",
            "Epoch 200/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2410 - accuracy: 0.9100 - val_loss: 0.2605 - val_accuracy: 0.8800\n",
            "Epoch 201/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2401 - accuracy: 0.9125 - val_loss: 0.2605 - val_accuracy: 0.8700\n",
            "Epoch 202/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2392 - accuracy: 0.9175 - val_loss: 0.2614 - val_accuracy: 0.8700\n",
            "Epoch 203/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2388 - accuracy: 0.9125 - val_loss: 0.2601 - val_accuracy: 0.8700\n",
            "Epoch 204/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2374 - accuracy: 0.9200 - val_loss: 0.2591 - val_accuracy: 0.8700\n",
            "Epoch 205/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2365 - accuracy: 0.9175 - val_loss: 0.2601 - val_accuracy: 0.8700\n",
            "Epoch 206/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2358 - accuracy: 0.9175 - val_loss: 0.2576 - val_accuracy: 0.8700\n",
            "Epoch 207/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2346 - accuracy: 0.9225 - val_loss: 0.2564 - val_accuracy: 0.8700\n",
            "Epoch 208/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2341 - accuracy: 0.9225 - val_loss: 0.2554 - val_accuracy: 0.8700\n",
            "Epoch 209/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2330 - accuracy: 0.9225 - val_loss: 0.2543 - val_accuracy: 0.8700\n",
            "Epoch 210/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2320 - accuracy: 0.9200 - val_loss: 0.2530 - val_accuracy: 0.8700\n",
            "Epoch 211/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2313 - accuracy: 0.9225 - val_loss: 0.2524 - val_accuracy: 0.8700\n",
            "Epoch 212/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2302 - accuracy: 0.9200 - val_loss: 0.2507 - val_accuracy: 0.8700\n",
            "Epoch 213/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2293 - accuracy: 0.9250 - val_loss: 0.2506 - val_accuracy: 0.8700\n",
            "Epoch 214/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2285 - accuracy: 0.9200 - val_loss: 0.2501 - val_accuracy: 0.8700\n",
            "Epoch 215/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2278 - accuracy: 0.9200 - val_loss: 0.2478 - val_accuracy: 0.8800\n",
            "Epoch 216/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2272 - accuracy: 0.9225 - val_loss: 0.2461 - val_accuracy: 0.8800\n",
            "Epoch 217/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2260 - accuracy: 0.9250 - val_loss: 0.2460 - val_accuracy: 0.8800\n",
            "Epoch 218/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2255 - accuracy: 0.9250 - val_loss: 0.2451 - val_accuracy: 0.8800\n",
            "Epoch 219/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2242 - accuracy: 0.9250 - val_loss: 0.2446 - val_accuracy: 0.8800\n",
            "Epoch 220/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2234 - accuracy: 0.9225 - val_loss: 0.2423 - val_accuracy: 0.8900\n",
            "Epoch 221/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2227 - accuracy: 0.9250 - val_loss: 0.2423 - val_accuracy: 0.8900\n",
            "Epoch 222/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2217 - accuracy: 0.9250 - val_loss: 0.2426 - val_accuracy: 0.8900\n",
            "Epoch 223/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2210 - accuracy: 0.9225 - val_loss: 0.2414 - val_accuracy: 0.8900\n",
            "Epoch 224/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2202 - accuracy: 0.9250 - val_loss: 0.2413 - val_accuracy: 0.8900\n",
            "Epoch 225/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2190 - accuracy: 0.9225 - val_loss: 0.2402 - val_accuracy: 0.8900\n",
            "Epoch 226/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2182 - accuracy: 0.9250 - val_loss: 0.2406 - val_accuracy: 0.8900\n",
            "Epoch 227/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2172 - accuracy: 0.9225 - val_loss: 0.2387 - val_accuracy: 0.8900\n",
            "Epoch 228/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2164 - accuracy: 0.9250 - val_loss: 0.2380 - val_accuracy: 0.8900\n",
            "Epoch 229/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2156 - accuracy: 0.9225 - val_loss: 0.2353 - val_accuracy: 0.8900\n",
            "Epoch 230/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2148 - accuracy: 0.9225 - val_loss: 0.2346 - val_accuracy: 0.8900\n",
            "Epoch 231/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2138 - accuracy: 0.9250 - val_loss: 0.2335 - val_accuracy: 0.8900\n",
            "Epoch 232/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2127 - accuracy: 0.9275 - val_loss: 0.2329 - val_accuracy: 0.8900\n",
            "Epoch 233/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2117 - accuracy: 0.9250 - val_loss: 0.2334 - val_accuracy: 0.8900\n",
            "Epoch 234/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2109 - accuracy: 0.9275 - val_loss: 0.2344 - val_accuracy: 0.9000\n",
            "Epoch 235/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2101 - accuracy: 0.9250 - val_loss: 0.2327 - val_accuracy: 0.9000\n",
            "Epoch 236/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9250 - val_loss: 0.2317 - val_accuracy: 0.9000\n",
            "Epoch 237/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2084 - accuracy: 0.9250 - val_loss: 0.2304 - val_accuracy: 0.9000\n",
            "Epoch 238/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.2073 - accuracy: 0.9300 - val_loss: 0.2305 - val_accuracy: 0.9000\n",
            "Epoch 239/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2064 - accuracy: 0.9250 - val_loss: 0.2295 - val_accuracy: 0.9000\n",
            "Epoch 240/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2054 - accuracy: 0.9250 - val_loss: 0.2271 - val_accuracy: 0.9000\n",
            "Epoch 241/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2045 - accuracy: 0.9300 - val_loss: 0.2281 - val_accuracy: 0.9000\n",
            "Epoch 242/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.2036 - accuracy: 0.9300 - val_loss: 0.2272 - val_accuracy: 0.9000\n",
            "Epoch 243/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2025 - accuracy: 0.9300 - val_loss: 0.2254 - val_accuracy: 0.9000\n",
            "Epoch 244/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2017 - accuracy: 0.9300 - val_loss: 0.2242 - val_accuracy: 0.9000\n",
            "Epoch 245/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.2010 - accuracy: 0.9300 - val_loss: 0.2239 - val_accuracy: 0.9000\n",
            "Epoch 246/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1998 - accuracy: 0.9300 - val_loss: 0.2219 - val_accuracy: 0.9000\n",
            "Epoch 247/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1989 - accuracy: 0.9300 - val_loss: 0.2228 - val_accuracy: 0.9000\n",
            "Epoch 248/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1977 - accuracy: 0.9300 - val_loss: 0.2211 - val_accuracy: 0.9000\n",
            "Epoch 249/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1968 - accuracy: 0.9325 - val_loss: 0.2201 - val_accuracy: 0.9000\n",
            "Epoch 250/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1960 - accuracy: 0.9300 - val_loss: 0.2194 - val_accuracy: 0.9000\n",
            "Epoch 251/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1950 - accuracy: 0.9325 - val_loss: 0.2179 - val_accuracy: 0.9000\n",
            "Epoch 252/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1939 - accuracy: 0.9375 - val_loss: 0.2179 - val_accuracy: 0.9000\n",
            "Epoch 253/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1930 - accuracy: 0.9325 - val_loss: 0.2160 - val_accuracy: 0.9000\n",
            "Epoch 254/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1920 - accuracy: 0.9425 - val_loss: 0.2164 - val_accuracy: 0.9000\n",
            "Epoch 255/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1910 - accuracy: 0.9425 - val_loss: 0.2152 - val_accuracy: 0.9000\n",
            "Epoch 256/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 0.1900 - accuracy: 0.9375 - val_loss: 0.2139 - val_accuracy: 0.9000\n",
            "Epoch 257/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1889 - accuracy: 0.9425 - val_loss: 0.2121 - val_accuracy: 0.9000\n",
            "Epoch 258/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1880 - accuracy: 0.9450 - val_loss: 0.2102 - val_accuracy: 0.9100\n",
            "Epoch 259/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1870 - accuracy: 0.9450 - val_loss: 0.2090 - val_accuracy: 0.9100\n",
            "Epoch 260/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1861 - accuracy: 0.9475 - val_loss: 0.2075 - val_accuracy: 0.9100\n",
            "Epoch 261/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1852 - accuracy: 0.9500 - val_loss: 0.2080 - val_accuracy: 0.9100\n",
            "Epoch 262/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1841 - accuracy: 0.9450 - val_loss: 0.2088 - val_accuracy: 0.9000\n",
            "Epoch 263/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1830 - accuracy: 0.9500 - val_loss: 0.2091 - val_accuracy: 0.9000\n",
            "Epoch 264/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1820 - accuracy: 0.9475 - val_loss: 0.2074 - val_accuracy: 0.9000\n",
            "Epoch 265/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1811 - accuracy: 0.9500 - val_loss: 0.2055 - val_accuracy: 0.9100\n",
            "Epoch 266/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1800 - accuracy: 0.9500 - val_loss: 0.2030 - val_accuracy: 0.9100\n",
            "Epoch 267/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1788 - accuracy: 0.9500 - val_loss: 0.2023 - val_accuracy: 0.9100\n",
            "Epoch 268/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1781 - accuracy: 0.9500 - val_loss: 0.2004 - val_accuracy: 0.9100\n",
            "Epoch 269/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1769 - accuracy: 0.9500 - val_loss: 0.2002 - val_accuracy: 0.9100\n",
            "Epoch 270/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1758 - accuracy: 0.9500 - val_loss: 0.2005 - val_accuracy: 0.9100\n",
            "Epoch 271/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1747 - accuracy: 0.9500 - val_loss: 0.2000 - val_accuracy: 0.9100\n",
            "Epoch 272/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1736 - accuracy: 0.9525 - val_loss: 0.1976 - val_accuracy: 0.9100\n",
            "Epoch 273/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.1727 - accuracy: 0.9525 - val_loss: 0.1972 - val_accuracy: 0.9100\n",
            "Epoch 274/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1716 - accuracy: 0.9525 - val_loss: 0.1954 - val_accuracy: 0.9100\n",
            "Epoch 275/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1705 - accuracy: 0.9525 - val_loss: 0.1942 - val_accuracy: 0.9100\n",
            "Epoch 276/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1697 - accuracy: 0.9500 - val_loss: 0.1936 - val_accuracy: 0.9100\n",
            "Epoch 277/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1685 - accuracy: 0.9525 - val_loss: 0.1929 - val_accuracy: 0.9100\n",
            "Epoch 278/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1678 - accuracy: 0.9525 - val_loss: 0.1911 - val_accuracy: 0.9200\n",
            "Epoch 279/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.1666 - accuracy: 0.9550 - val_loss: 0.1881 - val_accuracy: 0.9300\n",
            "Epoch 280/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1656 - accuracy: 0.9550 - val_loss: 0.1886 - val_accuracy: 0.9300\n",
            "Epoch 281/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.1645 - accuracy: 0.9525 - val_loss: 0.1871 - val_accuracy: 0.9300\n",
            "Epoch 282/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.1633 - accuracy: 0.9550 - val_loss: 0.1875 - val_accuracy: 0.9300\n",
            "Epoch 283/300\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 0.1629 - accuracy: 0.9550 - val_loss: 0.1860 - val_accuracy: 0.9300\n",
            "Epoch 284/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1612 - accuracy: 0.9550 - val_loss: 0.1847 - val_accuracy: 0.9300\n",
            "Epoch 285/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1601 - accuracy: 0.9550 - val_loss: 0.1842 - val_accuracy: 0.9300\n",
            "Epoch 286/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1591 - accuracy: 0.9550 - val_loss: 0.1817 - val_accuracy: 0.9300\n",
            "Epoch 287/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1582 - accuracy: 0.9575 - val_loss: 0.1792 - val_accuracy: 0.9400\n",
            "Epoch 288/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1569 - accuracy: 0.9600 - val_loss: 0.1788 - val_accuracy: 0.9400\n",
            "Epoch 289/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1558 - accuracy: 0.9575 - val_loss: 0.1780 - val_accuracy: 0.9400\n",
            "Epoch 290/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1549 - accuracy: 0.9625 - val_loss: 0.1775 - val_accuracy: 0.9300\n",
            "Epoch 291/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1536 - accuracy: 0.9625 - val_loss: 0.1784 - val_accuracy: 0.9300\n",
            "Epoch 292/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1526 - accuracy: 0.9600 - val_loss: 0.1772 - val_accuracy: 0.9300\n",
            "Epoch 293/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1518 - accuracy: 0.9600 - val_loss: 0.1756 - val_accuracy: 0.9300\n",
            "Epoch 294/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 0.1508 - accuracy: 0.9625 - val_loss: 0.1736 - val_accuracy: 0.9400\n",
            "Epoch 295/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1492 - accuracy: 0.9625 - val_loss: 0.1713 - val_accuracy: 0.9500\n",
            "Epoch 296/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1483 - accuracy: 0.9675 - val_loss: 0.1686 - val_accuracy: 0.9500\n",
            "Epoch 297/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9650 - val_loss: 0.1700 - val_accuracy: 0.9500\n",
            "Epoch 298/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1460 - accuracy: 0.9675 - val_loss: 0.1688 - val_accuracy: 0.9500\n",
            "Epoch 299/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9675 - val_loss: 0.1676 - val_accuracy: 0.9400\n",
            "Epoch 300/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 0.1439 - accuracy: 0.9650 - val_loss: 0.1675 - val_accuracy: 0.9400\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1478 - accuracy: 0.9620\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 0.1620 - accuracy: 0.9500\n",
            "Training set accuracy: 0.9620000123977661\n",
            "Test set accuracy: 0.949999988079071\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nq6RMLzciwN"
      },
      "source": [
        "Let's next look at some training plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te_BySHr13P2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e38de5bd-7a58-425f-9dde-20af565221dc"
      },
      "source": [
        "history"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4950da32d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpoIfuW8ciwQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "d14f5480-9793-4dc6-97bb-e40c25baf02b"
      },
      "source": [
        "# The history of our accuracy during training.\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkivLoq-ciwU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "9081b19d-97f4-4f9d-d033-fe51f2069221"
      },
      "source": [
        "# The history of our cross-entropy loss during training.\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXPkBbXs7Uqa"
      },
      "source": [
        "### b) Analyzing model performance (5 points)\n",
        "What was your model's final prediction accuracy on the test set? Explain the pattern/trend you have observed in the previous two plots in your own words.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cW4NHPHi78Fu"
      },
      "source": [
        "Test set final prediction accuracy: 0.950\n",
        "\n",
        "In general, both test and trainning set has a simillar trend and pattern.\n",
        "\n",
        "At the beginning (low epochs), the loss is big and the accuracy is low. And when it gets higher epochs, the loss becomes lower and accuracy becomes higher.\n",
        "\n",
        "At last, training set has slightly better accuracy and lower loss than test set. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-UNwaIt_HgR"
      },
      "source": [
        "### c) Decision Boundary (5 points)\n",
        "Plot the decisin boundary of the network you built (using the code below) and explain what you observe and why."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYDz8YyPciwW"
      },
      "source": [
        "The following code will allow us to visualize our deep neural network's decision boundary. Let's observe.\n",
        "\n",
        "This will take a moment to construct the plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs6FGaHKciwX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "6fcebe77-2613-4ae6-c631-40db750c71da"
      },
      "source": [
        "#\n",
        "# This code is substantively from https://rohitmidha23.github.io/Neural-Network-Decision-Boundary/\n",
        "#\n",
        "def plot_decision_boundary(X, y, model, steps=1000, cmap='bwr'):\n",
        "    # The following allows you to adjust the plot size\n",
        "    rcParams['figure.figsize'] = 8, 6  # 8 inches by 6 inches\n",
        "    cmap = plt.get_cmap(cmap)\n",
        "\n",
        "    # Define region of interest by data limits\n",
        "    xmin, xmax = X[:,0].min() - 1, X[:,0].max() + 1\n",
        "    ymin, ymax = X[:,1].min() - 1, X[:,1].max() + 1\n",
        "    x_span = np.linspace(xmin, xmax, steps)\n",
        "    y_span = np.linspace(ymin, ymax, steps)\n",
        "    xx, yy = np.meshgrid(x_span, y_span)\n",
        "\n",
        "    # Make predictions across region of interest\n",
        "    labels = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "\n",
        "    # Plot decision boundary in region of interest\n",
        "    z = labels.reshape(xx.shape)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.contourf(xx, yy, z, cmap=cmap, alpha=0.5)\n",
        "\n",
        "    # Get predicted labels on training data and plot\n",
        "    train_labels = model.predict(X)\n",
        "    ax.scatter(X[:,0], X[:,1], c=y, cmap=cmap, lw=0)\n",
        "\n",
        "    return fig, ax\n",
        "\n",
        "plot_decision_boundary(test_data, test_labels, model) \n",
        "# Reset figure size back to default.\n",
        "rcParams['figure.figsize'] = 6, 4"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLtd20xC2Mj3"
      },
      "source": [
        "The decision boundary looks like a couple of line segements. It works for this data set. For me, it is better to be a curve because both data sets are in the shape of moon."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak3Y2clPLZpv"
      },
      "source": [
        "## Problem 4 - Fish Data revisited "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wiXAk_ILy2N"
      },
      "source": [
        "We will revist the \"Fish\" dataset and train a regression neural network on the features \"Length1\", \"Length2\", \"Length3\",\t\"Height\", and \"Width\" to predict Weight. Run or fill in the following cells and answer written response questions for each section. Begin by downloading \"Fish.csv\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMy-21iKABVc"
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTvM0_JzABVc"
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLDSqS7_JD0j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "11eed1fd-3549-471b-ce6e-e16e4cf06d60"
      },
      "source": [
        "# Download the Fish data\n",
        "downloaded = drive.CreateFile({'id':\"1AtMi-xCejVlhYS5qjgjjW4gH-TLuWJjC\"})\n",
        "downloaded.GetContentFile('Fish.csv')  \n",
        "\n",
        "# Create pandas dataframe\n",
        "fish_data = pd.read_csv('Fish.csv')\n",
        "\n",
        "# Delete any rows for which there is a measurement of 0.0.\n",
        "fish_data = fish_data.drop( np.where(fish_data==0)[0] )\n",
        "fish_data.head()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Species</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Length1</th>\n",
              "      <th>Length2</th>\n",
              "      <th>Length3</th>\n",
              "      <th>Height</th>\n",
              "      <th>Width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bream</td>\n",
              "      <td>242.0</td>\n",
              "      <td>23.2</td>\n",
              "      <td>25.4</td>\n",
              "      <td>30.0</td>\n",
              "      <td>11.5200</td>\n",
              "      <td>4.0200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bream</td>\n",
              "      <td>290.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>26.3</td>\n",
              "      <td>31.2</td>\n",
              "      <td>12.4800</td>\n",
              "      <td>4.3056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bream</td>\n",
              "      <td>340.0</td>\n",
              "      <td>23.9</td>\n",
              "      <td>26.5</td>\n",
              "      <td>31.1</td>\n",
              "      <td>12.3778</td>\n",
              "      <td>4.6961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bream</td>\n",
              "      <td>363.0</td>\n",
              "      <td>26.3</td>\n",
              "      <td>29.0</td>\n",
              "      <td>33.5</td>\n",
              "      <td>12.7300</td>\n",
              "      <td>4.4555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bream</td>\n",
              "      <td>430.0</td>\n",
              "      <td>26.5</td>\n",
              "      <td>29.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>12.4440</td>\n",
              "      <td>5.1340</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Species  Weight  Length1  Length2  Length3   Height   Width\n",
              "0   Bream   242.0     23.2     25.4     30.0  11.5200  4.0200\n",
              "1   Bream   290.0     24.0     26.3     31.2  12.4800  4.3056\n",
              "2   Bream   340.0     23.9     26.5     31.1  12.3778  4.6961\n",
              "3   Bream   363.0     26.3     29.0     33.5  12.7300  4.4555\n",
              "4   Bream   430.0     26.5     29.0     34.0  12.4440  5.1340"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IZwN2j4yIaX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "ba52bd4a-966a-430a-e095-70777dac3ba7"
      },
      "source": [
        "fish_data.describe()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Weight</th>\n",
              "      <th>Length1</th>\n",
              "      <th>Length2</th>\n",
              "      <th>Length3</th>\n",
              "      <th>Height</th>\n",
              "      <th>Width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>158.000000</td>\n",
              "      <td>158.000000</td>\n",
              "      <td>158.000000</td>\n",
              "      <td>158.000000</td>\n",
              "      <td>158.000000</td>\n",
              "      <td>158.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>400.847468</td>\n",
              "      <td>26.293038</td>\n",
              "      <td>28.465823</td>\n",
              "      <td>31.280380</td>\n",
              "      <td>8.986790</td>\n",
              "      <td>4.424232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>357.697796</td>\n",
              "      <td>10.011427</td>\n",
              "      <td>10.731707</td>\n",
              "      <td>11.627605</td>\n",
              "      <td>4.295191</td>\n",
              "      <td>1.689010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.900000</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>8.400000</td>\n",
              "      <td>8.800000</td>\n",
              "      <td>1.728400</td>\n",
              "      <td>1.047600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>121.250000</td>\n",
              "      <td>19.150000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>23.200000</td>\n",
              "      <td>5.940600</td>\n",
              "      <td>3.398650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>281.500000</td>\n",
              "      <td>25.300000</td>\n",
              "      <td>27.400000</td>\n",
              "      <td>29.700000</td>\n",
              "      <td>7.789000</td>\n",
              "      <td>4.277050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>650.000000</td>\n",
              "      <td>32.700000</td>\n",
              "      <td>35.750000</td>\n",
              "      <td>39.675000</td>\n",
              "      <td>12.371850</td>\n",
              "      <td>5.586750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1650.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>63.400000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>18.957000</td>\n",
              "      <td>8.142000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Weight     Length1     Length2     Length3      Height       Width\n",
              "count   158.000000  158.000000  158.000000  158.000000  158.000000  158.000000\n",
              "mean    400.847468   26.293038   28.465823   31.280380    8.986790    4.424232\n",
              "std     357.697796   10.011427   10.731707   11.627605    4.295191    1.689010\n",
              "min       5.900000    7.500000    8.400000    8.800000    1.728400    1.047600\n",
              "25%     121.250000   19.150000   21.000000   23.200000    5.940600    3.398650\n",
              "50%     281.500000   25.300000   27.400000   29.700000    7.789000    4.277050\n",
              "75%     650.000000   32.700000   35.750000   39.675000   12.371850    5.586750\n",
              "max    1650.000000   59.000000   63.400000   68.000000   18.957000    8.142000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QH5esQZKdLNX"
      },
      "source": [
        "### a) Data Preprocessing (15 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yGF14XXidKS"
      },
      "source": [
        "Recall from the previous lectures and class excercises that it is especially important to normalize data for neural networks.\n",
        "\n",
        "In order to normalize our data to $[0,1]$ we use the equation:\n",
        "\n",
        "$$x_{norm}=\\frac{x-x_{min}}{x_{max}-x_{min}}$$\n",
        "\n",
        "Normalize the \"Length1\", \"Length2\", \"Length3\",\t\"Height\", and \"Width\", and \"Weight\" columns. We often need to normalize the target variables in a neural network regression task to limit exploding gradients (why might exploding gradients be more prevalent in a regression task?).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA98AUX0kukU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0d8cdc02-9d54-4418-cf72-5a8954f633ec"
      },
      "source": [
        "# Get fish max and min weight, we'll need these later.\n",
        "fish_max = fish_data[\"Weight\"].max()\n",
        "fish_min = fish_data[\"Weight\"].min()\n",
        "\n",
        "# Normalize the \"Length1\", \"Length2\", \"Length3\", \"Height\", \"Width\", \"Weight\" columns of fish_data.\n",
        "### YOUR CODE HERE ###\n",
        "\n",
        "to_normalize = [\"Length1\", \"Length2\", \"Length3\", \"Height\", \"Width\", \"Weight\"]\n",
        "\n",
        "def normalize_col(col):\n",
        "  return (col - col.min()) / (col.max() - col.min())\n",
        "\n",
        "for col in to_normalize:\n",
        "  fish_data[col] = normalize_col(fish_data[col])  \n",
        "\n",
        "# Take a look at the new age column.\n",
        "fish_data.head()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Species</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Length1</th>\n",
              "      <th>Length2</th>\n",
              "      <th>Length3</th>\n",
              "      <th>Height</th>\n",
              "      <th>Width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bream</td>\n",
              "      <td>0.143604</td>\n",
              "      <td>0.304854</td>\n",
              "      <td>0.309091</td>\n",
              "      <td>0.358108</td>\n",
              "      <td>0.568334</td>\n",
              "      <td>0.418978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bream</td>\n",
              "      <td>0.172800</td>\n",
              "      <td>0.320388</td>\n",
              "      <td>0.325455</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.624055</td>\n",
              "      <td>0.459235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bream</td>\n",
              "      <td>0.203211</td>\n",
              "      <td>0.318447</td>\n",
              "      <td>0.329091</td>\n",
              "      <td>0.376689</td>\n",
              "      <td>0.618123</td>\n",
              "      <td>0.514279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bream</td>\n",
              "      <td>0.217201</td>\n",
              "      <td>0.365049</td>\n",
              "      <td>0.374545</td>\n",
              "      <td>0.417230</td>\n",
              "      <td>0.638566</td>\n",
              "      <td>0.480365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bream</td>\n",
              "      <td>0.257953</td>\n",
              "      <td>0.368932</td>\n",
              "      <td>0.374545</td>\n",
              "      <td>0.425676</td>\n",
              "      <td>0.621966</td>\n",
              "      <td>0.576004</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Species    Weight   Length1   Length2   Length3    Height     Width\n",
              "0   Bream  0.143604  0.304854  0.309091  0.358108  0.568334  0.418978\n",
              "1   Bream  0.172800  0.320388  0.325455  0.378378  0.624055  0.459235\n",
              "2   Bream  0.203211  0.318447  0.329091  0.376689  0.618123  0.514279\n",
              "3   Bream  0.217201  0.365049  0.374545  0.417230  0.638566  0.480365\n",
              "4   Bream  0.257953  0.368932  0.374545  0.425676  0.621966  0.576004"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCtWDzuDoI2J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0a38091-9c89-40f1-b524-614b42867904"
      },
      "source": [
        "# split the data into features X_fish and target variable y_fish.\n",
        "y_fish = fish_data.iloc[:, 1] # Get Fish Weights\n",
        "X_fish = fish_data.drop(columns=['Weight']) # Get Fish measurements plus species\n",
        "X_fish = X_fish.drop(columns=['Species']) # Drop the Fish Species for now\n",
        "\n",
        "# print X.head(), you should have 5 features for each sample\n",
        "print(\"X_fish.head():\")\n",
        "print(X_fish.head())\n",
        "\n",
        "# print y.head(), you should have one label for each sample\n",
        "print(\"\\ny_fish.head()\")\n",
        "print(y_fish.head())"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_fish.head():\n",
            "    Length1   Length2   Length3    Height     Width\n",
            "0  0.304854  0.309091  0.358108  0.568334  0.418978\n",
            "1  0.320388  0.325455  0.378378  0.624055  0.459235\n",
            "2  0.318447  0.329091  0.376689  0.618123  0.514279\n",
            "3  0.365049  0.374545  0.417230  0.638566  0.480365\n",
            "4  0.368932  0.374545  0.425676  0.621966  0.576004\n",
            "\n",
            "y_fish.head()\n",
            "0    0.143604\n",
            "1    0.172800\n",
            "2    0.203211\n",
            "3    0.217201\n",
            "4    0.257953\n",
            "Name: Weight, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mr_6JsI5oyRl"
      },
      "source": [
        "# Split the X_fish and y_fish into 60/20 training/test split using train_test_split()\n",
        "### YOUR CODE HERE ###\n",
        "x_train, x_test, y_train, y_test = train_test_split(X_fish, y_fish, test_size=0.4, random_state=144)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSCV-qq2oUyk"
      },
      "source": [
        "### b) Neural Network Training (20 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEpeCVuNvK4I"
      },
      "source": [
        "In the cell below, build a neural network 4 layers as follows:\n",
        "* **input layer** of shape 5\n",
        "* **dense layer** with 10 neurons, and sigmoid activation\n",
        "* **dense layer** with 10 neurons, and sigmoid activation\n",
        "* **dense layer** with 5 neurons, and sigmoid activation\n",
        "* **dense layer** with 1 neuron, and linear activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Pno8UsUpSmR"
      },
      "source": [
        "def build_model1():\n",
        "### YOUR CODE HERE ###\n",
        "  input_layer = Input(shape=5)\n",
        "  x = Dense(10, activation=\"sigmoid\")(input_layer)\n",
        "  x = Dense(10, activation=\"sigmoid\")(x)\n",
        "  x = Dense(5, activation=\"sigmoid\")(x)\n",
        "  x = Dense(1, activation=\"linear\")(x)\n",
        "  return Model(input_layer, x)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gUJtdeuqkxa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "863937fa-cbfb-47af-c3ad-5bb2393eec56"
      },
      "source": [
        "# Get model summary\n",
        "model = build_model1()\n",
        "model.summary()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 5)]               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                60        \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 5)                 55        \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 231\n",
            "Trainable params: 231\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtfFKunWp0jI"
      },
      "source": [
        "Declare an SGD optimizer with learning rate of 0.05, weight decay of 1e-6 and momentum of 0.9. Compile your model Use mean_squared_error as the loss and metrics with the sgd optimizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok2LdYJfpr05"
      },
      "source": [
        "# Declare the optimizer\n",
        "### YOUR CODE HERE ###\n",
        "sgd = SGD(learning_rate=0.05, decay=1e-6, momentum=0.9)\n",
        "\n",
        "# Compile model\n",
        "### YOUR CODE HERE ###\n",
        "model.compile(loss=\"mean_squared_error\",\n",
        "              optimizer=sgd,\n",
        "              metrics=[\"mean_squared_error\"])\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQVlE8NkXOAv"
      },
      "source": [
        "Perform model fitting using the training set. Train for 2500 epochs with a batch size of 128 and a validation split of 0.25"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV6j3uRfqN-4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a96fde8-4ed8-4c0a-bdc3-c88f7241e6e0"
      },
      "source": [
        "# Fit model\n",
        "history = model.fit(x_train,\n",
        "                    y_train,\n",
        "                    epochs=2500,\n",
        "                    batch_size=128,\n",
        "                    validation_split=0.25)\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 1/2500\n",
            "1/1 [==============================] - 0s 402ms/step - loss: 0.7923 - mean_squared_error: 0.7923 - val_loss: 0.4736 - val_mean_squared_error: 0.4736\n",
            "Epoch 2/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.4088 - mean_squared_error: 0.4088 - val_loss: 0.1047 - val_mean_squared_error: 0.1047\n",
            "Epoch 3/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0782 - mean_squared_error: 0.0782 - val_loss: 0.0748 - val_mean_squared_error: 0.0748\n",
            "Epoch 4/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0875 - mean_squared_error: 0.0875 - val_loss: 0.2795 - val_mean_squared_error: 0.2795\n",
            "Epoch 5/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3212 - mean_squared_error: 0.3212 - val_loss: 0.4221 - val_mean_squared_error: 0.4221\n",
            "Epoch 6/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.4759 - mean_squared_error: 0.4759 - val_loss: 0.3471 - val_mean_squared_error: 0.3471\n",
            "Epoch 7/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.3949 - mean_squared_error: 0.3949 - val_loss: 0.1544 - val_mean_squared_error: 0.1544\n",
            "Epoch 8/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1817 - mean_squared_error: 0.1817 - val_loss: 0.0456 - val_mean_squared_error: 0.0456\n",
            "Epoch 9/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0452 - mean_squared_error: 0.0452 - val_loss: 0.1082 - val_mean_squared_error: 0.1082\n",
            "Epoch 10/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0810 - mean_squared_error: 0.0810 - val_loss: 0.2508 - val_mean_squared_error: 0.2508\n",
            "Epoch 11/2500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2048 - mean_squared_error: 0.2048 - val_loss: 0.3211 - val_mean_squared_error: 0.3211\n",
            "Epoch 12/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2684 - mean_squared_error: 0.2684 - val_loss: 0.2595 - val_mean_squared_error: 0.2595\n",
            "Epoch 13/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2126 - mean_squared_error: 0.2126 - val_loss: 0.1347 - val_mean_squared_error: 0.1347\n",
            "Epoch 14/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1030 - mean_squared_error: 0.1030 - val_loss: 0.0527 - val_mean_squared_error: 0.0527\n",
            "Epoch 15/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0405 - mean_squared_error: 0.0405 - val_loss: 0.0556 - val_mean_squared_error: 0.0556\n",
            "Epoch 16/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0619 - mean_squared_error: 0.0619 - val_loss: 0.1037 - val_mean_squared_error: 0.1037\n",
            "Epoch 17/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.1228 - mean_squared_error: 0.1228 - val_loss: 0.1314 - val_mean_squared_error: 0.1314\n",
            "Epoch 18/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.1554 - mean_squared_error: 0.1554 - val_loss: 0.1111 - val_mean_squared_error: 0.1111\n",
            "Epoch 19/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.1316 - mean_squared_error: 0.1316 - val_loss: 0.0676 - val_mean_squared_error: 0.0676\n",
            "Epoch 20/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0782 - mean_squared_error: 0.0782 - val_loss: 0.0445 - val_mean_squared_error: 0.0445\n",
            "Epoch 21/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0418 - mean_squared_error: 0.0418 - val_loss: 0.0613 - val_mean_squared_error: 0.0613\n",
            "Epoch 22/2500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0455 - mean_squared_error: 0.0455 - val_loss: 0.1001 - val_mean_squared_error: 0.1001\n",
            "Epoch 23/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0745 - mean_squared_error: 0.0745 - val_loss: 0.1265 - val_mean_squared_error: 0.1265\n",
            "Epoch 24/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0961 - mean_squared_error: 0.0961 - val_loss: 0.1205 - val_mean_squared_error: 0.1205\n",
            "Epoch 25/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0911 - mean_squared_error: 0.0911 - val_loss: 0.0899 - val_mean_squared_error: 0.0899\n",
            "Epoch 26/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0664 - mean_squared_error: 0.0664 - val_loss: 0.0586 - val_mean_squared_error: 0.0586\n",
            "Epoch 27/2500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0438 - mean_squared_error: 0.0438 - val_loss: 0.0447 - val_mean_squared_error: 0.0447\n",
            "Epoch 28/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0393 - mean_squared_error: 0.0393 - val_loss: 0.0486 - val_mean_squared_error: 0.0486\n",
            "Epoch 29/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0510 - mean_squared_error: 0.0510 - val_loss: 0.0575 - val_mean_squared_error: 0.0575\n",
            "Epoch 30/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0646 - mean_squared_error: 0.0646 - val_loss: 0.0595 - val_mean_squared_error: 0.0595\n",
            "Epoch 31/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0674 - mean_squared_error: 0.0674 - val_loss: 0.0530 - val_mean_squared_error: 0.0530\n",
            "Epoch 32/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0580 - mean_squared_error: 0.0580 - val_loss: 0.0455 - val_mean_squared_error: 0.0455\n",
            "Epoch 33/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0452 - mean_squared_error: 0.0452 - val_loss: 0.0455 - val_mean_squared_error: 0.0455\n",
            "Epoch 34/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0386 - mean_squared_error: 0.0386 - val_loss: 0.0545 - val_mean_squared_error: 0.0545\n",
            "Epoch 35/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0414 - mean_squared_error: 0.0414 - val_loss: 0.0661 - val_mean_squared_error: 0.0661\n",
            "Epoch 36/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0487 - mean_squared_error: 0.0487 - val_loss: 0.0724 - val_mean_squared_error: 0.0724\n",
            "Epoch 37/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0531 - mean_squared_error: 0.0531 - val_loss: 0.0695 - val_mean_squared_error: 0.0695\n",
            "Epoch 38/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0511 - mean_squared_error: 0.0511 - val_loss: 0.0603 - val_mean_squared_error: 0.0603\n",
            "Epoch 39/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0449 - mean_squared_error: 0.0449 - val_loss: 0.0507 - val_mean_squared_error: 0.0507\n",
            "Epoch 40/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0396 - mean_squared_error: 0.0396 - val_loss: 0.0452 - val_mean_squared_error: 0.0452\n",
            "Epoch 41/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0387 - mean_squared_error: 0.0387 - val_loss: 0.0443 - val_mean_squared_error: 0.0443\n",
            "Epoch 42/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0416 - mean_squared_error: 0.0416 - val_loss: 0.0453 - val_mean_squared_error: 0.0453\n",
            "Epoch 43/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0449 - mean_squared_error: 0.0449 - val_loss: 0.0457 - val_mean_squared_error: 0.0457\n",
            "Epoch 44/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0456 - mean_squared_error: 0.0456 - val_loss: 0.0448 - val_mean_squared_error: 0.0448\n",
            "Epoch 45/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0434 - mean_squared_error: 0.0434 - val_loss: 0.0442 - val_mean_squared_error: 0.0442\n",
            "Epoch 46/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0402 - mean_squared_error: 0.0402 - val_loss: 0.0456 - val_mean_squared_error: 0.0456\n",
            "Epoch 47/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0385 - mean_squared_error: 0.0385 - val_loss: 0.0492 - val_mean_squared_error: 0.0492\n",
            "Epoch 48/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0390 - mean_squared_error: 0.0390 - val_loss: 0.0532 - val_mean_squared_error: 0.0532\n",
            "Epoch 49/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0407 - mean_squared_error: 0.0407 - val_loss: 0.0555 - val_mean_squared_error: 0.0555\n",
            "Epoch 50/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0420 - mean_squared_error: 0.0420 - val_loss: 0.0549 - val_mean_squared_error: 0.0549\n",
            "Epoch 51/2500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0416 - mean_squared_error: 0.0416 - val_loss: 0.0520 - val_mean_squared_error: 0.0520\n",
            "Epoch 52/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0402 - mean_squared_error: 0.0402 - val_loss: 0.0485 - val_mean_squared_error: 0.0485\n",
            "Epoch 53/2500\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 0.0387 - mean_squared_error: 0.0387 - val_loss: 0.0459 - val_mean_squared_error: 0.0459\n",
            "Epoch 54/2500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0383 - mean_squared_error: 0.0383 - val_loss: 0.0445 - val_mean_squared_error: 0.0445\n",
            "Epoch 55/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0390 - mean_squared_error: 0.0390 - val_loss: 0.0441 - val_mean_squared_error: 0.0441\n",
            "Epoch 56/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0398 - mean_squared_error: 0.0398 - val_loss: 0.0440 - val_mean_squared_error: 0.0440\n",
            "Epoch 57/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0401 - mean_squared_error: 0.0401 - val_loss: 0.0441 - val_mean_squared_error: 0.0441\n",
            "Epoch 58/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0397 - mean_squared_error: 0.0397 - val_loss: 0.0445 - val_mean_squared_error: 0.0445\n",
            "Epoch 59/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0389 - mean_squared_error: 0.0389 - val_loss: 0.0455 - val_mean_squared_error: 0.0455\n",
            "Epoch 60/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0383 - mean_squared_error: 0.0383 - val_loss: 0.0471 - val_mean_squared_error: 0.0471\n",
            "Epoch 61/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0383 - mean_squared_error: 0.0383 - val_loss: 0.0487 - val_mean_squared_error: 0.0487\n",
            "Epoch 62/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0388 - mean_squared_error: 0.0388 - val_loss: 0.0497 - val_mean_squared_error: 0.0497\n",
            "Epoch 63/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0391 - mean_squared_error: 0.0391 - val_loss: 0.0497 - val_mean_squared_error: 0.0497\n",
            "Epoch 64/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0391 - mean_squared_error: 0.0391 - val_loss: 0.0488 - val_mean_squared_error: 0.0488\n",
            "Epoch 65/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0387 - mean_squared_error: 0.0387 - val_loss: 0.0474 - val_mean_squared_error: 0.0474\n",
            "Epoch 66/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0384 - mean_squared_error: 0.0384 - val_loss: 0.0461 - val_mean_squared_error: 0.0461\n",
            "Epoch 67/2500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0382 - mean_squared_error: 0.0382 - val_loss: 0.0452 - val_mean_squared_error: 0.0452\n",
            "Epoch 68/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0383 - mean_squared_error: 0.0383 - val_loss: 0.0447 - val_mean_squared_error: 0.0447\n",
            "Epoch 69/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0385 - mean_squared_error: 0.0385 - val_loss: 0.0445 - val_mean_squared_error: 0.0445\n",
            "Epoch 70/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0386 - mean_squared_error: 0.0386 - val_loss: 0.0446 - val_mean_squared_error: 0.0446\n",
            "Epoch 71/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0385 - mean_squared_error: 0.0385 - val_loss: 0.0449 - val_mean_squared_error: 0.0449\n",
            "Epoch 72/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0383 - mean_squared_error: 0.0383 - val_loss: 0.0455 - val_mean_squared_error: 0.0455\n",
            "Epoch 73/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0382 - mean_squared_error: 0.0382 - val_loss: 0.0463 - val_mean_squared_error: 0.0463\n",
            "Epoch 74/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0381 - mean_squared_error: 0.0381 - val_loss: 0.0470 - val_mean_squared_error: 0.0470\n",
            "Epoch 75/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0382 - mean_squared_error: 0.0382 - val_loss: 0.0475 - val_mean_squared_error: 0.0475\n",
            "Epoch 76/2500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0383 - mean_squared_error: 0.0383 - val_loss: 0.0475 - val_mean_squared_error: 0.0475\n",
            "Epoch 77/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0383 - mean_squared_error: 0.0383 - val_loss: 0.0472 - val_mean_squared_error: 0.0472\n",
            "Epoch 78/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0382 - mean_squared_error: 0.0382 - val_loss: 0.0466 - val_mean_squared_error: 0.0466\n",
            "Epoch 79/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0381 - mean_squared_error: 0.0381 - val_loss: 0.0460 - val_mean_squared_error: 0.0460\n",
            "Epoch 80/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0381 - mean_squared_error: 0.0381 - val_loss: 0.0455 - val_mean_squared_error: 0.0455\n",
            "Epoch 81/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0381 - mean_squared_error: 0.0381 - val_loss: 0.0451 - val_mean_squared_error: 0.0451\n",
            "Epoch 82/2500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0381 - mean_squared_error: 0.0381 - val_loss: 0.0450 - val_mean_squared_error: 0.0450\n",
            "Epoch 83/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0381 - mean_squared_error: 0.0381 - val_loss: 0.0450 - val_mean_squared_error: 0.0450\n",
            "Epoch 84/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0381 - mean_squared_error: 0.0381 - val_loss: 0.0452 - val_mean_squared_error: 0.0452\n",
            "Epoch 85/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0381 - mean_squared_error: 0.0381 - val_loss: 0.0455 - val_mean_squared_error: 0.0455\n",
            "Epoch 86/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0380 - mean_squared_error: 0.0380 - val_loss: 0.0458 - val_mean_squared_error: 0.0458\n",
            "Epoch 87/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0380 - mean_squared_error: 0.0380 - val_loss: 0.0462 - val_mean_squared_error: 0.0462\n",
            "Epoch 88/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0380 - mean_squared_error: 0.0380 - val_loss: 0.0464 - val_mean_squared_error: 0.0464\n",
            "Epoch 89/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0380 - mean_squared_error: 0.0380 - val_loss: 0.0465 - val_mean_squared_error: 0.0465\n",
            "Epoch 90/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0380 - mean_squared_error: 0.0380 - val_loss: 0.0464 - val_mean_squared_error: 0.0464\n",
            "Epoch 91/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0380 - mean_squared_error: 0.0380 - val_loss: 0.0461 - val_mean_squared_error: 0.0461\n",
            "Epoch 92/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0379 - mean_squared_error: 0.0379 - val_loss: 0.0458 - val_mean_squared_error: 0.0458\n",
            "Epoch 93/2500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0379 - mean_squared_error: 0.0379 - val_loss: 0.0455 - val_mean_squared_error: 0.0455\n",
            "Epoch 94/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0379 - mean_squared_error: 0.0379 - val_loss: 0.0453 - val_mean_squared_error: 0.0453\n",
            "Epoch 95/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0379 - mean_squared_error: 0.0379 - val_loss: 0.0452 - val_mean_squared_error: 0.0452\n",
            "Epoch 96/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0379 - mean_squared_error: 0.0379 - val_loss: 0.0452 - val_mean_squared_error: 0.0452\n",
            "Epoch 97/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0379 - mean_squared_error: 0.0379 - val_loss: 0.0452 - val_mean_squared_error: 0.0452\n",
            "Epoch 98/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0379 - mean_squared_error: 0.0379 - val_loss: 0.0454 - val_mean_squared_error: 0.0454\n",
            "Epoch 99/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0456 - val_mean_squared_error: 0.0456\n",
            "Epoch 100/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0457 - val_mean_squared_error: 0.0457\n",
            "Epoch 101/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0459 - val_mean_squared_error: 0.0459\n",
            "Epoch 102/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0459 - val_mean_squared_error: 0.0459\n",
            "Epoch 103/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0458 - val_mean_squared_error: 0.0458\n",
            "Epoch 104/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0457 - val_mean_squared_error: 0.0457\n",
            "Epoch 105/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0456 - val_mean_squared_error: 0.0456\n",
            "Epoch 106/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0454 - val_mean_squared_error: 0.0454\n",
            "Epoch 107/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0453 - val_mean_squared_error: 0.0453\n",
            "Epoch 108/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0452 - val_mean_squared_error: 0.0452\n",
            "Epoch 109/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0452 - val_mean_squared_error: 0.0452\n",
            "Epoch 110/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0452 - val_mean_squared_error: 0.0452\n",
            "Epoch 111/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0453 - val_mean_squared_error: 0.0453\n",
            "Epoch 112/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0453 - val_mean_squared_error: 0.0453\n",
            "Epoch 113/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0454 - val_mean_squared_error: 0.0454\n",
            "Epoch 114/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0455 - val_mean_squared_error: 0.0455\n",
            "Epoch 115/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - val_loss: 0.0455 - val_mean_squared_error: 0.0455\n",
            "Epoch 116/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - val_loss: 0.0455 - val_mean_squared_error: 0.0455\n",
            "Epoch 117/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - val_loss: 0.0454 - val_mean_squared_error: 0.0454\n",
            "Epoch 118/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - val_loss: 0.0453 - val_mean_squared_error: 0.0453\n",
            "Epoch 119/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - val_loss: 0.0452 - val_mean_squared_error: 0.0452\n",
            "Epoch 120/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - val_loss: 0.0452 - val_mean_squared_error: 0.0452\n",
            "Epoch 121/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - val_loss: 0.0451 - val_mean_squared_error: 0.0451\n",
            "Epoch 122/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0376 - mean_squared_error: 0.0376 - val_loss: 0.0451 - val_mean_squared_error: 0.0451\n",
            "Epoch 123/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0451 - val_mean_squared_error: 0.0451\n",
            "Epoch 124/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0451 - val_mean_squared_error: 0.0451\n",
            "Epoch 125/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0451 - val_mean_squared_error: 0.0451\n",
            "Epoch 126/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0452 - val_mean_squared_error: 0.0452\n",
            "Epoch 127/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0452 - val_mean_squared_error: 0.0452\n",
            "Epoch 128/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0452 - val_mean_squared_error: 0.0452\n",
            "Epoch 129/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0452 - val_mean_squared_error: 0.0452\n",
            "Epoch 130/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0451 - val_mean_squared_error: 0.0451\n",
            "Epoch 131/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0374 - mean_squared_error: 0.0374 - val_loss: 0.0451 - val_mean_squared_error: 0.0451\n",
            "Epoch 132/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0374 - mean_squared_error: 0.0374 - val_loss: 0.0450 - val_mean_squared_error: 0.0450\n",
            "Epoch 133/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0374 - mean_squared_error: 0.0374 - val_loss: 0.0450 - val_mean_squared_error: 0.0450\n",
            "Epoch 134/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0374 - mean_squared_error: 0.0374 - val_loss: 0.0449 - val_mean_squared_error: 0.0449\n",
            "Epoch 135/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0374 - mean_squared_error: 0.0374 - val_loss: 0.0449 - val_mean_squared_error: 0.0449\n",
            "Epoch 136/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0374 - mean_squared_error: 0.0374 - val_loss: 0.0449 - val_mean_squared_error: 0.0449\n",
            "Epoch 137/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0374 - mean_squared_error: 0.0374 - val_loss: 0.0449 - val_mean_squared_error: 0.0449\n",
            "Epoch 138/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.0449 - val_mean_squared_error: 0.0449\n",
            "Epoch 139/2500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.0449 - val_mean_squared_error: 0.0449\n",
            "Epoch 140/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.0449 - val_mean_squared_error: 0.0449\n",
            "Epoch 141/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.0449 - val_mean_squared_error: 0.0449\n",
            "Epoch 142/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.0449 - val_mean_squared_error: 0.0449\n",
            "Epoch 143/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.0449 - val_mean_squared_error: 0.0449\n",
            "Epoch 144/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.0448 - val_mean_squared_error: 0.0448\n",
            "Epoch 145/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0372 - mean_squared_error: 0.0372 - val_loss: 0.0448 - val_mean_squared_error: 0.0448\n",
            "Epoch 146/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0372 - mean_squared_error: 0.0372 - val_loss: 0.0447 - val_mean_squared_error: 0.0447\n",
            "Epoch 147/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0372 - mean_squared_error: 0.0372 - val_loss: 0.0447 - val_mean_squared_error: 0.0447\n",
            "Epoch 148/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0372 - mean_squared_error: 0.0372 - val_loss: 0.0447 - val_mean_squared_error: 0.0447\n",
            "Epoch 149/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0372 - mean_squared_error: 0.0372 - val_loss: 0.0447 - val_mean_squared_error: 0.0447\n",
            "Epoch 150/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0372 - mean_squared_error: 0.0372 - val_loss: 0.0447 - val_mean_squared_error: 0.0447\n",
            "Epoch 151/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0372 - mean_squared_error: 0.0372 - val_loss: 0.0447 - val_mean_squared_error: 0.0447\n",
            "Epoch 152/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0371 - mean_squared_error: 0.0371 - val_loss: 0.0446 - val_mean_squared_error: 0.0446\n",
            "Epoch 153/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0371 - mean_squared_error: 0.0371 - val_loss: 0.0446 - val_mean_squared_error: 0.0446\n",
            "Epoch 154/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0371 - mean_squared_error: 0.0371 - val_loss: 0.0446 - val_mean_squared_error: 0.0446\n",
            "Epoch 155/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0371 - mean_squared_error: 0.0371 - val_loss: 0.0446 - val_mean_squared_error: 0.0446\n",
            "Epoch 156/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0371 - mean_squared_error: 0.0371 - val_loss: 0.0446 - val_mean_squared_error: 0.0446\n",
            "Epoch 157/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0371 - mean_squared_error: 0.0371 - val_loss: 0.0446 - val_mean_squared_error: 0.0446\n",
            "Epoch 158/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0371 - mean_squared_error: 0.0371 - val_loss: 0.0445 - val_mean_squared_error: 0.0445\n",
            "Epoch 159/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0370 - mean_squared_error: 0.0370 - val_loss: 0.0445 - val_mean_squared_error: 0.0445\n",
            "Epoch 160/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0370 - mean_squared_error: 0.0370 - val_loss: 0.0445 - val_mean_squared_error: 0.0445\n",
            "Epoch 161/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0370 - mean_squared_error: 0.0370 - val_loss: 0.0445 - val_mean_squared_error: 0.0445\n",
            "Epoch 162/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0370 - mean_squared_error: 0.0370 - val_loss: 0.0444 - val_mean_squared_error: 0.0444\n",
            "Epoch 163/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0370 - mean_squared_error: 0.0370 - val_loss: 0.0444 - val_mean_squared_error: 0.0444\n",
            "Epoch 164/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0370 - mean_squared_error: 0.0370 - val_loss: 0.0444 - val_mean_squared_error: 0.0444\n",
            "Epoch 165/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0369 - mean_squared_error: 0.0369 - val_loss: 0.0444 - val_mean_squared_error: 0.0444\n",
            "Epoch 166/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0369 - mean_squared_error: 0.0369 - val_loss: 0.0444 - val_mean_squared_error: 0.0444\n",
            "Epoch 167/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0369 - mean_squared_error: 0.0369 - val_loss: 0.0444 - val_mean_squared_error: 0.0444\n",
            "Epoch 168/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0369 - mean_squared_error: 0.0369 - val_loss: 0.0443 - val_mean_squared_error: 0.0443\n",
            "Epoch 169/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0369 - mean_squared_error: 0.0369 - val_loss: 0.0443 - val_mean_squared_error: 0.0443\n",
            "Epoch 170/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0369 - mean_squared_error: 0.0369 - val_loss: 0.0443 - val_mean_squared_error: 0.0443\n",
            "Epoch 171/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0368 - mean_squared_error: 0.0368 - val_loss: 0.0443 - val_mean_squared_error: 0.0443\n",
            "Epoch 172/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0368 - mean_squared_error: 0.0368 - val_loss: 0.0442 - val_mean_squared_error: 0.0442\n",
            "Epoch 173/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0368 - mean_squared_error: 0.0368 - val_loss: 0.0442 - val_mean_squared_error: 0.0442\n",
            "Epoch 174/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0368 - mean_squared_error: 0.0368 - val_loss: 0.0442 - val_mean_squared_error: 0.0442\n",
            "Epoch 175/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0368 - mean_squared_error: 0.0368 - val_loss: 0.0442 - val_mean_squared_error: 0.0442\n",
            "Epoch 176/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0368 - mean_squared_error: 0.0368 - val_loss: 0.0441 - val_mean_squared_error: 0.0441\n",
            "Epoch 177/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0367 - mean_squared_error: 0.0367 - val_loss: 0.0441 - val_mean_squared_error: 0.0441\n",
            "Epoch 178/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0367 - mean_squared_error: 0.0367 - val_loss: 0.0441 - val_mean_squared_error: 0.0441\n",
            "Epoch 179/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0367 - mean_squared_error: 0.0367 - val_loss: 0.0441 - val_mean_squared_error: 0.0441\n",
            "Epoch 180/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0367 - mean_squared_error: 0.0367 - val_loss: 0.0441 - val_mean_squared_error: 0.0441\n",
            "Epoch 181/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0367 - mean_squared_error: 0.0367 - val_loss: 0.0440 - val_mean_squared_error: 0.0440\n",
            "Epoch 182/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0367 - mean_squared_error: 0.0367 - val_loss: 0.0440 - val_mean_squared_error: 0.0440\n",
            "Epoch 183/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0366 - mean_squared_error: 0.0366 - val_loss: 0.0440 - val_mean_squared_error: 0.0440\n",
            "Epoch 184/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0366 - mean_squared_error: 0.0366 - val_loss: 0.0440 - val_mean_squared_error: 0.0440\n",
            "Epoch 185/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0366 - mean_squared_error: 0.0366 - val_loss: 0.0439 - val_mean_squared_error: 0.0439\n",
            "Epoch 186/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0366 - mean_squared_error: 0.0366 - val_loss: 0.0439 - val_mean_squared_error: 0.0439\n",
            "Epoch 187/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0366 - mean_squared_error: 0.0366 - val_loss: 0.0439 - val_mean_squared_error: 0.0439\n",
            "Epoch 188/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0366 - mean_squared_error: 0.0366 - val_loss: 0.0439 - val_mean_squared_error: 0.0439\n",
            "Epoch 189/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0365 - mean_squared_error: 0.0365 - val_loss: 0.0439 - val_mean_squared_error: 0.0439\n",
            "Epoch 190/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0365 - mean_squared_error: 0.0365 - val_loss: 0.0438 - val_mean_squared_error: 0.0438\n",
            "Epoch 191/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0365 - mean_squared_error: 0.0365 - val_loss: 0.0438 - val_mean_squared_error: 0.0438\n",
            "Epoch 192/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0365 - mean_squared_error: 0.0365 - val_loss: 0.0438 - val_mean_squared_error: 0.0438\n",
            "Epoch 193/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0365 - mean_squared_error: 0.0365 - val_loss: 0.0438 - val_mean_squared_error: 0.0438\n",
            "Epoch 194/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0365 - mean_squared_error: 0.0365 - val_loss: 0.0437 - val_mean_squared_error: 0.0437\n",
            "Epoch 195/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0364 - mean_squared_error: 0.0364 - val_loss: 0.0437 - val_mean_squared_error: 0.0437\n",
            "Epoch 196/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0364 - mean_squared_error: 0.0364 - val_loss: 0.0437 - val_mean_squared_error: 0.0437\n",
            "Epoch 197/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0364 - mean_squared_error: 0.0364 - val_loss: 0.0437 - val_mean_squared_error: 0.0437\n",
            "Epoch 198/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0364 - mean_squared_error: 0.0364 - val_loss: 0.0436 - val_mean_squared_error: 0.0436\n",
            "Epoch 199/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0364 - mean_squared_error: 0.0364 - val_loss: 0.0436 - val_mean_squared_error: 0.0436\n",
            "Epoch 200/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0363 - mean_squared_error: 0.0363 - val_loss: 0.0436 - val_mean_squared_error: 0.0436\n",
            "Epoch 201/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0363 - mean_squared_error: 0.0363 - val_loss: 0.0436 - val_mean_squared_error: 0.0436\n",
            "Epoch 202/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0363 - mean_squared_error: 0.0363 - val_loss: 0.0435 - val_mean_squared_error: 0.0435\n",
            "Epoch 203/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0363 - mean_squared_error: 0.0363 - val_loss: 0.0435 - val_mean_squared_error: 0.0435\n",
            "Epoch 204/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0363 - mean_squared_error: 0.0363 - val_loss: 0.0435 - val_mean_squared_error: 0.0435\n",
            "Epoch 205/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0363 - mean_squared_error: 0.0363 - val_loss: 0.0435 - val_mean_squared_error: 0.0435\n",
            "Epoch 206/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0362 - mean_squared_error: 0.0362 - val_loss: 0.0434 - val_mean_squared_error: 0.0434\n",
            "Epoch 207/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0362 - mean_squared_error: 0.0362 - val_loss: 0.0434 - val_mean_squared_error: 0.0434\n",
            "Epoch 208/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0362 - mean_squared_error: 0.0362 - val_loss: 0.0434 - val_mean_squared_error: 0.0434\n",
            "Epoch 209/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0362 - mean_squared_error: 0.0362 - val_loss: 0.0434 - val_mean_squared_error: 0.0434\n",
            "Epoch 210/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0362 - mean_squared_error: 0.0362 - val_loss: 0.0433 - val_mean_squared_error: 0.0433\n",
            "Epoch 211/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0361 - mean_squared_error: 0.0361 - val_loss: 0.0433 - val_mean_squared_error: 0.0433\n",
            "Epoch 212/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0361 - mean_squared_error: 0.0361 - val_loss: 0.0433 - val_mean_squared_error: 0.0433\n",
            "Epoch 213/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0361 - mean_squared_error: 0.0361 - val_loss: 0.0433 - val_mean_squared_error: 0.0433\n",
            "Epoch 214/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0361 - mean_squared_error: 0.0361 - val_loss: 0.0432 - val_mean_squared_error: 0.0432\n",
            "Epoch 215/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0361 - mean_squared_error: 0.0361 - val_loss: 0.0432 - val_mean_squared_error: 0.0432\n",
            "Epoch 216/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0360 - mean_squared_error: 0.0360 - val_loss: 0.0432 - val_mean_squared_error: 0.0432\n",
            "Epoch 217/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0360 - mean_squared_error: 0.0360 - val_loss: 0.0432 - val_mean_squared_error: 0.0432\n",
            "Epoch 218/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0360 - mean_squared_error: 0.0360 - val_loss: 0.0431 - val_mean_squared_error: 0.0431\n",
            "Epoch 219/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0360 - mean_squared_error: 0.0360 - val_loss: 0.0431 - val_mean_squared_error: 0.0431\n",
            "Epoch 220/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0360 - mean_squared_error: 0.0360 - val_loss: 0.0431 - val_mean_squared_error: 0.0431\n",
            "Epoch 221/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0359 - mean_squared_error: 0.0359 - val_loss: 0.0430 - val_mean_squared_error: 0.0430\n",
            "Epoch 222/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0359 - mean_squared_error: 0.0359 - val_loss: 0.0430 - val_mean_squared_error: 0.0430\n",
            "Epoch 223/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0359 - mean_squared_error: 0.0359 - val_loss: 0.0430 - val_mean_squared_error: 0.0430\n",
            "Epoch 224/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0359 - mean_squared_error: 0.0359 - val_loss: 0.0430 - val_mean_squared_error: 0.0430\n",
            "Epoch 225/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0358 - mean_squared_error: 0.0358 - val_loss: 0.0429 - val_mean_squared_error: 0.0429\n",
            "Epoch 226/2500\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0358 - mean_squared_error: 0.0358 - val_loss: 0.0429 - val_mean_squared_error: 0.0429\n",
            "Epoch 227/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0358 - mean_squared_error: 0.0358 - val_loss: 0.0429 - val_mean_squared_error: 0.0429\n",
            "Epoch 228/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0358 - mean_squared_error: 0.0358 - val_loss: 0.0429 - val_mean_squared_error: 0.0429\n",
            "Epoch 229/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0358 - mean_squared_error: 0.0358 - val_loss: 0.0428 - val_mean_squared_error: 0.0428\n",
            "Epoch 230/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0357 - mean_squared_error: 0.0357 - val_loss: 0.0428 - val_mean_squared_error: 0.0428\n",
            "Epoch 231/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0357 - mean_squared_error: 0.0357 - val_loss: 0.0428 - val_mean_squared_error: 0.0428\n",
            "Epoch 232/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0357 - mean_squared_error: 0.0357 - val_loss: 0.0427 - val_mean_squared_error: 0.0427\n",
            "Epoch 233/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0357 - mean_squared_error: 0.0357 - val_loss: 0.0427 - val_mean_squared_error: 0.0427\n",
            "Epoch 234/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0357 - mean_squared_error: 0.0357 - val_loss: 0.0427 - val_mean_squared_error: 0.0427\n",
            "Epoch 235/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0356 - mean_squared_error: 0.0356 - val_loss: 0.0426 - val_mean_squared_error: 0.0426\n",
            "Epoch 236/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0356 - mean_squared_error: 0.0356 - val_loss: 0.0426 - val_mean_squared_error: 0.0426\n",
            "Epoch 237/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0356 - mean_squared_error: 0.0356 - val_loss: 0.0426 - val_mean_squared_error: 0.0426\n",
            "Epoch 238/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0356 - mean_squared_error: 0.0356 - val_loss: 0.0426 - val_mean_squared_error: 0.0426\n",
            "Epoch 239/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0355 - mean_squared_error: 0.0355 - val_loss: 0.0425 - val_mean_squared_error: 0.0425\n",
            "Epoch 240/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0355 - mean_squared_error: 0.0355 - val_loss: 0.0425 - val_mean_squared_error: 0.0425\n",
            "Epoch 241/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0355 - mean_squared_error: 0.0355 - val_loss: 0.0425 - val_mean_squared_error: 0.0425\n",
            "Epoch 242/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0355 - mean_squared_error: 0.0355 - val_loss: 0.0424 - val_mean_squared_error: 0.0424\n",
            "Epoch 243/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.0424 - val_mean_squared_error: 0.0424\n",
            "Epoch 244/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.0424 - val_mean_squared_error: 0.0424\n",
            "Epoch 245/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.0423 - val_mean_squared_error: 0.0423\n",
            "Epoch 246/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.0423 - val_mean_squared_error: 0.0423\n",
            "Epoch 247/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0353 - mean_squared_error: 0.0353 - val_loss: 0.0423 - val_mean_squared_error: 0.0423\n",
            "Epoch 248/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0353 - mean_squared_error: 0.0353 - val_loss: 0.0422 - val_mean_squared_error: 0.0422\n",
            "Epoch 249/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0353 - mean_squared_error: 0.0353 - val_loss: 0.0422 - val_mean_squared_error: 0.0422\n",
            "Epoch 250/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0353 - mean_squared_error: 0.0353 - val_loss: 0.0422 - val_mean_squared_error: 0.0422\n",
            "Epoch 251/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0352 - mean_squared_error: 0.0352 - val_loss: 0.0421 - val_mean_squared_error: 0.0421\n",
            "Epoch 252/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0352 - mean_squared_error: 0.0352 - val_loss: 0.0421 - val_mean_squared_error: 0.0421\n",
            "Epoch 253/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0352 - mean_squared_error: 0.0352 - val_loss: 0.0421 - val_mean_squared_error: 0.0421\n",
            "Epoch 254/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0352 - mean_squared_error: 0.0352 - val_loss: 0.0421 - val_mean_squared_error: 0.0421\n",
            "Epoch 255/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0351 - mean_squared_error: 0.0351 - val_loss: 0.0420 - val_mean_squared_error: 0.0420\n",
            "Epoch 256/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0351 - mean_squared_error: 0.0351 - val_loss: 0.0420 - val_mean_squared_error: 0.0420\n",
            "Epoch 257/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0351 - mean_squared_error: 0.0351 - val_loss: 0.0420 - val_mean_squared_error: 0.0420\n",
            "Epoch 258/2500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0351 - mean_squared_error: 0.0351 - val_loss: 0.0419 - val_mean_squared_error: 0.0419\n",
            "Epoch 259/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0350 - mean_squared_error: 0.0350 - val_loss: 0.0419 - val_mean_squared_error: 0.0419\n",
            "Epoch 260/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0350 - mean_squared_error: 0.0350 - val_loss: 0.0418 - val_mean_squared_error: 0.0418\n",
            "Epoch 261/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0350 - mean_squared_error: 0.0350 - val_loss: 0.0418 - val_mean_squared_error: 0.0418\n",
            "Epoch 262/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0350 - mean_squared_error: 0.0350 - val_loss: 0.0418 - val_mean_squared_error: 0.0418\n",
            "Epoch 263/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0349 - mean_squared_error: 0.0349 - val_loss: 0.0417 - val_mean_squared_error: 0.0417\n",
            "Epoch 264/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0349 - mean_squared_error: 0.0349 - val_loss: 0.0417 - val_mean_squared_error: 0.0417\n",
            "Epoch 265/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0349 - mean_squared_error: 0.0349 - val_loss: 0.0417 - val_mean_squared_error: 0.0417\n",
            "Epoch 266/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0349 - mean_squared_error: 0.0349 - val_loss: 0.0416 - val_mean_squared_error: 0.0416\n",
            "Epoch 267/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0348 - mean_squared_error: 0.0348 - val_loss: 0.0416 - val_mean_squared_error: 0.0416\n",
            "Epoch 268/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0348 - mean_squared_error: 0.0348 - val_loss: 0.0416 - val_mean_squared_error: 0.0416\n",
            "Epoch 269/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0348 - mean_squared_error: 0.0348 - val_loss: 0.0415 - val_mean_squared_error: 0.0415\n",
            "Epoch 270/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0348 - mean_squared_error: 0.0348 - val_loss: 0.0415 - val_mean_squared_error: 0.0415\n",
            "Epoch 271/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0347 - mean_squared_error: 0.0347 - val_loss: 0.0415 - val_mean_squared_error: 0.0415\n",
            "Epoch 272/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0347 - mean_squared_error: 0.0347 - val_loss: 0.0414 - val_mean_squared_error: 0.0414\n",
            "Epoch 273/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0347 - mean_squared_error: 0.0347 - val_loss: 0.0414 - val_mean_squared_error: 0.0414\n",
            "Epoch 274/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0346 - mean_squared_error: 0.0346 - val_loss: 0.0413 - val_mean_squared_error: 0.0413\n",
            "Epoch 275/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0346 - mean_squared_error: 0.0346 - val_loss: 0.0413 - val_mean_squared_error: 0.0413\n",
            "Epoch 276/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0346 - mean_squared_error: 0.0346 - val_loss: 0.0413 - val_mean_squared_error: 0.0413\n",
            "Epoch 277/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0346 - mean_squared_error: 0.0346 - val_loss: 0.0412 - val_mean_squared_error: 0.0412\n",
            "Epoch 278/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0345 - mean_squared_error: 0.0345 - val_loss: 0.0412 - val_mean_squared_error: 0.0412\n",
            "Epoch 279/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0345 - mean_squared_error: 0.0345 - val_loss: 0.0412 - val_mean_squared_error: 0.0412\n",
            "Epoch 280/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0345 - mean_squared_error: 0.0345 - val_loss: 0.0411 - val_mean_squared_error: 0.0411\n",
            "Epoch 281/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0344 - mean_squared_error: 0.0344 - val_loss: 0.0411 - val_mean_squared_error: 0.0411\n",
            "Epoch 282/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0344 - mean_squared_error: 0.0344 - val_loss: 0.0410 - val_mean_squared_error: 0.0410\n",
            "Epoch 283/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0344 - mean_squared_error: 0.0344 - val_loss: 0.0410 - val_mean_squared_error: 0.0410\n",
            "Epoch 284/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0343 - mean_squared_error: 0.0343 - val_loss: 0.0410 - val_mean_squared_error: 0.0410\n",
            "Epoch 285/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0343 - mean_squared_error: 0.0343 - val_loss: 0.0409 - val_mean_squared_error: 0.0409\n",
            "Epoch 286/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0343 - mean_squared_error: 0.0343 - val_loss: 0.0409 - val_mean_squared_error: 0.0409\n",
            "Epoch 287/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0343 - mean_squared_error: 0.0343 - val_loss: 0.0408 - val_mean_squared_error: 0.0408\n",
            "Epoch 288/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0342 - mean_squared_error: 0.0342 - val_loss: 0.0408 - val_mean_squared_error: 0.0408\n",
            "Epoch 289/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0342 - mean_squared_error: 0.0342 - val_loss: 0.0408 - val_mean_squared_error: 0.0408\n",
            "Epoch 290/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0342 - mean_squared_error: 0.0342 - val_loss: 0.0407 - val_mean_squared_error: 0.0407\n",
            "Epoch 291/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0341 - mean_squared_error: 0.0341 - val_loss: 0.0407 - val_mean_squared_error: 0.0407\n",
            "Epoch 292/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0341 - mean_squared_error: 0.0341 - val_loss: 0.0406 - val_mean_squared_error: 0.0406\n",
            "Epoch 293/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0341 - mean_squared_error: 0.0341 - val_loss: 0.0406 - val_mean_squared_error: 0.0406\n",
            "Epoch 294/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0406 - val_mean_squared_error: 0.0406\n",
            "Epoch 295/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0405 - val_mean_squared_error: 0.0405\n",
            "Epoch 296/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0405 - val_mean_squared_error: 0.0405\n",
            "Epoch 297/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0339 - mean_squared_error: 0.0339 - val_loss: 0.0404 - val_mean_squared_error: 0.0404\n",
            "Epoch 298/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0339 - mean_squared_error: 0.0339 - val_loss: 0.0404 - val_mean_squared_error: 0.0404\n",
            "Epoch 299/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0339 - mean_squared_error: 0.0339 - val_loss: 0.0403 - val_mean_squared_error: 0.0403\n",
            "Epoch 300/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0338 - mean_squared_error: 0.0338 - val_loss: 0.0403 - val_mean_squared_error: 0.0403\n",
            "Epoch 301/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0338 - mean_squared_error: 0.0338 - val_loss: 0.0403 - val_mean_squared_error: 0.0403\n",
            "Epoch 302/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0338 - mean_squared_error: 0.0338 - val_loss: 0.0402 - val_mean_squared_error: 0.0402\n",
            "Epoch 303/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0337 - mean_squared_error: 0.0337 - val_loss: 0.0402 - val_mean_squared_error: 0.0402\n",
            "Epoch 304/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0337 - mean_squared_error: 0.0337 - val_loss: 0.0401 - val_mean_squared_error: 0.0401\n",
            "Epoch 305/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0337 - mean_squared_error: 0.0337 - val_loss: 0.0401 - val_mean_squared_error: 0.0401\n",
            "Epoch 306/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0336 - mean_squared_error: 0.0336 - val_loss: 0.0400 - val_mean_squared_error: 0.0400\n",
            "Epoch 307/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0336 - mean_squared_error: 0.0336 - val_loss: 0.0400 - val_mean_squared_error: 0.0400\n",
            "Epoch 308/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0336 - mean_squared_error: 0.0336 - val_loss: 0.0399 - val_mean_squared_error: 0.0399\n",
            "Epoch 309/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.0399 - val_mean_squared_error: 0.0399\n",
            "Epoch 310/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.0398 - val_mean_squared_error: 0.0398\n",
            "Epoch 311/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0335 - mean_squared_error: 0.0335 - val_loss: 0.0398 - val_mean_squared_error: 0.0398\n",
            "Epoch 312/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0334 - mean_squared_error: 0.0334 - val_loss: 0.0397 - val_mean_squared_error: 0.0397\n",
            "Epoch 313/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0334 - mean_squared_error: 0.0334 - val_loss: 0.0397 - val_mean_squared_error: 0.0397\n",
            "Epoch 314/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0334 - mean_squared_error: 0.0334 - val_loss: 0.0397 - val_mean_squared_error: 0.0397\n",
            "Epoch 315/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0396 - val_mean_squared_error: 0.0396\n",
            "Epoch 316/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0396 - val_mean_squared_error: 0.0396\n",
            "Epoch 317/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0332 - mean_squared_error: 0.0332 - val_loss: 0.0395 - val_mean_squared_error: 0.0395\n",
            "Epoch 318/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0332 - mean_squared_error: 0.0332 - val_loss: 0.0395 - val_mean_squared_error: 0.0395\n",
            "Epoch 319/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0332 - mean_squared_error: 0.0332 - val_loss: 0.0394 - val_mean_squared_error: 0.0394\n",
            "Epoch 320/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0331 - mean_squared_error: 0.0331 - val_loss: 0.0394 - val_mean_squared_error: 0.0394\n",
            "Epoch 321/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0331 - mean_squared_error: 0.0331 - val_loss: 0.0393 - val_mean_squared_error: 0.0393\n",
            "Epoch 322/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0331 - mean_squared_error: 0.0331 - val_loss: 0.0393 - val_mean_squared_error: 0.0393\n",
            "Epoch 323/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0330 - mean_squared_error: 0.0330 - val_loss: 0.0392 - val_mean_squared_error: 0.0392\n",
            "Epoch 324/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0330 - mean_squared_error: 0.0330 - val_loss: 0.0392 - val_mean_squared_error: 0.0392\n",
            "Epoch 325/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0329 - mean_squared_error: 0.0329 - val_loss: 0.0391 - val_mean_squared_error: 0.0391\n",
            "Epoch 326/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0329 - mean_squared_error: 0.0329 - val_loss: 0.0391 - val_mean_squared_error: 0.0391\n",
            "Epoch 327/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0329 - mean_squared_error: 0.0329 - val_loss: 0.0390 - val_mean_squared_error: 0.0390\n",
            "Epoch 328/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0328 - mean_squared_error: 0.0328 - val_loss: 0.0390 - val_mean_squared_error: 0.0390\n",
            "Epoch 329/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0328 - mean_squared_error: 0.0328 - val_loss: 0.0389 - val_mean_squared_error: 0.0389\n",
            "Epoch 330/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0327 - mean_squared_error: 0.0327 - val_loss: 0.0388 - val_mean_squared_error: 0.0388\n",
            "Epoch 331/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0327 - mean_squared_error: 0.0327 - val_loss: 0.0388 - val_mean_squared_error: 0.0388\n",
            "Epoch 332/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0327 - mean_squared_error: 0.0327 - val_loss: 0.0387 - val_mean_squared_error: 0.0387\n",
            "Epoch 333/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0326 - mean_squared_error: 0.0326 - val_loss: 0.0387 - val_mean_squared_error: 0.0387\n",
            "Epoch 334/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0326 - mean_squared_error: 0.0326 - val_loss: 0.0386 - val_mean_squared_error: 0.0386\n",
            "Epoch 335/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0325 - mean_squared_error: 0.0325 - val_loss: 0.0386 - val_mean_squared_error: 0.0386\n",
            "Epoch 336/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0325 - mean_squared_error: 0.0325 - val_loss: 0.0385 - val_mean_squared_error: 0.0385\n",
            "Epoch 337/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0324 - mean_squared_error: 0.0324 - val_loss: 0.0385 - val_mean_squared_error: 0.0385\n",
            "Epoch 338/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0324 - mean_squared_error: 0.0324 - val_loss: 0.0384 - val_mean_squared_error: 0.0384\n",
            "Epoch 339/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0324 - mean_squared_error: 0.0324 - val_loss: 0.0384 - val_mean_squared_error: 0.0384\n",
            "Epoch 340/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0323 - mean_squared_error: 0.0323 - val_loss: 0.0383 - val_mean_squared_error: 0.0383\n",
            "Epoch 341/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0323 - mean_squared_error: 0.0323 - val_loss: 0.0382 - val_mean_squared_error: 0.0382\n",
            "Epoch 342/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0322 - mean_squared_error: 0.0322 - val_loss: 0.0382 - val_mean_squared_error: 0.0382\n",
            "Epoch 343/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0322 - mean_squared_error: 0.0322 - val_loss: 0.0381 - val_mean_squared_error: 0.0381\n",
            "Epoch 344/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0321 - mean_squared_error: 0.0321 - val_loss: 0.0381 - val_mean_squared_error: 0.0381\n",
            "Epoch 345/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0321 - mean_squared_error: 0.0321 - val_loss: 0.0380 - val_mean_squared_error: 0.0380\n",
            "Epoch 346/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0321 - mean_squared_error: 0.0321 - val_loss: 0.0380 - val_mean_squared_error: 0.0380\n",
            "Epoch 347/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0320 - mean_squared_error: 0.0320 - val_loss: 0.0379 - val_mean_squared_error: 0.0379\n",
            "Epoch 348/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0320 - mean_squared_error: 0.0320 - val_loss: 0.0378 - val_mean_squared_error: 0.0378\n",
            "Epoch 349/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0319 - mean_squared_error: 0.0319 - val_loss: 0.0378 - val_mean_squared_error: 0.0378\n",
            "Epoch 350/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0319 - mean_squared_error: 0.0319 - val_loss: 0.0377 - val_mean_squared_error: 0.0377\n",
            "Epoch 351/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0318 - mean_squared_error: 0.0318 - val_loss: 0.0377 - val_mean_squared_error: 0.0377\n",
            "Epoch 352/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0318 - mean_squared_error: 0.0318 - val_loss: 0.0376 - val_mean_squared_error: 0.0376\n",
            "Epoch 353/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0317 - mean_squared_error: 0.0317 - val_loss: 0.0375 - val_mean_squared_error: 0.0375\n",
            "Epoch 354/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0317 - mean_squared_error: 0.0317 - val_loss: 0.0375 - val_mean_squared_error: 0.0375\n",
            "Epoch 355/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0316 - mean_squared_error: 0.0316 - val_loss: 0.0374 - val_mean_squared_error: 0.0374\n",
            "Epoch 356/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0316 - mean_squared_error: 0.0316 - val_loss: 0.0373 - val_mean_squared_error: 0.0373\n",
            "Epoch 357/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0315 - mean_squared_error: 0.0315 - val_loss: 0.0373 - val_mean_squared_error: 0.0373\n",
            "Epoch 358/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0315 - mean_squared_error: 0.0315 - val_loss: 0.0372 - val_mean_squared_error: 0.0372\n",
            "Epoch 359/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0314 - mean_squared_error: 0.0314 - val_loss: 0.0372 - val_mean_squared_error: 0.0372\n",
            "Epoch 360/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0314 - mean_squared_error: 0.0314 - val_loss: 0.0371 - val_mean_squared_error: 0.0371\n",
            "Epoch 361/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0313 - mean_squared_error: 0.0313 - val_loss: 0.0370 - val_mean_squared_error: 0.0370\n",
            "Epoch 362/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0313 - mean_squared_error: 0.0313 - val_loss: 0.0370 - val_mean_squared_error: 0.0370\n",
            "Epoch 363/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0313 - mean_squared_error: 0.0313 - val_loss: 0.0369 - val_mean_squared_error: 0.0369\n",
            "Epoch 364/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0312 - mean_squared_error: 0.0312 - val_loss: 0.0368 - val_mean_squared_error: 0.0368\n",
            "Epoch 365/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0311 - mean_squared_error: 0.0311 - val_loss: 0.0368 - val_mean_squared_error: 0.0368\n",
            "Epoch 366/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0311 - mean_squared_error: 0.0311 - val_loss: 0.0367 - val_mean_squared_error: 0.0367\n",
            "Epoch 367/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0310 - mean_squared_error: 0.0310 - val_loss: 0.0366 - val_mean_squared_error: 0.0366\n",
            "Epoch 368/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0310 - mean_squared_error: 0.0310 - val_loss: 0.0366 - val_mean_squared_error: 0.0366\n",
            "Epoch 369/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0309 - mean_squared_error: 0.0309 - val_loss: 0.0365 - val_mean_squared_error: 0.0365\n",
            "Epoch 370/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0309 - mean_squared_error: 0.0309 - val_loss: 0.0364 - val_mean_squared_error: 0.0364\n",
            "Epoch 371/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0308 - mean_squared_error: 0.0308 - val_loss: 0.0364 - val_mean_squared_error: 0.0364\n",
            "Epoch 372/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0308 - mean_squared_error: 0.0308 - val_loss: 0.0363 - val_mean_squared_error: 0.0363\n",
            "Epoch 373/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0307 - mean_squared_error: 0.0307 - val_loss: 0.0362 - val_mean_squared_error: 0.0362\n",
            "Epoch 374/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0307 - mean_squared_error: 0.0307 - val_loss: 0.0361 - val_mean_squared_error: 0.0361\n",
            "Epoch 375/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0306 - mean_squared_error: 0.0306 - val_loss: 0.0361 - val_mean_squared_error: 0.0361\n",
            "Epoch 376/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0306 - mean_squared_error: 0.0306 - val_loss: 0.0360 - val_mean_squared_error: 0.0360\n",
            "Epoch 377/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0305 - mean_squared_error: 0.0305 - val_loss: 0.0359 - val_mean_squared_error: 0.0359\n",
            "Epoch 378/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0305 - mean_squared_error: 0.0305 - val_loss: 0.0359 - val_mean_squared_error: 0.0359\n",
            "Epoch 379/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0304 - mean_squared_error: 0.0304 - val_loss: 0.0358 - val_mean_squared_error: 0.0358\n",
            "Epoch 380/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0303 - mean_squared_error: 0.0303 - val_loss: 0.0357 - val_mean_squared_error: 0.0357\n",
            "Epoch 381/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0303 - mean_squared_error: 0.0303 - val_loss: 0.0356 - val_mean_squared_error: 0.0356\n",
            "Epoch 382/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0302 - mean_squared_error: 0.0302 - val_loss: 0.0356 - val_mean_squared_error: 0.0356\n",
            "Epoch 383/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0302 - mean_squared_error: 0.0302 - val_loss: 0.0355 - val_mean_squared_error: 0.0355\n",
            "Epoch 384/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0301 - mean_squared_error: 0.0301 - val_loss: 0.0354 - val_mean_squared_error: 0.0354\n",
            "Epoch 385/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0301 - mean_squared_error: 0.0301 - val_loss: 0.0353 - val_mean_squared_error: 0.0353\n",
            "Epoch 386/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0300 - mean_squared_error: 0.0300 - val_loss: 0.0353 - val_mean_squared_error: 0.0353\n",
            "Epoch 387/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0299 - mean_squared_error: 0.0299 - val_loss: 0.0352 - val_mean_squared_error: 0.0352\n",
            "Epoch 388/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0299 - mean_squared_error: 0.0299 - val_loss: 0.0351 - val_mean_squared_error: 0.0351\n",
            "Epoch 389/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0298 - mean_squared_error: 0.0298 - val_loss: 0.0350 - val_mean_squared_error: 0.0350\n",
            "Epoch 390/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0298 - mean_squared_error: 0.0298 - val_loss: 0.0350 - val_mean_squared_error: 0.0350\n",
            "Epoch 391/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0297 - mean_squared_error: 0.0297 - val_loss: 0.0349 - val_mean_squared_error: 0.0349\n",
            "Epoch 392/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0296 - mean_squared_error: 0.0296 - val_loss: 0.0348 - val_mean_squared_error: 0.0348\n",
            "Epoch 393/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0296 - mean_squared_error: 0.0296 - val_loss: 0.0347 - val_mean_squared_error: 0.0347\n",
            "Epoch 394/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0295 - mean_squared_error: 0.0295 - val_loss: 0.0346 - val_mean_squared_error: 0.0346\n",
            "Epoch 395/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0295 - mean_squared_error: 0.0295 - val_loss: 0.0346 - val_mean_squared_error: 0.0346\n",
            "Epoch 396/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0294 - mean_squared_error: 0.0294 - val_loss: 0.0345 - val_mean_squared_error: 0.0345\n",
            "Epoch 397/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0293 - mean_squared_error: 0.0293 - val_loss: 0.0344 - val_mean_squared_error: 0.0344\n",
            "Epoch 398/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0293 - mean_squared_error: 0.0293 - val_loss: 0.0343 - val_mean_squared_error: 0.0343\n",
            "Epoch 399/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0292 - mean_squared_error: 0.0292 - val_loss: 0.0342 - val_mean_squared_error: 0.0342\n",
            "Epoch 400/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0292 - mean_squared_error: 0.0292 - val_loss: 0.0341 - val_mean_squared_error: 0.0341\n",
            "Epoch 401/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0291 - mean_squared_error: 0.0291 - val_loss: 0.0341 - val_mean_squared_error: 0.0341\n",
            "Epoch 402/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0290 - mean_squared_error: 0.0290 - val_loss: 0.0340 - val_mean_squared_error: 0.0340\n",
            "Epoch 403/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0290 - mean_squared_error: 0.0290 - val_loss: 0.0339 - val_mean_squared_error: 0.0339\n",
            "Epoch 404/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0289 - mean_squared_error: 0.0289 - val_loss: 0.0338 - val_mean_squared_error: 0.0338\n",
            "Epoch 405/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0288 - mean_squared_error: 0.0288 - val_loss: 0.0337 - val_mean_squared_error: 0.0337\n",
            "Epoch 406/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0288 - mean_squared_error: 0.0288 - val_loss: 0.0336 - val_mean_squared_error: 0.0336\n",
            "Epoch 407/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0287 - mean_squared_error: 0.0287 - val_loss: 0.0335 - val_mean_squared_error: 0.0335\n",
            "Epoch 408/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0286 - mean_squared_error: 0.0286 - val_loss: 0.0335 - val_mean_squared_error: 0.0335\n",
            "Epoch 409/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0286 - mean_squared_error: 0.0286 - val_loss: 0.0334 - val_mean_squared_error: 0.0334\n",
            "Epoch 410/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0285 - mean_squared_error: 0.0285 - val_loss: 0.0333 - val_mean_squared_error: 0.0333\n",
            "Epoch 411/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0284 - mean_squared_error: 0.0284 - val_loss: 0.0332 - val_mean_squared_error: 0.0332\n",
            "Epoch 412/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0284 - mean_squared_error: 0.0284 - val_loss: 0.0331 - val_mean_squared_error: 0.0331\n",
            "Epoch 413/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0283 - mean_squared_error: 0.0283 - val_loss: 0.0330 - val_mean_squared_error: 0.0330\n",
            "Epoch 414/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0282 - mean_squared_error: 0.0282 - val_loss: 0.0329 - val_mean_squared_error: 0.0329\n",
            "Epoch 415/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0281 - mean_squared_error: 0.0281 - val_loss: 0.0328 - val_mean_squared_error: 0.0328\n",
            "Epoch 416/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0281 - mean_squared_error: 0.0281 - val_loss: 0.0327 - val_mean_squared_error: 0.0327\n",
            "Epoch 417/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0280 - mean_squared_error: 0.0280 - val_loss: 0.0326 - val_mean_squared_error: 0.0326\n",
            "Epoch 418/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0279 - mean_squared_error: 0.0279 - val_loss: 0.0326 - val_mean_squared_error: 0.0326\n",
            "Epoch 419/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0279 - mean_squared_error: 0.0279 - val_loss: 0.0325 - val_mean_squared_error: 0.0325\n",
            "Epoch 420/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0278 - mean_squared_error: 0.0278 - val_loss: 0.0324 - val_mean_squared_error: 0.0324\n",
            "Epoch 421/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0277 - mean_squared_error: 0.0277 - val_loss: 0.0323 - val_mean_squared_error: 0.0323\n",
            "Epoch 422/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0276 - mean_squared_error: 0.0276 - val_loss: 0.0322 - val_mean_squared_error: 0.0322\n",
            "Epoch 423/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0276 - mean_squared_error: 0.0276 - val_loss: 0.0321 - val_mean_squared_error: 0.0321\n",
            "Epoch 424/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0275 - mean_squared_error: 0.0275 - val_loss: 0.0320 - val_mean_squared_error: 0.0320\n",
            "Epoch 425/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0274 - mean_squared_error: 0.0274 - val_loss: 0.0319 - val_mean_squared_error: 0.0319\n",
            "Epoch 426/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0273 - mean_squared_error: 0.0273 - val_loss: 0.0318 - val_mean_squared_error: 0.0318\n",
            "Epoch 427/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0273 - mean_squared_error: 0.0273 - val_loss: 0.0317 - val_mean_squared_error: 0.0317\n",
            "Epoch 428/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0272 - mean_squared_error: 0.0272 - val_loss: 0.0316 - val_mean_squared_error: 0.0316\n",
            "Epoch 429/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0271 - mean_squared_error: 0.0271 - val_loss: 0.0315 - val_mean_squared_error: 0.0315\n",
            "Epoch 430/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0270 - mean_squared_error: 0.0270 - val_loss: 0.0314 - val_mean_squared_error: 0.0314\n",
            "Epoch 431/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0270 - mean_squared_error: 0.0270 - val_loss: 0.0313 - val_mean_squared_error: 0.0313\n",
            "Epoch 432/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0269 - mean_squared_error: 0.0269 - val_loss: 0.0312 - val_mean_squared_error: 0.0312\n",
            "Epoch 433/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0268 - mean_squared_error: 0.0268 - val_loss: 0.0311 - val_mean_squared_error: 0.0311\n",
            "Epoch 434/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0267 - mean_squared_error: 0.0267 - val_loss: 0.0310 - val_mean_squared_error: 0.0310\n",
            "Epoch 435/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0267 - mean_squared_error: 0.0267 - val_loss: 0.0309 - val_mean_squared_error: 0.0309\n",
            "Epoch 436/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0266 - mean_squared_error: 0.0266 - val_loss: 0.0308 - val_mean_squared_error: 0.0308\n",
            "Epoch 437/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0265 - mean_squared_error: 0.0265 - val_loss: 0.0307 - val_mean_squared_error: 0.0307\n",
            "Epoch 438/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0264 - mean_squared_error: 0.0264 - val_loss: 0.0306 - val_mean_squared_error: 0.0306\n",
            "Epoch 439/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0263 - mean_squared_error: 0.0263 - val_loss: 0.0305 - val_mean_squared_error: 0.0305\n",
            "Epoch 440/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0263 - mean_squared_error: 0.0263 - val_loss: 0.0304 - val_mean_squared_error: 0.0304\n",
            "Epoch 441/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0262 - mean_squared_error: 0.0262 - val_loss: 0.0303 - val_mean_squared_error: 0.0303\n",
            "Epoch 442/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0261 - mean_squared_error: 0.0261 - val_loss: 0.0301 - val_mean_squared_error: 0.0301\n",
            "Epoch 443/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0260 - mean_squared_error: 0.0260 - val_loss: 0.0300 - val_mean_squared_error: 0.0300\n",
            "Epoch 444/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0259 - mean_squared_error: 0.0259 - val_loss: 0.0299 - val_mean_squared_error: 0.0299\n",
            "Epoch 445/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0258 - mean_squared_error: 0.0258 - val_loss: 0.0298 - val_mean_squared_error: 0.0298\n",
            "Epoch 446/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0258 - mean_squared_error: 0.0258 - val_loss: 0.0297 - val_mean_squared_error: 0.0297\n",
            "Epoch 447/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0257 - mean_squared_error: 0.0257 - val_loss: 0.0296 - val_mean_squared_error: 0.0296\n",
            "Epoch 448/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0256 - mean_squared_error: 0.0256 - val_loss: 0.0295 - val_mean_squared_error: 0.0295\n",
            "Epoch 449/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0255 - mean_squared_error: 0.0255 - val_loss: 0.0294 - val_mean_squared_error: 0.0294\n",
            "Epoch 450/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0254 - mean_squared_error: 0.0254 - val_loss: 0.0293 - val_mean_squared_error: 0.0293\n",
            "Epoch 451/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0253 - mean_squared_error: 0.0253 - val_loss: 0.0292 - val_mean_squared_error: 0.0292\n",
            "Epoch 452/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0252 - mean_squared_error: 0.0252 - val_loss: 0.0290 - val_mean_squared_error: 0.0290\n",
            "Epoch 453/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0252 - mean_squared_error: 0.0252 - val_loss: 0.0289 - val_mean_squared_error: 0.0289\n",
            "Epoch 454/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0251 - mean_squared_error: 0.0251 - val_loss: 0.0288 - val_mean_squared_error: 0.0288\n",
            "Epoch 455/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0250 - mean_squared_error: 0.0250 - val_loss: 0.0287 - val_mean_squared_error: 0.0287\n",
            "Epoch 456/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0249 - mean_squared_error: 0.0249 - val_loss: 0.0286 - val_mean_squared_error: 0.0286\n",
            "Epoch 457/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0248 - mean_squared_error: 0.0248 - val_loss: 0.0285 - val_mean_squared_error: 0.0285\n",
            "Epoch 458/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0247 - mean_squared_error: 0.0247 - val_loss: 0.0284 - val_mean_squared_error: 0.0284\n",
            "Epoch 459/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0246 - mean_squared_error: 0.0246 - val_loss: 0.0282 - val_mean_squared_error: 0.0282\n",
            "Epoch 460/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0245 - mean_squared_error: 0.0245 - val_loss: 0.0281 - val_mean_squared_error: 0.0281\n",
            "Epoch 461/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0244 - mean_squared_error: 0.0244 - val_loss: 0.0280 - val_mean_squared_error: 0.0280\n",
            "Epoch 462/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0244 - mean_squared_error: 0.0244 - val_loss: 0.0279 - val_mean_squared_error: 0.0279\n",
            "Epoch 463/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0243 - mean_squared_error: 0.0243 - val_loss: 0.0278 - val_mean_squared_error: 0.0278\n",
            "Epoch 464/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0242 - mean_squared_error: 0.0242 - val_loss: 0.0277 - val_mean_squared_error: 0.0277\n",
            "Epoch 465/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0241 - mean_squared_error: 0.0241 - val_loss: 0.0275 - val_mean_squared_error: 0.0275\n",
            "Epoch 466/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0240 - mean_squared_error: 0.0240 - val_loss: 0.0274 - val_mean_squared_error: 0.0274\n",
            "Epoch 467/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0239 - mean_squared_error: 0.0239 - val_loss: 0.0273 - val_mean_squared_error: 0.0273\n",
            "Epoch 468/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0238 - mean_squared_error: 0.0238 - val_loss: 0.0272 - val_mean_squared_error: 0.0272\n",
            "Epoch 469/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0237 - mean_squared_error: 0.0237 - val_loss: 0.0270 - val_mean_squared_error: 0.0270\n",
            "Epoch 470/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0236 - mean_squared_error: 0.0236 - val_loss: 0.0269 - val_mean_squared_error: 0.0269\n",
            "Epoch 471/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.0268 - val_mean_squared_error: 0.0268\n",
            "Epoch 472/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0267 - val_mean_squared_error: 0.0267\n",
            "Epoch 473/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0233 - mean_squared_error: 0.0233 - val_loss: 0.0266 - val_mean_squared_error: 0.0266\n",
            "Epoch 474/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.0264 - val_mean_squared_error: 0.0264\n",
            "Epoch 475/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0231 - mean_squared_error: 0.0231 - val_loss: 0.0263 - val_mean_squared_error: 0.0263\n",
            "Epoch 476/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0262 - val_mean_squared_error: 0.0262\n",
            "Epoch 477/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0229 - mean_squared_error: 0.0229 - val_loss: 0.0261 - val_mean_squared_error: 0.0261\n",
            "Epoch 478/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0259 - val_mean_squared_error: 0.0259\n",
            "Epoch 479/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0227 - mean_squared_error: 0.0227 - val_loss: 0.0258 - val_mean_squared_error: 0.0258\n",
            "Epoch 480/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0226 - mean_squared_error: 0.0226 - val_loss: 0.0257 - val_mean_squared_error: 0.0257\n",
            "Epoch 481/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0226 - mean_squared_error: 0.0226 - val_loss: 0.0255 - val_mean_squared_error: 0.0255\n",
            "Epoch 482/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0225 - mean_squared_error: 0.0225 - val_loss: 0.0254 - val_mean_squared_error: 0.0254\n",
            "Epoch 483/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0224 - mean_squared_error: 0.0224 - val_loss: 0.0253 - val_mean_squared_error: 0.0253\n",
            "Epoch 484/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0223 - mean_squared_error: 0.0223 - val_loss: 0.0252 - val_mean_squared_error: 0.0252\n",
            "Epoch 485/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0222 - mean_squared_error: 0.0222 - val_loss: 0.0250 - val_mean_squared_error: 0.0250\n",
            "Epoch 486/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0221 - mean_squared_error: 0.0221 - val_loss: 0.0249 - val_mean_squared_error: 0.0249\n",
            "Epoch 487/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0220 - mean_squared_error: 0.0220 - val_loss: 0.0248 - val_mean_squared_error: 0.0248\n",
            "Epoch 488/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0218 - mean_squared_error: 0.0218 - val_loss: 0.0246 - val_mean_squared_error: 0.0246\n",
            "Epoch 489/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0217 - mean_squared_error: 0.0217 - val_loss: 0.0245 - val_mean_squared_error: 0.0245\n",
            "Epoch 490/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0216 - mean_squared_error: 0.0216 - val_loss: 0.0244 - val_mean_squared_error: 0.0244\n",
            "Epoch 491/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0215 - mean_squared_error: 0.0215 - val_loss: 0.0242 - val_mean_squared_error: 0.0242\n",
            "Epoch 492/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0214 - mean_squared_error: 0.0214 - val_loss: 0.0241 - val_mean_squared_error: 0.0241\n",
            "Epoch 493/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0213 - mean_squared_error: 0.0213 - val_loss: 0.0240 - val_mean_squared_error: 0.0240\n",
            "Epoch 494/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0212 - mean_squared_error: 0.0212 - val_loss: 0.0238 - val_mean_squared_error: 0.0238\n",
            "Epoch 495/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0211 - mean_squared_error: 0.0211 - val_loss: 0.0237 - val_mean_squared_error: 0.0237\n",
            "Epoch 496/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0210 - mean_squared_error: 0.0210 - val_loss: 0.0236 - val_mean_squared_error: 0.0236\n",
            "Epoch 497/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0209 - mean_squared_error: 0.0209 - val_loss: 0.0234 - val_mean_squared_error: 0.0234\n",
            "Epoch 498/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0208 - mean_squared_error: 0.0208 - val_loss: 0.0233 - val_mean_squared_error: 0.0233\n",
            "Epoch 499/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0207 - mean_squared_error: 0.0207 - val_loss: 0.0232 - val_mean_squared_error: 0.0232\n",
            "Epoch 500/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0206 - mean_squared_error: 0.0206 - val_loss: 0.0230 - val_mean_squared_error: 0.0230\n",
            "Epoch 501/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0205 - mean_squared_error: 0.0205 - val_loss: 0.0229 - val_mean_squared_error: 0.0229\n",
            "Epoch 502/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0204 - mean_squared_error: 0.0204 - val_loss: 0.0228 - val_mean_squared_error: 0.0228\n",
            "Epoch 503/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0203 - mean_squared_error: 0.0203 - val_loss: 0.0226 - val_mean_squared_error: 0.0226\n",
            "Epoch 504/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0202 - mean_squared_error: 0.0202 - val_loss: 0.0225 - val_mean_squared_error: 0.0225\n",
            "Epoch 505/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0201 - mean_squared_error: 0.0201 - val_loss: 0.0224 - val_mean_squared_error: 0.0224\n",
            "Epoch 506/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0200 - mean_squared_error: 0.0200 - val_loss: 0.0222 - val_mean_squared_error: 0.0222\n",
            "Epoch 507/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0199 - mean_squared_error: 0.0199 - val_loss: 0.0221 - val_mean_squared_error: 0.0221\n",
            "Epoch 508/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0198 - mean_squared_error: 0.0198 - val_loss: 0.0219 - val_mean_squared_error: 0.0219\n",
            "Epoch 509/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0197 - mean_squared_error: 0.0197 - val_loss: 0.0218 - val_mean_squared_error: 0.0218\n",
            "Epoch 510/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0196 - mean_squared_error: 0.0196 - val_loss: 0.0217 - val_mean_squared_error: 0.0217\n",
            "Epoch 511/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0194 - mean_squared_error: 0.0194 - val_loss: 0.0215 - val_mean_squared_error: 0.0215\n",
            "Epoch 512/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0193 - mean_squared_error: 0.0193 - val_loss: 0.0214 - val_mean_squared_error: 0.0214\n",
            "Epoch 513/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0192 - mean_squared_error: 0.0192 - val_loss: 0.0213 - val_mean_squared_error: 0.0213\n",
            "Epoch 514/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0191 - mean_squared_error: 0.0191 - val_loss: 0.0211 - val_mean_squared_error: 0.0211\n",
            "Epoch 515/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - val_loss: 0.0210 - val_mean_squared_error: 0.0210\n",
            "Epoch 516/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0189 - mean_squared_error: 0.0189 - val_loss: 0.0209 - val_mean_squared_error: 0.0209\n",
            "Epoch 517/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.0207 - val_mean_squared_error: 0.0207\n",
            "Epoch 518/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0187 - mean_squared_error: 0.0187 - val_loss: 0.0206 - val_mean_squared_error: 0.0206\n",
            "Epoch 519/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0186 - mean_squared_error: 0.0186 - val_loss: 0.0204 - val_mean_squared_error: 0.0204\n",
            "Epoch 520/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.0203 - val_mean_squared_error: 0.0203\n",
            "Epoch 521/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0202 - val_mean_squared_error: 0.0202\n",
            "Epoch 522/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0200 - val_mean_squared_error: 0.0200\n",
            "Epoch 523/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0199 - val_mean_squared_error: 0.0199\n",
            "Epoch 524/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.0197 - val_mean_squared_error: 0.0197\n",
            "Epoch 525/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0179 - mean_squared_error: 0.0179 - val_loss: 0.0196 - val_mean_squared_error: 0.0196\n",
            "Epoch 526/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0178 - mean_squared_error: 0.0178 - val_loss: 0.0195 - val_mean_squared_error: 0.0195\n",
            "Epoch 527/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0177 - mean_squared_error: 0.0177 - val_loss: 0.0193 - val_mean_squared_error: 0.0193\n",
            "Epoch 528/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0176 - mean_squared_error: 0.0176 - val_loss: 0.0192 - val_mean_squared_error: 0.0192\n",
            "Epoch 529/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0175 - mean_squared_error: 0.0175 - val_loss: 0.0191 - val_mean_squared_error: 0.0191\n",
            "Epoch 530/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.0189 - val_mean_squared_error: 0.0189\n",
            "Epoch 531/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0173 - mean_squared_error: 0.0173 - val_loss: 0.0188 - val_mean_squared_error: 0.0188\n",
            "Epoch 532/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0172 - mean_squared_error: 0.0172 - val_loss: 0.0187 - val_mean_squared_error: 0.0187\n",
            "Epoch 533/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.0185 - val_mean_squared_error: 0.0185\n",
            "Epoch 534/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.0184 - val_mean_squared_error: 0.0184\n",
            "Epoch 535/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0169 - mean_squared_error: 0.0169 - val_loss: 0.0182 - val_mean_squared_error: 0.0182\n",
            "Epoch 536/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0168 - mean_squared_error: 0.0168 - val_loss: 0.0181 - val_mean_squared_error: 0.0181\n",
            "Epoch 537/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0167 - mean_squared_error: 0.0167 - val_loss: 0.0180 - val_mean_squared_error: 0.0180\n",
            "Epoch 538/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.0178 - val_mean_squared_error: 0.0178\n",
            "Epoch 539/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.0177 - val_mean_squared_error: 0.0177\n",
            "Epoch 540/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.0176 - val_mean_squared_error: 0.0176\n",
            "Epoch 541/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0174 - val_mean_squared_error: 0.0174\n",
            "Epoch 542/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0173 - val_mean_squared_error: 0.0173\n",
            "Epoch 543/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
            "Epoch 544/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
            "Epoch 545/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0169 - val_mean_squared_error: 0.0169\n",
            "Epoch 546/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
            "Epoch 547/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
            "Epoch 548/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
            "Epoch 549/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0154 - mean_squared_error: 0.0154 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
            "Epoch 550/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0153 - mean_squared_error: 0.0153 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
            "Epoch 551/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0152 - mean_squared_error: 0.0152 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
            "Epoch 552/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
            "Epoch 553/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0150 - mean_squared_error: 0.0150 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
            "Epoch 554/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.0157 - val_mean_squared_error: 0.0157\n",
            "Epoch 555/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
            "Epoch 556/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.0155 - val_mean_squared_error: 0.0155\n",
            "Epoch 557/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0154 - val_mean_squared_error: 0.0154\n",
            "Epoch 558/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0152 - val_mean_squared_error: 0.0152\n",
            "Epoch 559/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0144 - mean_squared_error: 0.0144 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
            "Epoch 560/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0150 - val_mean_squared_error: 0.0150\n",
            "Epoch 561/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0142 - mean_squared_error: 0.0142 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
            "Epoch 562/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0148 - val_mean_squared_error: 0.0148\n",
            "Epoch 563/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0140 - mean_squared_error: 0.0140 - val_loss: 0.0146 - val_mean_squared_error: 0.0146\n",
            "Epoch 564/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0145 - val_mean_squared_error: 0.0145\n",
            "Epoch 565/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.0144 - val_mean_squared_error: 0.0144\n",
            "Epoch 566/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0143 - val_mean_squared_error: 0.0143\n",
            "Epoch 567/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0142 - val_mean_squared_error: 0.0142\n",
            "Epoch 568/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0140 - val_mean_squared_error: 0.0140\n",
            "Epoch 569/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0139 - val_mean_squared_error: 0.0139\n",
            "Epoch 570/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0138 - val_mean_squared_error: 0.0138\n",
            "Epoch 571/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0137 - val_mean_squared_error: 0.0137\n",
            "Epoch 572/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0136 - val_mean_squared_error: 0.0136\n",
            "Epoch 573/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0135 - val_mean_squared_error: 0.0135\n",
            "Epoch 574/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0134 - val_mean_squared_error: 0.0134\n",
            "Epoch 575/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0133 - val_mean_squared_error: 0.0133\n",
            "Epoch 576/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0131 - val_mean_squared_error: 0.0131\n",
            "Epoch 577/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0130 - val_mean_squared_error: 0.0130\n",
            "Epoch 578/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0129 - val_mean_squared_error: 0.0129\n",
            "Epoch 579/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
            "Epoch 580/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
            "Epoch 581/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
            "Epoch 582/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
            "Epoch 583/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
            "Epoch 584/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
            "Epoch 585/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
            "Epoch 586/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
            "Epoch 587/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
            "Epoch 588/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
            "Epoch 589/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
            "Epoch 590/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
            "Epoch 591/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 592/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
            "Epoch 593/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
            "Epoch 594/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
            "Epoch 595/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
            "Epoch 596/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
            "Epoch 597/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
            "Epoch 598/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
            "Epoch 599/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
            "Epoch 600/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
            "Epoch 601/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0108 - val_mean_squared_error: 0.0108\n",
            "Epoch 602/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0107 - val_mean_squared_error: 0.0107\n",
            "Epoch 603/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0106 - val_mean_squared_error: 0.0106\n",
            "Epoch 604/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0105 - val_mean_squared_error: 0.0105\n",
            "Epoch 605/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0105 - val_mean_squared_error: 0.0105\n",
            "Epoch 606/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0104 - val_mean_squared_error: 0.0104\n",
            "Epoch 607/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0103 - val_mean_squared_error: 0.0103\n",
            "Epoch 608/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0102 - val_mean_squared_error: 0.0102\n",
            "Epoch 609/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0102 - val_mean_squared_error: 0.0102\n",
            "Epoch 610/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0101 - val_mean_squared_error: 0.0101\n",
            "Epoch 611/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0100 - val_mean_squared_error: 0.0100\n",
            "Epoch 612/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0100 - val_mean_squared_error: 0.0100\n",
            "Epoch 613/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0099 - val_mean_squared_error: 0.0099\n",
            "Epoch 614/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0098 - val_mean_squared_error: 0.0098\n",
            "Epoch 615/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0098 - val_mean_squared_error: 0.0098\n",
            "Epoch 616/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0097 - val_mean_squared_error: 0.0097\n",
            "Epoch 617/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0096 - val_mean_squared_error: 0.0096\n",
            "Epoch 618/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0096 - val_mean_squared_error: 0.0096\n",
            "Epoch 619/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0095 - val_mean_squared_error: 0.0095\n",
            "Epoch 620/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0095 - val_mean_squared_error: 0.0095\n",
            "Epoch 621/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0094 - val_mean_squared_error: 0.0094\n",
            "Epoch 622/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0093 - val_mean_squared_error: 0.0093\n",
            "Epoch 623/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0093 - val_mean_squared_error: 0.0093\n",
            "Epoch 624/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0092 - val_mean_squared_error: 0.0092\n",
            "Epoch 625/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0092 - val_mean_squared_error: 0.0092\n",
            "Epoch 626/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0091 - val_mean_squared_error: 0.0091\n",
            "Epoch 627/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0091 - val_mean_squared_error: 0.0091\n",
            "Epoch 628/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0090 - val_mean_squared_error: 0.0090\n",
            "Epoch 629/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0090 - val_mean_squared_error: 0.0090\n",
            "Epoch 630/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0089 - val_mean_squared_error: 0.0089\n",
            "Epoch 631/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0089 - val_mean_squared_error: 0.0089\n",
            "Epoch 632/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0088 - val_mean_squared_error: 0.0088\n",
            "Epoch 633/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0088 - val_mean_squared_error: 0.0088\n",
            "Epoch 634/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0087 - val_mean_squared_error: 0.0087\n",
            "Epoch 635/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0087 - val_mean_squared_error: 0.0087\n",
            "Epoch 636/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
            "Epoch 637/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
            "Epoch 638/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
            "Epoch 639/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0085 - val_mean_squared_error: 0.0085\n",
            "Epoch 640/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0085 - val_mean_squared_error: 0.0085\n",
            "Epoch 641/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0084 - val_mean_squared_error: 0.0084\n",
            "Epoch 642/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0084 - val_mean_squared_error: 0.0084\n",
            "Epoch 643/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0084 - val_mean_squared_error: 0.0084\n",
            "Epoch 644/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0083 - val_mean_squared_error: 0.0083\n",
            "Epoch 645/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0083 - val_mean_squared_error: 0.0083\n",
            "Epoch 646/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0083 - val_mean_squared_error: 0.0083\n",
            "Epoch 647/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0082 - val_mean_squared_error: 0.0082\n",
            "Epoch 648/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0082 - val_mean_squared_error: 0.0082\n",
            "Epoch 649/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0082 - val_mean_squared_error: 0.0082\n",
            "Epoch 650/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0081 - val_mean_squared_error: 0.0081\n",
            "Epoch 651/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0081 - val_mean_squared_error: 0.0081\n",
            "Epoch 652/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0081 - val_mean_squared_error: 0.0081\n",
            "Epoch 653/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0080 - val_mean_squared_error: 0.0080\n",
            "Epoch 654/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0080 - val_mean_squared_error: 0.0080\n",
            "Epoch 655/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0080 - val_mean_squared_error: 0.0080\n",
            "Epoch 656/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0079 - val_mean_squared_error: 0.0079\n",
            "Epoch 657/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0079 - val_mean_squared_error: 0.0079\n",
            "Epoch 658/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0079 - val_mean_squared_error: 0.0079\n",
            "Epoch 659/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0079 - val_mean_squared_error: 0.0079\n",
            "Epoch 660/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0078 - val_mean_squared_error: 0.0078\n",
            "Epoch 661/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0078 - val_mean_squared_error: 0.0078\n",
            "Epoch 662/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0078 - val_mean_squared_error: 0.0078\n",
            "Epoch 663/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0078 - val_mean_squared_error: 0.0078\n",
            "Epoch 664/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0077 - val_mean_squared_error: 0.0077\n",
            "Epoch 665/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0077 - val_mean_squared_error: 0.0077\n",
            "Epoch 666/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0077 - val_mean_squared_error: 0.0077\n",
            "Epoch 667/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0077 - val_mean_squared_error: 0.0077\n",
            "Epoch 668/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0077 - val_mean_squared_error: 0.0077\n",
            "Epoch 669/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0076 - val_mean_squared_error: 0.0076\n",
            "Epoch 670/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0076 - val_mean_squared_error: 0.0076\n",
            "Epoch 671/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0076 - val_mean_squared_error: 0.0076\n",
            "Epoch 672/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0076 - val_mean_squared_error: 0.0076\n",
            "Epoch 673/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0076 - val_mean_squared_error: 0.0076\n",
            "Epoch 674/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0075 - val_mean_squared_error: 0.0075\n",
            "Epoch 675/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0075 - val_mean_squared_error: 0.0075\n",
            "Epoch 676/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0075 - val_mean_squared_error: 0.0075\n",
            "Epoch 677/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0075 - val_mean_squared_error: 0.0075\n",
            "Epoch 678/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0075 - val_mean_squared_error: 0.0075\n",
            "Epoch 679/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0074 - val_mean_squared_error: 0.0074\n",
            "Epoch 680/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0074 - val_mean_squared_error: 0.0074\n",
            "Epoch 681/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0074 - val_mean_squared_error: 0.0074\n",
            "Epoch 682/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0074 - val_mean_squared_error: 0.0074\n",
            "Epoch 683/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0074 - val_mean_squared_error: 0.0074\n",
            "Epoch 684/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0074 - val_mean_squared_error: 0.0074\n",
            "Epoch 685/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
            "Epoch 686/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
            "Epoch 687/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
            "Epoch 688/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
            "Epoch 689/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
            "Epoch 690/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
            "Epoch 691/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
            "Epoch 692/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
            "Epoch 693/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
            "Epoch 694/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
            "Epoch 695/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
            "Epoch 696/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
            "Epoch 697/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
            "Epoch 698/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
            "Epoch 699/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
            "Epoch 700/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
            "Epoch 701/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n",
            "Epoch 702/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n",
            "Epoch 703/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n",
            "Epoch 704/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n",
            "Epoch 705/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n",
            "Epoch 706/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n",
            "Epoch 707/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n",
            "Epoch 708/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n",
            "Epoch 709/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n",
            "Epoch 710/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
            "Epoch 711/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
            "Epoch 712/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
            "Epoch 713/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
            "Epoch 714/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
            "Epoch 715/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
            "Epoch 716/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
            "Epoch 717/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
            "Epoch 718/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
            "Epoch 719/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
            "Epoch 720/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
            "Epoch 721/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
            "Epoch 722/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
            "Epoch 723/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
            "Epoch 724/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
            "Epoch 725/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
            "Epoch 726/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
            "Epoch 727/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
            "Epoch 728/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
            "Epoch 729/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
            "Epoch 730/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
            "Epoch 731/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
            "Epoch 732/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
            "Epoch 733/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
            "Epoch 734/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
            "Epoch 735/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
            "Epoch 736/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
            "Epoch 737/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
            "Epoch 738/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
            "Epoch 739/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
            "Epoch 740/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
            "Epoch 741/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
            "Epoch 742/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
            "Epoch 743/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
            "Epoch 744/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
            "Epoch 745/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
            "Epoch 746/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
            "Epoch 747/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
            "Epoch 748/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
            "Epoch 749/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
            "Epoch 750/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
            "Epoch 751/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
            "Epoch 752/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
            "Epoch 753/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
            "Epoch 754/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
            "Epoch 755/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
            "Epoch 756/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
            "Epoch 757/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
            "Epoch 758/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
            "Epoch 759/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
            "Epoch 760/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
            "Epoch 761/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
            "Epoch 762/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
            "Epoch 763/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
            "Epoch 764/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
            "Epoch 765/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
            "Epoch 766/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
            "Epoch 767/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
            "Epoch 768/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
            "Epoch 769/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
            "Epoch 770/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
            "Epoch 771/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
            "Epoch 772/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
            "Epoch 773/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
            "Epoch 774/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
            "Epoch 775/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
            "Epoch 776/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 777/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 778/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 779/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 780/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 781/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 782/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 783/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 784/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 785/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 786/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 787/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 788/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 789/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 790/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 791/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
            "Epoch 792/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 793/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 794/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 795/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 796/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 797/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 798/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 799/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 800/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 801/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 802/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 803/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 804/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 805/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 806/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 807/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
            "Epoch 808/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 809/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 810/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 811/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 812/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 813/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 814/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 815/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 816/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 817/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 818/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 819/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 820/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 821/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 822/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 823/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 824/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 825/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
            "Epoch 826/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 827/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 828/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 829/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 830/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 831/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 832/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 833/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 834/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 835/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 836/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 837/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 838/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 839/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 840/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 841/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 842/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 843/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 844/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 845/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 846/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 847/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 848/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 849/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 850/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 851/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 852/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 853/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 854/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 855/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 856/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 857/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 858/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 859/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 860/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 861/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 862/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
            "Epoch 863/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 864/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 865/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 866/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 867/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 868/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 869/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 870/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 871/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 872/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 873/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 874/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 875/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 876/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 877/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 878/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 879/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 880/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 881/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 882/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 883/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
            "Epoch 884/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 885/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 886/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 887/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 888/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 889/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 890/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 891/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 892/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 893/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 894/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 895/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 896/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 897/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 898/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 899/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 900/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 901/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 902/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 903/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 904/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
            "Epoch 905/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 906/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 907/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 908/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 909/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 910/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 911/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 912/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 913/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 914/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 915/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 916/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 917/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 918/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 919/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 920/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 921/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 922/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 923/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 924/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 925/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 926/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 927/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 928/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 929/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 930/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 931/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 932/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 933/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 934/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 935/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 936/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 937/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 938/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 939/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 940/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 941/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 942/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 943/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 944/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 945/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 946/2500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 947/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 948/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 949/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 950/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 951/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 952/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
            "Epoch 953/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 954/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 955/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 956/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 957/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 958/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 959/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 960/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 961/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 962/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 963/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 964/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 965/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 966/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 967/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 968/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 969/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 970/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 971/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 972/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 973/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 974/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 975/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 976/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 977/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 978/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 979/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 980/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 981/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 982/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 983/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 984/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 985/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 986/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 987/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 988/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 989/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 990/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 991/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 992/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 993/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 994/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 995/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 996/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 997/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 998/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 999/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 1000/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 1001/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 1002/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 1003/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 1004/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 1005/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 1006/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
            "Epoch 1007/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1008/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1009/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1010/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1011/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1012/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1013/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1014/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1015/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1016/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1017/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1018/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1019/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1020/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1021/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1022/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1023/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1024/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1025/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1026/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1027/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1028/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1029/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1030/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1031/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1032/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1033/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1034/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1035/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
            "Epoch 1036/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1037/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1038/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1039/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1040/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1041/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1042/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1043/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1044/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1045/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1046/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1047/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1048/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1049/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1050/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1051/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1052/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1053/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1054/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1055/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1056/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1057/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1058/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1059/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1060/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1061/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1062/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1063/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1064/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1065/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1066/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 1067/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1068/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1069/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1070/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1071/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1072/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1073/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1074/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1075/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1076/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1077/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1078/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1079/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1080/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1081/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1082/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1083/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1084/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1085/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1086/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1087/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1088/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1089/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1090/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1091/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1092/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1093/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1094/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1095/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1096/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1097/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1098/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1099/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1100/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
            "Epoch 1101/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1102/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1103/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1104/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1105/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1106/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1107/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1108/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1109/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1110/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1111/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1112/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1113/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1114/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1115/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1116/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1117/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1118/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1119/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1120/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1121/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1122/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1123/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1124/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1125/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1126/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1127/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1128/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1129/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1130/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1131/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1132/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1133/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1134/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1135/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0051 - val_mean_squared_error: 0.0051\n",
            "Epoch 1136/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1137/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1138/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1139/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1140/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1141/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1142/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1143/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1144/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1145/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1146/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1147/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1148/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1149/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1150/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1151/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1152/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1153/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1154/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1155/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1156/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1157/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1158/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1159/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1160/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1161/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1162/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1163/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1164/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1165/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1166/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1167/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1168/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1169/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1170/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1171/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1172/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1173/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0050 - val_mean_squared_error: 0.0050\n",
            "Epoch 1174/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1175/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1176/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1177/2500\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1178/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1179/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1180/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1181/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1182/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1183/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1184/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1185/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1186/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1187/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1188/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1189/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1190/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1191/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1192/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1193/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1194/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1195/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1196/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1197/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1198/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1199/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1200/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1201/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1202/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1203/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1204/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1205/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1206/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1207/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1208/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1209/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1210/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1211/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1212/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1213/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
            "Epoch 1214/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1215/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1216/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1217/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1218/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1219/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1220/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1221/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1222/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1223/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1224/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1225/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1226/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1227/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1228/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1229/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1230/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1231/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1232/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1233/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1234/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1235/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1236/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1237/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1238/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1239/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1240/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1241/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1242/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1243/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1244/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1245/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1246/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1247/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1248/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1249/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1250/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1251/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1252/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1253/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1254/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1255/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
            "Epoch 1256/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1257/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1258/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1259/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1260/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1261/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1262/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1263/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1264/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1265/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1266/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1267/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1268/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1269/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1270/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1271/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1272/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1273/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1274/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1275/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1276/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1277/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1278/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1279/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1280/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1281/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1282/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1283/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1284/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1285/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1286/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1287/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1288/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1289/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1290/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1291/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1292/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1293/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1294/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1295/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1296/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1297/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1298/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1299/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
            "Epoch 1300/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1301/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1302/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1303/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1304/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1305/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1306/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1307/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1308/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1309/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1310/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1311/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1312/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1313/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1314/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1315/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1316/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1317/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1318/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1319/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1320/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1321/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1322/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1323/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1324/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1325/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1326/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1327/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1328/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1329/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1330/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1331/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1332/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1333/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1334/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1335/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1336/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1337/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1338/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1339/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1340/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1341/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1342/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1343/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1344/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1345/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0046 - val_mean_squared_error: 0.0046\n",
            "Epoch 1346/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1347/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1348/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1349/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1350/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1351/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1352/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1353/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1354/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1355/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1356/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1357/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1358/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1359/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1360/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1361/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1362/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1363/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1364/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1365/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1366/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1367/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1368/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1369/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1370/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1371/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1372/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1373/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1374/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1375/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1376/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1377/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1378/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1379/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1380/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1381/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1382/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1383/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1384/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1385/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1386/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1387/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1388/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1389/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1390/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1391/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1392/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1393/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
            "Epoch 1394/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1395/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1396/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1397/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1398/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1399/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1400/2500\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1401/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1402/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1403/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1404/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1405/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1406/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1407/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1408/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1409/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1410/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1411/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1412/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1413/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1414/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1415/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1416/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1417/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1418/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1419/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1420/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1421/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1422/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0046 - mean_squared_error: 0.0046 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1423/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1424/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1425/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1426/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1427/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1428/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1429/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1430/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1431/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1432/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1433/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1434/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1435/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1436/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1437/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1438/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1439/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1440/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1441/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1442/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1443/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
            "Epoch 1444/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1445/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1446/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1447/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1448/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1449/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1450/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1451/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1452/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1453/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1454/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1455/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1456/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1457/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1458/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1459/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1460/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1461/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1462/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1463/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1464/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1465/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1466/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1467/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1468/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1469/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1470/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1471/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1472/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1473/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1474/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1475/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1476/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1477/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1478/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1479/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1480/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1481/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1482/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1483/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1484/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1485/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1486/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1487/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1488/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1489/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1490/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1491/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1492/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1493/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1494/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1495/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1496/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
            "Epoch 1497/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1498/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1499/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1500/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1501/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1502/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1503/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1504/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1505/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1506/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1507/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1508/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1509/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1510/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1511/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1512/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1513/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1514/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1515/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1516/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1517/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1518/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1519/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1520/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1521/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1522/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1523/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1524/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1525/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1526/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1527/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1528/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1529/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1530/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1531/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1532/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1533/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1534/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1535/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1536/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1537/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1538/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1539/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1540/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1541/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1542/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1543/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1544/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1545/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1546/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1547/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1548/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1549/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1550/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0042 - val_mean_squared_error: 0.0042\n",
            "Epoch 1551/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1552/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1553/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1554/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1555/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1556/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1557/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1558/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1559/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1560/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1561/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1562/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1563/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1564/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1565/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1566/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1567/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1568/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1569/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1570/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1571/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1572/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1573/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1574/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1575/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1576/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1577/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1578/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1579/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1580/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1581/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1582/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1583/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1584/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1585/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1586/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1587/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1588/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1589/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1590/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1591/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1592/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1593/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1594/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1595/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1596/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1597/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1598/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1599/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1600/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1601/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1602/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1603/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1604/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1605/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
            "Epoch 1606/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1607/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1608/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1609/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1610/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1611/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1612/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1613/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1614/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1615/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1616/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1617/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1618/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1619/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1620/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1621/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1622/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1623/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1624/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1625/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1626/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1627/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1628/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1629/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1630/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1631/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1632/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1633/2500\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1634/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1635/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1636/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1637/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1638/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1639/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1640/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1641/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1642/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1643/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1644/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1645/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1646/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1647/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1648/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1649/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1650/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1651/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1652/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1653/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1654/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1655/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1656/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1657/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1658/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1659/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1660/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1661/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1662/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1663/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
            "Epoch 1664/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1665/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1666/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1667/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1668/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1669/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1670/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1671/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1672/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1673/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1674/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1675/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1676/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1677/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1678/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1679/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1680/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1681/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1682/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1683/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1684/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1685/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1686/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1687/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1688/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1689/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1690/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1691/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1692/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1693/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1694/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1695/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1696/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1697/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1698/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1699/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1700/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1701/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1702/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1703/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1704/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1705/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1706/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1707/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1708/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1709/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1710/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1711/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1712/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1713/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1714/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1715/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1716/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1717/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1718/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1719/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1720/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1721/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1722/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
            "Epoch 1723/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1724/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1725/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1726/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1727/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1728/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1729/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1730/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1731/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1732/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1733/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1734/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1735/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1736/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1737/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1738/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1739/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1740/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1741/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1742/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1743/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1744/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1745/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1746/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1747/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1748/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1749/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1750/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1751/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1752/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1753/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1754/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1755/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1756/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1757/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1758/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1759/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1760/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1761/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1762/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1763/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1764/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1765/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1766/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1767/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1768/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1769/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1770/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1771/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1772/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1773/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1774/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1775/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1776/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1777/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1778/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1779/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1780/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1781/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1782/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1783/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1784/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
            "Epoch 1785/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1786/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1787/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1788/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1789/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1790/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1791/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1792/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1793/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1794/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1795/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1796/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1797/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1798/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1799/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1800/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1801/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1802/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1803/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1804/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1805/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1806/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1807/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1808/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1809/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1810/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1811/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1812/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1813/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1814/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1815/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1816/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1817/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1818/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1819/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1820/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1821/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1822/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1823/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1824/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1825/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1826/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1827/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1828/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1829/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1830/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1831/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1832/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1833/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1834/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1835/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1836/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1837/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1838/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1839/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1840/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1841/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1842/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1843/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1844/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1845/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1846/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1847/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
            "Epoch 1848/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1849/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1850/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1851/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1852/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1853/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1854/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1855/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1856/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1857/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1858/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1859/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1860/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1861/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1862/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1863/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1864/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1865/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1866/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1867/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1868/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1869/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1870/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1871/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1872/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1873/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1874/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1875/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1876/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1877/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1878/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1879/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1880/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1881/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1882/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1883/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1884/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1885/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1886/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1887/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1888/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1889/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1890/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1891/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1892/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1893/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1894/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1895/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1896/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1897/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1898/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1899/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1900/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1901/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1902/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1903/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1904/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1905/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1906/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1907/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1908/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1909/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1910/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1911/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1912/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
            "Epoch 1913/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1914/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1915/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1916/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1917/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1918/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1919/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1920/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1921/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1922/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1923/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1924/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1925/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1926/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1927/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1928/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1929/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1930/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1931/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1932/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1933/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1934/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1935/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1936/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1937/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1938/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1939/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1940/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1941/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1942/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1943/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1944/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1945/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1946/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1947/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1948/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1949/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1950/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1951/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1952/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1953/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1954/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1955/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1956/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1957/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1958/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1959/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1960/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1961/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1962/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1963/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1964/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1965/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1966/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1967/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1968/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1969/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1970/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1971/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1972/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1973/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1974/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1975/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1976/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1977/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1978/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1979/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
            "Epoch 1980/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1981/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1982/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1983/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1984/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1985/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1986/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1987/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1988/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1989/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1990/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1991/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1992/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1993/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1994/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1995/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1996/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1997/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1998/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 1999/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2000/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2001/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2002/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2003/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2004/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2005/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2006/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2007/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2008/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2009/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2010/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2011/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2012/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2013/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2014/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2015/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2016/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2017/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2018/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2019/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2020/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2021/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2022/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2023/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2024/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2025/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2026/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2027/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2028/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2029/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2030/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2031/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2032/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2033/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2034/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2035/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2036/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2037/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2038/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2039/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2040/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2041/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2042/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2043/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2044/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2045/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2046/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2047/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2048/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
            "Epoch 2049/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2050/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2051/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2052/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2053/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2054/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2055/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2056/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2057/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2058/2500\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2059/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2060/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2061/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2062/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2063/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2064/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2065/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2066/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2067/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2068/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2069/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2070/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2071/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2072/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2073/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2074/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2075/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2076/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2077/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2078/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2079/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2080/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2081/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2082/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2083/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2084/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2085/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2086/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2087/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2088/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2089/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2090/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2091/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2092/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2093/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2094/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2095/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2096/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2097/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2098/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2099/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2100/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2101/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2102/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2103/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2104/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2105/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2106/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2107/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2108/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2109/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2110/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2111/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2112/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2113/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2114/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2115/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2116/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2117/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2118/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2119/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
            "Epoch 2120/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2121/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2122/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2123/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2124/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2125/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2126/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2127/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2128/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2129/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2130/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2131/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2132/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2133/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2134/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2135/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2136/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2137/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2138/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2139/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2140/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2141/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2142/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2143/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2144/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2145/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2146/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2147/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2148/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2149/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2150/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2151/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2152/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2153/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2154/2500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2155/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2156/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2157/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2158/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2159/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2160/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2161/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2162/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2163/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2164/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2165/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2166/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2167/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2168/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2169/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2170/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2171/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2172/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2173/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2174/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2175/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2176/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2177/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2178/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2179/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2180/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2181/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2182/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2183/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2184/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2185/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2186/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2187/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2188/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2189/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2190/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2191/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2192/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2193/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
            "Epoch 2194/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2195/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2196/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2197/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2198/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2199/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2200/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2201/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2202/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2203/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2204/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2205/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2206/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2207/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2208/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2209/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2210/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2211/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2212/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2213/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2214/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2215/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2216/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2217/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2218/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2219/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2220/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2221/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2222/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2223/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2224/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2225/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2226/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2227/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2228/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2229/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2230/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2231/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2232/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2233/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2234/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2235/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2236/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2237/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2238/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2239/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2240/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2241/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2242/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2243/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2244/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2245/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2246/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2247/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2248/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2249/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2250/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2251/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2252/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2253/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2254/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2255/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2256/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2257/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2258/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2259/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2260/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2261/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2262/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2263/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2264/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2265/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2266/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2267/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2268/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2269/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2270/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
            "Epoch 2271/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2272/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2273/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2274/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2275/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2276/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2277/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2278/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2279/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2280/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2281/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2282/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2283/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2284/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2285/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2286/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2287/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2288/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2289/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2290/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2291/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2292/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2293/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2294/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2295/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2296/2500\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2297/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2298/2500\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2299/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2300/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2301/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2302/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2303/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2304/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2305/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2306/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2307/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2308/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2309/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2310/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2311/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2312/2500\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2313/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2314/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2315/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2316/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2317/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2318/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2319/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2320/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2321/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2322/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2323/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2324/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2325/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2326/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2327/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2328/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2329/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2330/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2331/2500\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2332/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2333/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2334/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2335/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2336/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2337/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2338/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2339/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2340/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2341/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2342/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2343/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2344/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2345/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2346/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2347/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2348/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2349/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
            "Epoch 2350/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2351/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2352/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2353/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2354/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2355/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2356/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2357/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2358/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2359/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2360/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2361/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2362/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2363/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2364/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2365/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2366/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2367/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2368/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2369/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2370/2500\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2371/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2372/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2373/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2374/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2375/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2376/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2377/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2378/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2379/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2380/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2381/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2382/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2383/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2384/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2385/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2386/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2387/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2388/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2389/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2390/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2391/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2392/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2393/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2394/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2395/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2396/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2397/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2398/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2399/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2400/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2401/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2402/2500\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2403/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2404/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2405/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2406/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2407/2500\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2408/2500\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2409/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2410/2500\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2411/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2412/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2413/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2414/2500\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2415/2500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2416/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2417/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2418/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2419/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2420/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2421/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2422/2500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2423/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2424/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2425/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2426/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2427/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2428/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2429/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2430/2500\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2431/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2432/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
            "Epoch 2433/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2434/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2435/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2436/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2437/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2438/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2439/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2440/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2441/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2442/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2443/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2444/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2445/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2446/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2447/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2448/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2449/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2450/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2451/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2452/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2453/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2454/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2455/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2456/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2457/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2458/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2459/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2460/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2461/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2462/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2463/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2464/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2465/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2466/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2467/2500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2468/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2469/2500\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2470/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2471/2500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2472/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2473/2500\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2474/2500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2475/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2476/2500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2477/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2478/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2479/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2480/2500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2481/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2482/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2483/2500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2484/2500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2485/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2486/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2487/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2488/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2489/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2490/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2491/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2492/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2493/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2494/2500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2495/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2496/2500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2497/2500\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2498/2500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2499/2500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
            "Epoch 2500/2500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0HqYFKtrVOM"
      },
      "source": [
        "# Get fish weight predictions\n",
        "y_fish_pred = model.predict(x_test)\n",
        "\n",
        "# map normalized fish weights back to grams\n",
        "y_fish_pred = (fish_max-fish_min) * y_fish_pred + fish_min \n",
        "y_test = (fish_max-fish_min) * y_test.values + fish_min "
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0cyLYP-qx36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "867e6fde-1fa7-431b-9bb3-c9539cfe9499"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Compute the mean squared error using y_fish_test and y_fish_pred\n",
        "### YOUR CODE HERE ###\n",
        "print(\"Mean squared error: \", mean_squared_error(y_test, y_fish_pred))\n",
        "\n",
        "# Compute the coefficient of determination using y_fish_test and y_fish_pred\n",
        "### YOUR CODE HERE ###\n",
        "print(\"Coefficient of determination: \", r2_score(y_test, y_fish_pred))\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean squared error:  8119.83678379169\n",
            "Coefficient of determination:  0.9457992702675007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXh5nXxgzAsZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6717113-866c-453a-b94a-417e6aa7ac22"
      },
      "source": [
        "# Print the predictions along with actual weights\n",
        "np.set_printoptions(formatter={'float_kind':'{:f}'.format},precision=2)\n",
        "print(np.concatenate((y_fish_pred.reshape(len(y_fish_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[438.040771 430.000000]\n",
            " [634.669983 575.000000]\n",
            " [-138.816971 9.800000]\n",
            " [-75.155624 19.700000]\n",
            " [705.118591 650.000000]\n",
            " [159.965088 170.000000]\n",
            " [-14.752851 51.500000]\n",
            " [679.529114 800.000000]\n",
            " [132.415085 130.000000]\n",
            " [-130.213898 10.000000]\n",
            " [585.993774 700.000000]\n",
            " [836.378235 1015.000000]\n",
            " [-118.313255 12.200000]\n",
            " [-138.410477 9.700000]\n",
            " [133.170044 110.000000]\n",
            " [680.351196 700.000000]\n",
            " [251.175537 218.000000]\n",
            " [506.275482 500.000000]\n",
            " [322.442841 300.000000]\n",
            " [83.629639 120.000000]\n",
            " [123.218163 130.000000]\n",
            " [-45.994560 40.000000]\n",
            " [-11.829828 60.000000]\n",
            " [1022.610657 950.000000]\n",
            " [1238.200073 1250.000000]\n",
            " [1494.309692 1650.000000]\n",
            " [216.291718 180.000000]\n",
            " [286.830200 250.000000]\n",
            " [-124.711800 12.200000]\n",
            " [-20.378410 55.000000]\n",
            " [-133.168671 9.900000]\n",
            " [789.161072 900.000000]\n",
            " [899.778137 1000.000000]\n",
            " [274.897034 260.000000]\n",
            " [607.799683 610.000000]\n",
            " [282.672546 290.000000]\n",
            " [-70.541382 19.900000]\n",
            " [788.927917 1000.000000]\n",
            " [476.405518 450.000000]\n",
            " [120.140793 135.000000]\n",
            " [266.750244 270.000000]\n",
            " [-152.243195 7.000000]\n",
            " [95.463150 115.000000]\n",
            " [924.284363 925.000000]\n",
            " [101.986542 110.000000]\n",
            " [-138.177444 8.700000]\n",
            " [132.905167 150.000000]\n",
            " [-150.961014 7.500000]\n",
            " [174.504166 145.000000]\n",
            " [808.998962 820.000000]\n",
            " [851.432495 920.000000]\n",
            " [171.346725 161.000000]\n",
            " [660.826294 690.000000]\n",
            " [101.605339 110.000000]\n",
            " [753.944214 850.000000]\n",
            " [71.212669 87.000000]\n",
            " [693.872498 680.000000]\n",
            " [625.827271 510.000000]\n",
            " [844.604065 1000.000000]\n",
            " [42.099232 90.000000]\n",
            " [714.617432 500.000000]\n",
            " [289.673370 250.000000]\n",
            " [764.149109 820.000000]\n",
            " [-58.066296 40.000000]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FprpdF_YzJf6"
      },
      "source": [
        "What was the R-squared value and mean squared error for this model? Does this model appear to do a better job at predicting weights than linear regression?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDRR8wzy0SZu"
      },
      "source": [
        "Mean squared error:  8119.83678379169\n",
        "\n",
        "Coefficient of determination:  0.9457992702675007\n",
        "\n",
        "It is better than Linear regression since the mean squared error is smaller and R-squared value is close to 1."
      ]
    }
  ]
}