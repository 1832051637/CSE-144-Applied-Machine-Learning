{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2IlwhV0z2nMr"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Chprzdhe2nMw"
   },
   "source": [
    "# Assignment 1\n",
    "\n",
    "**DUE: Sunday June 27 at 11:59pm**\n",
    "\n",
    "Turn in the assignment via Canvas.\n",
    "\n",
    "To write legible answers you will need to be familiar with both [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) and [Latex](https://www.latex-tutorial.com/tutorials/amsmath/)\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, restart the kernel (in the menubar, select Runtime→→Restart runtime) and then run all cells (in the menubar, select Runtime→→Run All).\n",
    "\n",
    "Make sure you fill in any place that says \"YOUR CODE HERE\" or \"YOUR ANSWER HERE\", as well as your name below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8jeWubXE2nMx"
   },
   "outputs": [],
   "source": [
    "NAME = \"Erjie Zhang\"\n",
    "STUDENT_ID = \"1813132\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hWGANrgdWdk"
   },
   "source": [
    "## Problem 1 - Discrete Probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5FtL8JZdYeh"
   },
   "source": [
    "When playing football, Sammy the Slug ALWAYS scores between 0 to 4 goals. The discrete probability distribution for the number of goals scored in a match is given in the table below where **x** is the number of goals scored in a game and **P(x)** is the probability of scoring **x** points.\n",
    "\n",
    "| x      | P(x) |\n",
    "| ----------- | ----------- |\n",
    "| 0     | 0.01   |\n",
    "| 1     | 0.03   |\n",
    "| 2     | 0.21   |\n",
    "| 3     | 0.46   |\n",
    "| 4     | 0.26   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9heUpjFRek9C"
   },
   "source": [
    "### a) (1 point)\n",
    "\n",
    "What is the probability that Sammy Scores 1 point in a match? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwM2rh4ofqkE"
   },
   "source": [
    "[YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QdR6qrLCftTH"
   },
   "source": [
    "What is the probability that Sammy scores 4 points in a match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJ7GDXOJfwGf"
   },
   "source": [
    "[YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zKendEfUey73"
   },
   "source": [
    "### b) (1 point)\n",
    "\n",
    "\n",
    "What is $P(1<x<4)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2LCnzS6JfyMA"
   },
   "source": [
    "[YOUR ANSWER HERE]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1YqmH5HTAAUF"
   },
   "source": [
    "### c) (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFSIqmecgFZ-"
   },
   "source": [
    "What is $P(1\\leq x \\leq 4)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1NS7mSq-gGom"
   },
   "source": [
    "[YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FsorH57-gB5M"
   },
   "source": [
    "### d) (3 points)\n",
    "\n",
    "What is the Expectation of this distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nCfLpv8gWvI"
   },
   "source": [
    "[YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWZveDLbgX3P"
   },
   "source": [
    "### e) (3 points)\n",
    "\n",
    "What is the variance of this distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5kpGqbtqgcEI"
   },
   "source": [
    "[YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wC8thn7rlRQW"
   },
   "source": [
    "## Problem 2 - Continuous Probability\n",
    "\n",
    "Sammy the slug also participates on the UCSC swim team. The probability that Sammy the Slug completes the 400m swim in $x$ seconds is modeled by the probability density function:\n",
    "$$f(x)=0.019e^{-0.019x}$$\n",
    "for $0\\leq x\\leq \\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EugkCQrWmzSy"
   },
   "source": [
    "### a.) (4 points)\n",
    "\n",
    "what is the probability that Sammy the Slug finishes the 400m swim in 200 seconds or less (hint: what is $F(200)$)? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2co2pjdlobCx"
   },
   "source": [
    "[YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrJ1hKatYaiU"
   },
   "source": [
    "## Problem 3 -  Monte Carlo Simulation\n",
    "\n",
    "Monte Carlo simulations can yield numeric solutions to probability problems that aren't possible to solve analytically. These simulations are also often easy to code up, and so also provide a way to check one's calculations for problems that amenable to analysis. So this is an important technique to become familiar with.\n",
    "\n",
    "Basically, one creates a simulation of the situation, and runs many trials that allow one to estimate the probabilities by computing proportions. \n",
    "\n",
    "First we give you an example of a Monte Carlo simulation, and then you'll solve such a problem yourself.\n",
    "\n",
    "### Example\n",
    "\n",
    "If you toss a coin 10 times, with what probability are you likely to see the subsequence {H, H, T, T} appear?\n",
    "\n",
    "Be patient, this may take a bit to run, but notice how straightforward the coding is. The simplicity of the Monte Carlo method makes it very powerful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vBn1ndB3oJxa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0 %  complete:   prob = 0.4397\n",
      "20.0 %  complete:   prob = 0.43925\n",
      "30.0 %  complete:   prob = 0.4398666666666667\n",
      "40.0 %  complete:   prob = 0.439775\n",
      "50.0 %  complete:   prob = 0.43872\n",
      "60.0 %  complete:   prob = 0.43865\n",
      "70.0 %  complete:   prob = 0.4395142857142857\n",
      "80.0 %  complete:   prob = 0.439075\n",
      "90.0 %  complete:   prob = 0.4384888888888889\n",
      "100.0 %  complete:   prob = 0.43879\n",
      "Probability of this subsequence = 0.43879\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import randint\n",
    "import numpy as np\n",
    "\n",
    "num_tosses = 10    # tosses per trial\n",
    "num_trials = 100000\n",
    "\n",
    "# This sets the feedback interval so we know the program hasn't crashed.\n",
    "feedback = int(np.round(num_trials / 10))\n",
    "\n",
    "num_seq_found = 0   # to count the number of target subsequences detected\n",
    "for t in range(1, num_trials + 1):\n",
    "    \n",
    "    # To see the progress.\n",
    "    if t % feedback == 0:  \n",
    "        print(np.round(100 * t / num_trials, 1), '%  complete:   prob =', num_seq_found / t)\n",
    "        \n",
    "    # Roll the die num_tosses times.\n",
    "    trial = [randint(1, 3) for _ in range(num_tosses)]\n",
    "    # Find the indices of all the 1s.\n",
    "    heads = [i for i in range(num_tosses) if trial[i] == 1]\n",
    "    \n",
    "    # Search for the correct pattern.\n",
    "    for j in heads:\n",
    "        if j < num_tosses - 3 and trial[j] == 1 and trial[j + 1] == 1 and trial[j + 2] == 2 and trial[j + 3] == 2:\n",
    "            # We've found the target subsequence.\n",
    "            num_seq_found += 1\n",
    "    \n",
    "print('Probability of this subsequence =', num_seq_found / num_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IT-eRCtiYaib"
   },
   "source": [
    "### a) (6 points)\n",
    "\n",
    "Consider two dice: One fair and one unfair. The unfair die has a 50% chance to land on the 3 face, and even chance for the rest of the faces.\n",
    "\n",
    "Write code that rolls both dice and computes the sum.\n",
    "\n",
    "Do this many times, and give the mean of all the sums.  This will converge to the expected average sum of both randomly rolled dice. You may need to run this several times to be sure of your accuracy. You can check the correctness of your Monte Carlo Simulation by solving this problem analytically.\n",
    "\n",
    "Hint:\n",
    "\n",
    "https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.random.choice.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H4GVkg25oJxd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "\n",
    "num_trials = 100000\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "mean_sum = None\n",
    "print('mean sum =', mean_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OuwF3Y2b2nN3"
   },
   "source": [
    "## Problem 4 - Heart Disease Dataset\n",
    "\n",
    "When a data scientist first encounters a new dataset, the first step is data exploration. The dataset we'll be using is derived from the Heart database from the UCI Machine Learning Repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 978,
     "status": "ok",
     "timestamp": 1624574628597,
     "user": {
      "displayName": "Michael Briden",
      "photoUrl": "",
      "userId": "02544285333299770616"
     },
     "user_tz": 420
    },
    "id": "QZJlh8ZH2nN4"
   },
   "outputs": [],
   "source": [
    "# Useful libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLCeUi8K2ycm"
   },
   "source": [
    "### a) Read in the Data (4 points)\n",
    "This is much easier when you have the data on your own hard drive! Just run the next couple of code blocks. You'll have to paste your authorization code at one point...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3363,
     "status": "ok",
     "timestamp": 1624574620654,
     "user": {
      "displayName": "Michael Briden",
      "photoUrl": "",
      "userId": "02544285333299770616"
     },
     "user_tz": 420
    },
    "id": "Xnm4IUVn2va9",
    "outputId": "4a881483-ddca-4ef4-bc60-aa72b64e90f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyDrive\n",
      "  Using cached PyDrive-1.3.1.tar.gz (987 kB)\n",
      "Collecting google-api-python-client>=1.2\n",
      "  Using cached google_api_python_client-2.10.0-py2.py3-none-any.whl (7.0 MB)\n",
      "Collecting oauth2client>=4.0.0\n",
      "  Using cached oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "Requirement already satisfied: PyYAML>=3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from PyDrive) (5.4.1)\n",
      "Collecting google-api-core<2dev,>=1.21.0\n",
      "  Using cached google_api_core-1.30.0-py2.py3-none-any.whl (93 kB)\n",
      "Collecting httplib2<1dev,>=0.15.0\n",
      "  Using cached httplib2-0.19.1-py3-none-any.whl (95 kB)\n",
      "Collecting google-auth<2dev,>=1.16.0\n",
      "  Using cached google_auth-1.32.0-py2.py3-none-any.whl (147 kB)\n",
      "Requirement already satisfied: six<2dev,>=1.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-python-client>=1.2->PyDrive) (1.15.0)\n",
      "Collecting uritemplate<4dev,>=3.0.0\n",
      "  Using cached uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
      "Collecting google-auth-httplib2>=0.1.0\n",
      "  Using cached google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.6.0\n",
      "  Using cached googleapis_common_protos-1.53.0-py2.py3-none-any.whl (198 kB)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (52.0.0.post20210125)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.25.1)\n",
      "Collecting protobuf>=3.12.0\n",
      "  Downloading protobuf-3.17.3-py2.py3-none-any.whl (173 kB)\n",
      "Requirement already satisfied: packaging>=14.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (20.9)\n",
      "Requirement already satisfied: pytz in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2021.1)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: pyparsing<3,>=2.4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client>=1.2->PyDrive) (2.4.7)\n",
      "Collecting pyasn1>=0.1.7\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (4.0.0)\n",
      "Building wheels for collected packages: PyDrive\n",
      "  Building wheel for PyDrive (setup.py): started\n",
      "  Building wheel for PyDrive (setup.py): finished with status 'done'\n",
      "  Created wheel for PyDrive: filename=PyDrive-1.3.1-py3-none-any.whl size=27435 sha256=8bbbb94ab588a243944dea313682c054894bae003495cb1d33cdc5fb83f335c3\n",
      "  Stored in directory: c:\\users\\apk10\\appdata\\local\\pip\\cache\\wheels\\c6\\14\\12\\ccdcc5d3b41661f360f9c7d9f7ea9d1879a5f85aa4ecc8cc6f\n",
      "Successfully built PyDrive\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, protobuf, cachetools, httplib2, googleapis-common-protos, google-auth, uritemplate, google-auth-httplib2, google-api-core, oauth2client, google-api-python-client, PyDrive\n",
      "Successfully installed PyDrive-1.3.1 cachetools-4.2.2 google-api-core-1.30.0 google-api-python-client-2.10.0 google-auth-1.32.0 google-auth-httplib2-0.1.0 googleapis-common-protos-1.53.0 httplib2-0.19.1 oauth2client-4.1.3 protobuf-3.17.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 rsa-4.7.2 uritemplate-3.0.1\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-079f90e22c62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpydrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauth\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGoogleAuth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpydrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrive\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGoogleDrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0moauth2client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "!pip install PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1624574621344,
     "user": {
      "displayName": "Michael Briden",
      "photoUrl": "",
      "userId": "02544285333299770616"
     },
     "user_tz": 420
    },
    "id": "osP9dVT02_m1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'auth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-3254a9bed9fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mauth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mgauth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGoogleAuth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgauth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcredentials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_application_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdrive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGoogleDrive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgauth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'auth' is not defined"
     ]
    }
   ],
   "source": [
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1110,
     "status": "ok",
     "timestamp": 1624574678982,
     "user": {
      "displayName": "Michael Briden",
      "photoUrl": "",
      "userId": "02544285333299770616"
     },
     "user_tz": 420
    },
    "id": "rYrU50rO2nN6"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'drive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-91a2e5334f6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdownloaded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCreateFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"1qF_Ees7ETr5BiPnHTabyeIH1KQVkViUK\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# Replace the id with id of file you want to access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdownloaded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetContentFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Heart.csv'\u001b[0m\u001b[1;33m)\u001b[0m        \u001b[1;31m# Replace the file name with your file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Finally we can actually read in the data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Heart.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'drive' is not defined"
     ]
    }
   ],
   "source": [
    "downloaded = drive.CreateFile({'id':\"1qF_Ees7ETr5BiPnHTabyeIH1KQVkViUK\"})   # Replace the id with id of file you want to access\n",
    "downloaded.GetContentFile('Heart.csv')        # Replace the file name with your file\n",
    "\n",
    "# Finally we can actually read in the data.\n",
    "data = pd.read_csv('Heart.csv')\n",
    "\n",
    "# How many rows and columns are in this dataset?\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugFGZQiI1bVr"
   },
   "source": [
    "Number of rows: [YOUR ANSWER HERE]\n",
    "\n",
    "Number of columns: [YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSuWlktS2nN9"
   },
   "source": [
    "### b) Understanding the Data (15 points)\n",
    "\n",
    "Look for a data description file whenever you explore a new dataset. This is a codebook (or text file) that tells you what each data item represents. The following is a data dictionary for this dataset, which is derived from one in the UCI Machine Learning Dataset Repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6EthXyP2nN-"
   },
   "source": [
    "Age: The person's age in years\n",
    "\n",
    "Sex: The person's sex (1 = male, 0 = female)\n",
    "\n",
    "ChestPain: The chest pain experienced <br>\n",
    ".............typical angina  <br>\n",
    ".............atypical angina <br>\n",
    ".............non-anginal pain  <br>\n",
    ".............asymptomatic\n",
    "\n",
    "RestBP: The person's resting blood pressure (mm Hg on admission to the hospital)\n",
    "\n",
    "Chol: The person's cholesterol measurement in mg/dl\n",
    "\n",
    "Fbs: The person's fasting blood sugar (> 120 mg/dl, 1 = true; 0 = false)\n",
    "\n",
    "RestECG: Resting electrocardiographic measurement <br>\n",
    ".............0: normal <br>\n",
    ".............1: having ST-T wave abnormality <br>\n",
    ".............2: showing probable left ventricular hypertrophy by Estes' criteria\n",
    "\n",
    "MaxHR: The person's maximum heart rate achieved\n",
    "\n",
    "ExAng: Exercise induced angina (1 = yes; 0 = no)\n",
    "\n",
    "Oldpeak: ST depression induced by exercise relative to rest <br>\n",
    "..............('ST' relates to positions on the ECG plot.)\n",
    "\n",
    "Slope: the slope of the peak exercise ST segment <br>\n",
    "...........1: upsloping <br>\n",
    "...........2: flat <br>\n",
    "...........3: downsloping\n",
    "\n",
    "Ca: The number of major vessels (0-3)\n",
    "\n",
    "Thal: A blood disorder called thalassemia <br>\n",
    "...........normal <br>\n",
    "...........fixed <br>\n",
    "...........reversable\n",
    "\n",
    "AHD: Heart disease ('No', 'Yes') -  The target we would like to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3OtUkDID2nN-"
   },
   "outputs": [],
   "source": [
    "# Show the first few rows of the data.\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C116JGsY2nOA"
   },
   "outputs": [],
   "source": [
    "# Print out the \"info\" of the dataset.\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JRzQNLl2nOE"
   },
   "source": [
    "The above output can help you to see how much missing data is in the dataset. How many null values (missing values) exists in the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4bmW83H2O_D"
   },
   "source": [
    "[YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-m5AXWe2TWf"
   },
   "source": [
    "What to do about missing values is very good question. Sometimes one replaces such missing values with the mean of all the values that are present for this variable. But to keep things simple here we will simply delete any rows with missing data.\n",
    "\n",
    "Use the code cell below to drop null values from the data. [hint: you can use dropna() function]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hOepmrOg2nOE"
   },
   "outputs": [],
   "source": [
    "# Drop any rows with missing data\n",
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FoLwru912nOH"
   },
   "source": [
    "Another useful Pandas dataframe method is describe(). The describe method gives summary statistics for each column, which can help you to identify outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eU_RHFpE2nOI"
   },
   "outputs": [],
   "source": [
    "# The describe method of a Pandas dataframe yields much useful information.\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVnRhHh82nOK"
   },
   "source": [
    "Outliers are values far removed from the other data values, and are usually typos or other errors. Looking at the data description above, do you spot any possible outliers in the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MV8k7xzv3Twl"
   },
   "source": [
    "[YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czNvxv173JNh"
   },
   "source": [
    "### c) Outlier Detection \\& Elimination (8 points)\n",
    "In this section, We'll remove any ages that are more than 4 standard deviations from the mean.\n",
    "\n",
    "To accomplish this: \n",
    "\n",
    "1) You'll make a new column called AgeZ to hold the z-transformed values of the Age column. \n",
    "\n",
    "\n",
    "2) Then, any AgeZ value that's less than -4 or more than 4 should be flagged as an outlier. \n",
    "\n",
    "\n",
    "3) Remove those entries from the dataset.\n",
    "\n",
    "Remember that standardizing the data (or z-transform) is making your data have a zero mean and unit variance. This can be done with:\n",
    "\n",
    "$$x \\to_{stdize}  \\frac{x - \\mu}{\\sigma}$$\n",
    "Where $\\mu$ is your mean and $\\sigma$ is your standard deviation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LzKOPmvf2nOL"
   },
   "outputs": [],
   "source": [
    "data['AgeZ'] = ### YOUR CODE HERE ###\n",
    "\n",
    "# Delete any rows for which AgeZ is greater than 4 or less than -4.\n",
    "data = ### YOUR CODE HERE ###\n",
    "\n",
    "# Cleanup - delete the z-tranform column since we don't need it any more.\n",
    "data = data.drop(columns=['AgeZ'])\n",
    "\n",
    "# Let's take another look.\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4YIpqol2nON"
   },
   "source": [
    "Notice that now the Age column is much more reasonable.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJvLHq_m2nOO"
   },
   "source": [
    "Perform the same process to eliminate any extreme outliers (more than 4 standard deviations away from the mean) for RestBP, MaxHR, and the Oldpeak variables. Delete those exta columns after you have removed the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jrizwTo22nOO"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "\n",
    "\n",
    "# Leave this for your last line.\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kls093zf2nOR"
   },
   "source": [
    "### d) Data Visualization (8 points)\n",
    "\n",
    "Sometimes it's useful to look at a pairwise plot of all the variables. Below we do this for all but the first column. Be patient, this takes a minute to complete. Notice that the main diagonal has histogram plots for each variable, which gives you a sense of the distribution of values of each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KadsSpNR2nOR"
   },
   "outputs": [],
   "source": [
    "# Make a pairplot of all the variables (columns), excepting the first column.\n",
    "plt.rcParams['figure.figsize'] = (15, 15)\n",
    "sns.pairplot(data.drop(columns='Unnamed: 0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PuRhYp32nOU"
   },
   "source": [
    "Let's look at a larger plot of the patient age distribution for the patients in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eWpVLgZK2nOU"
   },
   "outputs": [],
   "source": [
    "# Plot the patient age distribution.\n",
    "plt.rcParams['figure.figsize'] = (7, 4)\n",
    "sns.distplot(data['Age'])\n",
    "plt.title('Age Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRAR3b_52nOX"
   },
   "source": [
    "Plot the distribution of patient cholesterol levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2sCbr9z2nOY"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QLPhTCq2nOa"
   },
   "source": [
    "### e) Data Normalization (8 points)\n",
    "\n",
    "We've already seen how the z-transform can be used to rescale values. We used this to help eliminate outliers, but such transforms can also be useful prior to applying machine learning algorithms, and often improves the algorithms performance. \n",
    "\n",
    "Another common transform is to map all the variable values into the interval $[0,1]$, via the transform:\n",
    "\n",
    "$$x \\to  \\frac{x - \\min}{\\max - \\min}$$\n",
    "\n",
    "Let's create a new column ('NewAge') mapping all ages into the interval $[0,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cEvlQDXm2nOb"
   },
   "outputs": [],
   "source": [
    "# Create a new column, NewAge, to hold the normalized Age variable.\n",
    "data['NewAge'] = ### YOUR CODE HERE ###\n",
    "\n",
    "# Take a look at the new age column.\n",
    "data['NewAge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hvWHd-vZ2nOd"
   },
   "outputs": [],
   "source": [
    "# We don't need this column, so we delete it. (It was just to show you how to do this.)\n",
    "data = data.drop(columns=['NewAge'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gObPkanN2nOg"
   },
   "source": [
    "Map the minimum to 0 and maximum to 1 (in other words, normalize the column) for the RestBP, Chol, and MaxHR columns. Don't create new columns, just replace the existing ones with the transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MSjXg7Go2nOg"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "\n",
    "# Leave this for your last line.\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PRmp0GI2nOi"
   },
   "source": [
    "### f) Converting Categorical Data to Numeric Values (6 points)\n",
    "\n",
    "It's frequently useful to convert categorical (non-numeric) values to numeric ones. The last variable in the data frame, AHD, has categorical values 'No' if the patient has no heart disease, and 'Yes' if they do. Convert these values to 0 for 'No' and 1 for 'Yes'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A0vh80Yc2nOj"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zmj1yFJU2nOm"
   },
   "source": [
    "### g) One-Hot-Encoding (10 points)\n",
    "\n",
    "One-hot-encoding is another often used way of converting categorical data to numeric. For example, instead of the categories 'cold', 'warm', 'hot', we form a seperate column for each of these attributes, so that what was represented as 'cold' is now $[1,0,0]$ and what was 'hot' is now $[0,0,1]$.  There is a built in command for doing this in the sklearn package.\n",
    "\n",
    "Similar to what you've learned from the class exercise of lecture 2, add new columns for one-hot-encoding of 'Thal' column. Use 'Thal' as the prefix. Then drop the original column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jiPkdXxE2nOo"
   },
   "outputs": [],
   "source": [
    "# Concatentate new one-hot encodings with the original dataframe.\n",
    "data = ### YOUR CODE HERE ###\n",
    "\n",
    "# now drop the original 'Thal' column (you don't need it anymore)\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-7xSpv62nOs"
   },
   "source": [
    "Create a one-hot-encoding for the ChestPain column, just as we did above for the Thal column, deleting the original column as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HH8kndAQ2nOs"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "\n",
    "# Leave this for your last line.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGXRujgd2nOv"
   },
   "source": [
    "### h) Feature Engineering (10 points)\n",
    "\n",
    "Feature engineering is central to much of machine learning. Traditionally such features needed to be hand crafted, which is as much an art as it is engineering. One of the huge advantages of neural networks over traditional machine learning techniques is that neural networks can learn optimal features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekfL1tTH2nOv"
   },
   "source": [
    "Create a new column (feature) called AgeC, which will be the product of the patient's age and the patient's cholesterol level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DFJhzWT02nOv"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "\n",
    "# Leave this for your last line.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JNeMdC4D2nOx"
   },
   "source": [
    "###  i) Balanced or Unbalanced Classes (10 points)\n",
    "\n",
    "For this dataset, one variable that we might like to predict is the presence of heart disease, the AHD column, using all the other columns. Some datasets are highly imbalanced.  Suppose that 95% of a set of subjects were healthy, with only 5% having heart disease. A machine learning model can attain 95% accuracy by simply ALWAYS predicting no heart disease. It sounds like a fairly accurate model, but it would miss predicting any heart disease! \n",
    "\n",
    "There are techniques for dealing with this, but first we have to ascertain if our data is unbalanced. Use the code cell below to see if the data is imbalanced or not and describe your observations in the next text cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J8Ie6nAf2nOy"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jCOv0vYf2nO0"
   },
   "source": [
    "[YOUR ANSWER HERE]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Summer_21_Assignment_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
